{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00104a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 17:59:56.536403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095052bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('winemag-data_first150k.csv',index_col= 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf21eb6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151839</th>\n",
       "      <td>Italy</td>\n",
       "      <td>This opens with aromas of toast, oak, menthol,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Piedmont</td>\n",
       "      <td>Barbaresco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nebbiolo</td>\n",
       "      <td>Castello di Neive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151840</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Flat in color, with a dull luster, this smells...</td>\n",
       "      <td>Grand Vin</td>\n",
       "      <td>87.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Mendoza Province</td>\n",
       "      <td>Vista Flores</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Antucura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151841</th>\n",
       "      <td>France</td>\n",
       "      <td>Juicy dark plum, cherry and boysenberry are up...</td>\n",
       "      <td>Samsó Seulle</td>\n",
       "      <td>87.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>France Other</td>\n",
       "      <td>Vin de France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cinsault</td>\n",
       "      <td>Frédéric Brouca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151842</th>\n",
       "      <td>US</td>\n",
       "      <td>This light, refreshing rosé mixes fresh strawb...</td>\n",
       "      <td>Three Otters Pinot Noir</td>\n",
       "      <td>87.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Rosé</td>\n",
       "      <td>Fullerton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151843</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151844 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country                                        description  \\\n",
       "0              US  This tremendous 100% varietal wine hails from ...   \n",
       "1           Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2              US  Mac Watson honors the memory of a wine once ma...   \n",
       "3              US  This spent 20 months in 30% new French oak, an...   \n",
       "4          France  This is the top wine from La Bégude, named aft...   \n",
       "...           ...                                                ...   \n",
       "151839      Italy  This opens with aromas of toast, oak, menthol,...   \n",
       "151840  Argentina  Flat in color, with a dull luster, this smells...   \n",
       "151841     France  Juicy dark plum, cherry and boysenberry are up...   \n",
       "151842         US  This light, refreshing rosé mixes fresh strawb...   \n",
       "151843        NaN                                                NaN   \n",
       "\n",
       "                                 designation  points  price          province  \\\n",
       "0                          Martha's Vineyard    96.0  235.0        California   \n",
       "1       Carodorum Selección Especial Reserva    96.0  110.0    Northern Spain   \n",
       "2              Special Selected Late Harvest    96.0   90.0        California   \n",
       "3                                    Reserve    96.0   65.0            Oregon   \n",
       "4                                 La Brûlade    95.0   66.0          Provence   \n",
       "...                                      ...     ...    ...               ...   \n",
       "151839                                   NaN    87.0   35.0          Piedmont   \n",
       "151840                             Grand Vin    87.0   30.0  Mendoza Province   \n",
       "151841                          Samsó Seulle    87.0   23.0      France Other   \n",
       "151842               Three Otters Pinot Noir    87.0   18.0            Oregon   \n",
       "151843                                   NaN     NaN    NaN               NaN   \n",
       "\n",
       "                 region_1           region_2                   variety  \\\n",
       "0             Napa Valley               Napa        Cabernet Sauvignon   \n",
       "1                    Toro                NaN             Tinta de Toro   \n",
       "2          Knights Valley             Sonoma           Sauvignon Blanc   \n",
       "3       Willamette Valley  Willamette Valley                Pinot Noir   \n",
       "4                  Bandol                NaN        Provence red blend   \n",
       "...                   ...                ...                       ...   \n",
       "151839         Barbaresco                NaN                  Nebbiolo   \n",
       "151840       Vista Flores                NaN  Bordeaux-style Red Blend   \n",
       "151841      Vin de France                NaN                  Cinsault   \n",
       "151842  Willamette Valley  Willamette Valley                      Rosé   \n",
       "151843                NaN                NaN                       NaN   \n",
       "\n",
       "                         winery  \n",
       "0                         Heitz  \n",
       "1       Bodega Carmen Rodríguez  \n",
       "2                      Macauley  \n",
       "3                         Ponzi  \n",
       "4          Domaine de la Bégude  \n",
       "...                         ...  \n",
       "151839        Castello di Neive  \n",
       "151840                 Antucura  \n",
       "151841          Frédéric Brouca  \n",
       "151842                Fullerton  \n",
       "151843                      NaN  \n",
       "\n",
       "[151844 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae8cfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['region_2'] = wine_df['region_2'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4a2929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Napa Valley                         6246\n",
       "Columbia Valley (WA)                4994\n",
       "Mendoza                             3597\n",
       "Russian River Valley                3588\n",
       "California                          3472\n",
       "                                    ... \n",
       "Vin de Pays des Côtes de Thongue       1\n",
       "Toledo                                 1\n",
       "Vin de Pays de Montferrand             1\n",
       "Napa County-Lake County                1\n",
       "El Pomar District                      1\n",
       "Name: region_1, Length: 1239, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_counts = wine_df.region_1.value_counts()\n",
    "region_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0a5b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Density'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAGdCAYAAADZiZ2PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQPUlEQVR4nO3de1hU57k3/u8wJ8DARKUwEJXgIVFKkkZIECMaTYNimu2pkaYt1e7EV5oYRZod4yGNtW3Q7MRf4uupttbUXxJlt2h0N5iItaLWiRFFJNGmNkGxCCGoMHiAOT3vHzALhhmGYWRmWPD9XNdcgTX3rHlmoeH2fp51PwohhAARERERdVlQoAdAREREJFdMpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEtMpIiIiIi8pAr0AHozm82Gy5cvIywsDAqFItDDISIiIg8IIdDQ0ICYmBgEBbmvOTGR8qHLly9j8ODBgR4GEREReeHSpUsYNGiQ2xgmUj4UFhYGoPkHER4eHuDREBERkSeMRiMGDx4s/R53h4mUD9mn88LDw5lIERERyYwny3K42JyIiIjIS0ykiIiIiLzERIqIiIjIS0ykiIiIiLzERIqIiIjIS0ykiIiIiLzERIqIiIjIS0ykiIiIiLzERIqIiIjIS0ykiIiIiLzERIqIiIjIS0ykiIiIiLzERIooQN4/XoFDX9QEehhERHQbVIEeAFFf9OU317FsdxkAYO+CR3D/oDsDOyAiIvIKK1JEAVBV1yh9febf9QEcCRER3Q4mUkQBcOVGk/R13U1TAEdCRES3g4kUUQBcvdGaPF27aQ7gSIiI6HYwkSIKAMdEihUpIiK5YiJFFABX2iRSdaxIERHJFhMpogBoaLRIX7MiRUQkX0ykiALglskqfX2jyeImkoiIejImUkQB0GhuTaRutfmaiIjkhYkUUQDcNLVWoW6ZbAEcCRER3Q4mUkQBcMvcmjw1siJFRCRbTKSIAqD91J4QIoCjISIibzGRIgqAtlN7VpuA2cpEiohIjphIEQVA27v2XH1PRETywESKKAAazY4LzHnnHhGRPDGRIvIzi9UGk5WJFBFRb8BEisjP2iZNYcGq5mOc2iMikiUmUkR+1nZaTxeiBsCKFBGRXDGRIvIzc8u0nkYZhFCNEgB7SRERyVXAE6mNGzciLi4OwcHBSExMxJEjR9zGFxUVITExEcHBwRg6dCg2b97sFJOfn4/4+HhotVrEx8dj9+7dDs9v2rQJ999/P8LDwxEeHo6UlBTs27fPIWbu3LlQKBQOjzFjxtz+B6Y+z55IqZUKaFTNfwXbr5kiIiJ5CGgilZeXh+zsbCxfvhwlJSVITU1Feno6KioqXMaXl5dj6tSpSE1NRUlJCZYtW4aFCxciPz9fijEYDMjIyEBmZiZKS0uRmZmJ2bNn4/jx41LMoEGDsHr1ahQXF6O4uBiTJk3CtGnT8Pnnnzu835QpU1BVVSU9CgoKfHMhqE+RKlKqIKiVLYmUhYkUEZEcKUQAWyonJydj9OjR2LRpk3Rs1KhRmD59OnJzc53ilyxZgr179+LcuXPSsaysLJSWlsJgMAAAMjIyYDQaHSpMU6ZMQf/+/bFjx44OxzJgwAD893//N5555hkAzRWpuro6fPDBB15/PqPRCJ1Oh/r6eoSHh3t9HupdPr9cjyfWHUVkmBZ3R/TDp+VXsf6HD+J798cEemhERISu/f4OWEXKZDLh5MmTSEtLczielpaGY8eOuXyNwWBwip88eTKKi4thNpvdxnR0TqvVip07d+LGjRtISUlxeO7QoUOIjIzEPffcg3nz5qGmpqZLn5HIFXsXc7UyCFoVK1JERHKmCtQb19bWwmq1IioqyuF4VFQUqqurXb6murraZbzFYkFtbS2io6M7jGl/zrKyMqSkpKCxsRF33HEHdu/ejfj4eOn59PR0PPXUU4iNjUV5eTleeeUVTJo0CSdPnoRWq3U5vqamJjQ1NUnfG43Gzi8E9TmupvbMXCNFRCRLAUuk7BQKhcP3QginY53Ftz/uyTnvvfdenD59GnV1dcjPz8ecOXNQVFQkJVMZGRlSbEJCApKSkhAbG4sPP/wQM2fOdDm23Nxc/PKXv+xw7EQAYLa03rWn4RopIiJZC9jUXkREBJRKpVOlqKamxqmiZKfX613Gq1QqDBw40G1M+3NqNBoMHz4cSUlJyM3NxQMPPIC33367w/FGR0cjNjYW58+f7zBm6dKlqK+vlx6XLl3qMJb6LvsdemqVAmrprj1uWkxEJEcBS6Q0Gg0SExNRWFjocLywsBBjx451+ZqUlBSn+P379yMpKQlqtdptTEfntBNCOEzLtXflyhVcunQJ0dHRHcZotVqppYL9QdSevfqkblOR4tQeEZE8BXRqLycnB5mZmUhKSkJKSgq2bNmCiooKZGVlAWiu8FRWVmL79u0Amu/QW79+PXJycjBv3jwYDAZs3brV4W68RYsWYfz48VizZg2mTZuGPXv24MCBAzh69KgUs2zZMqSnp2Pw4MFoaGjAzp07cejQIXz00UcAgOvXr2PlypWYNWsWoqOjceHCBSxbtgwRERGYMWOGH68Q9UZtF5trVM1TzpzaIyKSp4AmUhkZGbhy5QpWrVqFqqoqJCQkoKCgALGxsQCAqqoqh55ScXFxKCgowOLFi7FhwwbExMRg3bp1mDVrlhQzduxY7Ny5EytWrMArr7yCYcOGIS8vD8nJyVLM119/jczMTFRVVUGn0+H+++/HRx99hMcffxwAoFQqUVZWhu3bt6Ourg7R0dGYOHEi8vLyEBYW5qerQ71V287mrEgREclbQPtI9XbsI0Wu/E/xJbz05zOYNDISQyP64fdHyzF//FAsnToq0EMjIiLIpI8UUV/FLWKIiHoPJlJEftZ2sTm3iCEikjcmUkR+5rBGSsU1UkREcsZEisjPHO7akxabc6kiEZEcMZEi8jP7NF7zFjFsf0BEJGdMpIj8rHWxeRA0KiUALjYnIpIrJlJEfiYtNlcpWJEiIpI5JlJEfsbF5kREvQcTKSI/s29Q3LazOStSRETyxESKyM+kNVIqVqSIiOSOiRSRn7lsyMn2B0REssREisjPWtdItdkixmIN5JCIiMhLTKSI/Kxt+wM1G3ISEckaEykiP5MWm6uCoFVxsTkRkZwxkSLyM7OLNVJcbE5EJE9MpIj8zOTQ2ZwVKSIiOWMiReRn0mLztp3NWZEiIpIlJlJEfta2/QH7SBERyRsTKSI/c9gipmWNlE0AFiZTRESyw0SKyM/srQ7UqtbF5m2PExGRfDCRIvIz+9Re202L2x4nIiL5YCJF5GdtG3KqghTScS44JyKSHyZSRH5mku7aC4JC0WabGCZSRESyw0SKyM9aK1LN1Sj7gnMzp/aIiGSHiRSRn0mLzVsSKPaSIiKSLyZSRH4khIDV1pxI2ddHqVoSKgvv2iMikh0mUkR+ZLG1JkuqoJaKVEtCZbGxIkVEJDdMpIj8yNo2kVI6VqTYR4qISH6YSBH5UdutYJTS1F5LRYprpIiIZIeJFJEfOVSkWhIpdcsUX9tpPyIikgcmUkR+1DZZal+R4sbFRETyw0SKyI/sd+apghRQKBTS14BjtYqIiOSBiRSRH9nvzLNXoZq/5mJzIiK5YiJF5EetPaRa/+qp2P6AiEi2Ap5Ibdy4EXFxcQgODkZiYiKOHDniNr6oqAiJiYkIDg7G0KFDsXnzZqeY/Px8xMfHQ6vVIj4+Hrt373Z4ftOmTbj//vsRHh6O8PBwpKSkYN++fQ4xQgisXLkSMTExCAkJwaOPPorPP//89j8w9Wn2qpOyzWbFajbkJCKSrYAmUnl5ecjOzsby5ctRUlKC1NRUpKeno6KiwmV8eXk5pk6ditTUVJSUlGDZsmVYuHAh8vPzpRiDwYCMjAxkZmaitLQUmZmZmD17No4fPy7FDBo0CKtXr0ZxcTGKi4sxadIkTJs2zSFRev3117F27VqsX78eJ06cgF6vx+OPP46GhgbfXRDq9ewVKbXD1B4XmxMRyZYIoIcfflhkZWU5HBs5cqR4+eWXXca/9NJLYuTIkQ7H5s+fL8aMGSN9P3v2bDFlyhSHmMmTJ4sf/OAHbsfSv39/8fvf/14IIYTNZhN6vV6sXr1aer6xsVHodDqxefPmzj9Yi/r6egFA1NfXe/wa6t0+q6wTsUv+Ih7+TaF07Jl3TojYJX8R7x+/GMCRERGRXVd+fwesImUymXDy5EmkpaU5HE9LS8OxY8dcvsZgMDjFT548GcXFxTCbzW5jOjqn1WrFzp07cePGDaSkpABornxVV1c7nEer1WLChAkdngcAmpqaYDQaHR5EbbXetedijRQrUkREshOwRKq2thZWqxVRUVEOx6OiolBdXe3yNdXV1S7jLRYLamtr3ca0P2dZWRnuuOMOaLVaZGVlYffu3YiPj5fOYX+dp2MDgNzcXOh0OukxePDgDmOpb7L3kVK5mNpjQ04iIvkJ+GJzey8dOyGE07HO4tsf9+Sc9957L06fPo1PPvkEP/vZzzBnzhycPXv2tsa2dOlS1NfXS49Lly51GEt9k32NFBebExH1DqpAvXFERASUSqVThaempsapEmSn1+tdxqtUKgwcONBtTPtzajQaDB8+HACQlJSEEydO4O2338Zvf/tb6PV6AM2VqejoaI/GBjRP/2m1Wncfm/o4+/Sdqk0iZf/azPYHRESyE7CKlEajQWJiIgoLCx2OFxYWYuzYsS5fk5KS4hS/f/9+JCUlQa1Wu43p6Jx2Qgg0NTUBAOLi4qDX6x3OYzKZUFRU1Ol5iNyxuOojxYoUEZFsBawiBQA5OTnIzMxEUlISUlJSsGXLFlRUVCArKwtA81RZZWUltm/fDgDIysrC+vXrkZOTg3nz5sFgMGDr1q3YsWOHdM5FixZh/PjxWLNmDaZNm4Y9e/bgwIEDOHr0qBSzbNkypKenY/DgwWhoaMDOnTtx6NAhfPTRRwCap/Sys7Px2muvYcSIERgxYgRee+01hIaG4oc//KEfrxD1Nq46m9tbIXCxORGR/AQ0kcrIyMCVK1ewatUqVFVVISEhAQUFBYiNjQUAVFVVOfSUiouLQ0FBARYvXowNGzYgJiYG69atw6xZs6SYsWPHYufOnVixYgVeeeUVDBs2DHl5eUhOTpZivv76a2RmZqKqqgo6nQ73338/PvroIzz++ONSzEsvvYRbt27hueeew7Vr15CcnIz9+/cjLCzMD1eGeiuLi4ac9uqUmYvNiYhkRyHsq7Wp2xmNRuh0OtTX1yM8PDzQw6EeYF9ZFX723ik8fPcA/E9Wc7uN1wrOYcvhr/B/xg/FsqmjAjxCIiLqyu/vgN+1R9SXmF3ctSctNufUHhGR7DCRIvIjq4s1UlxsTkQkX0ykiPyotbN5m8Xm9s7mbH9ARCQ7TKSI/MgiTe05tz8wsyJFRCQ7TKSI/Ki1jxTbHxAR9QZMpIj8yGp1XiOllDqbsyJFRCQ3TKSI/MhVRco+tWfl1B4RkewwkSLyI1drpLjYnIhIvphIEfmRtSWRUrtof8DF5kRE8sNEisiP7E03la4Wm7MiRUQkO0ykiPyotSLVpv1BECtSRERyxUSKyI8srraIYfsDIiLZYiJF5Ef2ZEnlYq89K9sfEBHJDhMpIj+S2h9wsTkRUa/ARIrIj6xsf0BE1KswkSLyI7OLTYvtFSkLK1JERLLDRIrIj6w25y1i7F+bWZEiIpIdJlJEfuRy0+IgVqSIiOSKiRSRH9mTpbZrpKRNi5lIERHJDhMpIj9ytUWM/Wsrp/aIiGSHiRSRH7naIoaLzYmI5IuJFJEfWV2skbJ/zcXmRETyw0SKyI9aF5u36SPFihQRkWwxkSLyI4ub9gcWm4AQTKaIiOSEiRSRH7Xetefc/gBorVgREZE8MJEi8iOri6k9ZZvqFDcuJiKSFyZSRH5kdrPYHGi9q4+IiOSBiRSRH9l7RSkd+ki1mdrjgnMiIllhIkXkR/ZESd2us7miJa9iCwQiInlhIkXkR/bF5G0XmwPcb4+ISK6YSBH5kbTYXOmYSEktEJhIERHJChMpIj+S+ki1q0gp2d2ciEiWmEgR+ZG94tS2/QHQuuCc7Q+IiOSFiRSRH1k6mtqzV6TY/oCISFYCnkht3LgRcXFxCA4ORmJiIo4cOeI2vqioCImJiQgODsbQoUOxefNmp5j8/HzEx8dDq9UiPj4eu3fvdng+NzcXDz30EMLCwhAZGYnp06fjiy++cIiZO3cuFAqFw2PMmDG3/4GpT3O1aTHA/faIiOQqoIlUXl4esrOzsXz5cpSUlCA1NRXp6emoqKhwGV9eXo6pU6ciNTUVJSUlWLZsGRYuXIj8/HwpxmAwICMjA5mZmSgtLUVmZiZmz56N48ePSzFFRUV4/vnn8cknn6CwsBAWiwVpaWm4ceOGw/tNmTIFVVVV0qOgoMA3F4L6DHvFqf1de6377bEiRUQkJwoRwF1Sk5OTMXr0aGzatEk6NmrUKEyfPh25ublO8UuWLMHevXtx7tw56VhWVhZKS0thMBgAABkZGTAajdi3b58UM2XKFPTv3x87duxwOY5vvvkGkZGRKCoqwvjx4wE0V6Tq6urwwQcfeP35jEYjdDod6uvrER4e7vV5qPeI/8VHuGmy4shLEzF4QKh0/LE3D+HLb25g5/8ZgzFDBwZwhERE1JXf3wGrSJlMJpw8eRJpaWkOx9PS0nDs2DGXrzEYDE7xkydPRnFxMcxms9uYjs4JAPX19QCAAQMGOBw/dOgQIiMjcc8992DevHmoqalx+5mamppgNBodHkRtddhHilN7RESyFLBEqra2FlarFVFRUQ7Ho6KiUF1d7fI11dXVLuMtFgtqa2vdxnR0TiEEcnJyMG7cOCQkJEjH09PT8d577+HgwYN48803ceLECUyaNAlNTU0dfqbc3FzodDrpMXjw4I4vAPVJFqv79gec2iMikhdVoAegUDj+QhFCOB3rLL798a6cc8GCBThz5gyOHj3qcDwjI0P6OiEhAUlJSYiNjcWHH36ImTNnujzX0qVLkZOTI31vNBqZTJHEZhOwdzdQKR3/DaNiRYqISJYClkhFRERAqVQ6VYpqamqcKkp2er3eZbxKpcLAgQPdxrg65wsvvIC9e/fi8OHDGDRokNvxRkdHIzY2FufPn+8wRqvVQqvVuj0P9V3WNssRnbeIYUWKiEiOAja1p9FokJiYiMLCQofjhYWFGDt2rMvXpKSkOMXv378fSUlJUKvVbmPanlMIgQULFmDXrl04ePAg4uLiOh3vlStXcOnSJURHR3v0+Yjaa1ttaj+1Z79rz8yKFBGRrAS0/UFOTg5+//vf4w9/+APOnTuHxYsXo6KiAllZWQCap8p+8pOfSPFZWVm4ePEicnJycO7cOfzhD3/A1q1b8eKLL0oxixYtwv79+7FmzRr84x//wJo1a3DgwAFkZ2dLMc8//zzeffddvP/++wgLC0N1dTWqq6tx69YtAMD169fx4osvwmAw4MKFCzh06BCefPJJREREYMaMGf65ONTrtK02tW/IKS02Z0WKiEhWArpGKiMjA1euXMGqVatQVVWFhIQEFBQUIDY2FgBQVVXl0FMqLi4OBQUFWLx4MTZs2ICYmBisW7cOs2bNkmLGjh2LnTt3YsWKFXjllVcwbNgw5OXlITk5WYqxt1t49NFHHcazbds2zJ07F0qlEmVlZdi+fTvq6uoQHR2NiRMnIi8vD2FhYT68ItSbOVak2q2RCmJFiohIjgLaR6q3Yx8pauubhiY89JsDAIDy3KkON0DM216MwrNf47UZ9+GHyUMCNUQiIoJM+kgR9TX27WHUSoXTXaT2ipSVU3tERLLCRIrITzraHgZobX/AqT0iInlhIkXkJ60bFjv/tWP7AyIieWIiReQn9u1h2t+x1/YYK1JERPLCRIrIT+zVpvY9pAB2NicikismUkR+Yk+SXK2R4tQeEZE8MZEi8hN3a6SUQVxsTkQkR0ykiPxEmtpzsUZK3XLMYmVFiohITphIEfmJu6k9e3JlX5BORETywESKyE+khpwupvZU0tQeK1JERHLCRIrIT8w2N4vNpak9VqSIiOSEiRSRn9i3f1G77CPVUpHiXXtERLLCRIrIT9yukQpiRYqISI6YSBH5icXdFjH2hpysSBERyQoTKSI/8WSLGFakiIjkhYkUkZ/Y10i57mxur0gxkSIikhMmUkR+Yu9a7nqvPfumxZzaIyKSEyZSRH4ibRGjdNFHipsWExHJEhMpIj9pXWzOTYuJiHoLJlJEfmLfR8/1FjHctJiISI6YSBH5ibRFjMupPVakiIjkiIkUkZ+Y3TTklO7aY0WKiEhWmEgR+Ym9/QHv2iMi6j2YSBH5ibuGnNKmxewjRUQkK0ykiPzEYu14ixgVp/aIiGTJq0SqvLy8u8dB1OvZq02u79rj1B4RkRx5lUgNHz4cEydOxLvvvovGxsbuHhNRryStkXI5tcctYoiI5MirRKq0tBQPPvggfv7zn0Ov12P+/Pn49NNPu3tsRL2K2y1igliRIiKSI68SqYSEBKxduxaVlZXYtm0bqqurMW7cOHz729/G2rVr8c0333T3OIlkzypN7Tn/tVNzixgiIlm6rcXmKpUKM2bMwP/8z/9gzZo1+PLLL/Hiiy9i0KBB+MlPfoKqqqruGieR7Nmn7dRu1kixIScRkbzcViJVXFyM5557DtHR0Vi7di1efPFFfPnllzh48CAqKysxbdq07honkexJW8S4WCNlv2vPbBUQglUpIiK5UHnzorVr12Lbtm344osvMHXqVGzfvh1Tp05FUMsvg7i4OPz2t7/FyJEju3WwRHJmdbdpcZvkymoTLhekExFRz+NVIrVp0yb853/+J376059Cr9e7jBkyZAi2bt16W4Mj6k2khpyu+ki12X/PYhNQKf02LCIiug1eJVKFhYUYMmSIVIGyE0Lg0qVLGDJkCDQaDebMmdMtgyTqDSxu2h+0rVKZrTYEq5lJERHJgVdrpIYNG4ba2lqn41evXkVcXFyXzrVx40bExcUhODgYiYmJOHLkiNv4oqIiJCYmIjg4GEOHDsXmzZudYvLz8xEfHw+tVov4+Hjs3r3b4fnc3Fw89NBDCAsLQ2RkJKZPn44vvvjCIUYIgZUrVyImJgYhISF49NFH8fnnn3fpsxG1ZXG3aXHbihTv3CMikg2vEqmOFsNev34dwcHBHp8nLy8P2dnZWL58OUpKSpCamor09HRUVFS4jC8vL8fUqVORmpqKkpISLFu2DAsXLkR+fr4UYzAYkJGRgczMTJSWliIzMxOzZ8/G8ePHpZiioiI8//zz+OSTT1BYWAiLxYK0tDTcuHFDinn99dexdu1arF+/HidOnIBer8fjjz+OhoYGjz8fUVtW6a495792yiAFFC35lZl37hERyYZCdOEWoZycHADA22+/jXnz5iE0NFR6zmq14vjx41Aqlfj73//u0fmSk5MxevRobNq0STo2atQoTJ8+Hbm5uU7xS5Yswd69e3Hu3DnpWFZWFkpLS2EwGAAAGRkZMBqN2LdvnxQzZcoU9O/fHzt27HA5jm+++QaRkZEoKirC+PHjIYRATEwMsrOzsWTJEgBAU1MToqKisGbNGsyfP9+jz2c0GqHT6VBfX4/w8HCPXkO910/+8CkO//MbvPnUA5iVOMjp+XuW74PJasOxlych5s6QAIyQiIiArv3+7lJFqqSkBCUlJRBCoKysTPq+pKQE//jHP/DAAw/gnXfe8ehcJpMJJ0+eRFpamsPxtLQ0HDt2zOVrDAaDU/zkyZNRXFwMs9nsNqajcwJAfX09AGDAgAEAmitf1dXVDufRarWYMGGC2/M0NTXBaDQ6PIjs3G0R0/Y4p/aIiOSjS4vN//a3vwEAfvrTn+Ltt9++rSpLbW0trFYroqKiHI5HRUWhurra5Wuqq6tdxlssFtTW1iI6OrrDmI7OKYRATk4Oxo0bh4SEBOl97K9rf56LFy92+Jlyc3Pxy1/+ssPnqW+zWDu+a6/5eMs2MZzaIyKSDa/WSG3btq3bpqoUCsd/nQshnI51Ft/+eFfOuWDBApw5c8bltF9Xx7Z06VLU19dLj0uXLnUYS32PxdbxYnOA28QQEcmRxxWpmTNn4p133kF4eDhmzpzpNnbXrl2dni8iIgJKpdKpUlRTU+NUCbLT6/Uu41UqFQYOHOg2xtU5X3jhBezduxeHDx/GoEGta1bsvbGqq6sRHR3t0diA5uk/rVbb4fPUt0lbxHQytceNi4mI5MPjipROp5OqMTqdzu3DExqNBomJiSgsLHQ4XlhYiLFjx7p8TUpKilP8/v37kZSUBLVa7Tam7TmFEFiwYAF27dqFgwcPOrVsiIuLg16vdziPyWRCUVFRh2Mj6ox9jVRHFSn7lJ894SIiop7P44rUtm3bXH59O3JycpCZmYmkpCSkpKRgy5YtqKioQFZWFoDmqbLKykps374dQPMdeuvXr0dOTg7mzZsHg8GArVu3OkzLLVq0COPHj8eaNWswbdo07NmzBwcOHMDRo0elmOeffx7vv/8+9uzZg7CwMKmCpdPpEBISAoVCgezsbLz22msYMWIERowYgddeew2hoaH44Q9/2C2fnfqeztZIqaXF5qxIERHJhVedzW/dugUhhNT+4OLFi9i9ezfi4+Od7phzJyMjA1euXMGqVatQVVWFhIQEFBQUIDY2FgBQVVXl0FMqLi4OBQUFWLx4MTZs2ICYmBisW7cOs2bNkmLGjh2LnTt3YsWKFXjllVcwbNgw5OXlITk5WYqxt1t49NFHHcazbds2zJ07FwDw0ksv4datW3juuedw7do1JCcnY//+/QgLC+vStSKyk7aI6XBqr3XjYiIikocu9ZGyS0tLw8yZM5GVlYW6ujrce++90Gg0qK2txdq1a/Gzn/3MF2OVHfaRorYmvnEI5bU38OesFCTdPcDp+SlvHcY/qhvw/z/zMFJHfCsAIyQiIsCHfaTsTp06hdTUVADAn//8Z+j1ely8eBHbt2/HunXrvDklUa9nX0TOu/aIiHoPrxKpmzdvSlNc+/fvx8yZMxEUFIQxY8a47bNE1JdJW8QoO+gjxbv2iIhkx6tEavjw4fjggw9w6dIlfPzxx9K6qJqaGk5hEXXA7GbTYqB1Dz7etUdEJB9eJVK/+MUv8OKLL+Luu+9GcnIyUlJSADRXpx588MFuHSBRbyFtEdNR+wNWpIiIZMeru/a+//3vY9y4caiqqsIDDzwgHX/ssccwY8aMbhscUW/SetdeR1N7XCNFRCQ3XiVSQHP3b3sHcLuHH374tgdE1Fu19pHqaGqvpY8U99ojIpINrxKpGzduYPXq1fjrX/+Kmpoa2Nr9j/+rr77qlsER9SbWTvbaa53aY0WKiEguvEqknn32WRQVFSEzMxPR0dFuN/Ilomb2SlNnDTnZ2ZyISD68SqT27duHDz/8EI888kh3j4eoV7LZBOw343W0RYxKmtpjRYqISC68umuvf//+GDDAuTMzEbnWNjnqbNNiTu0REcmHV4nUr371K/ziF7/AzZs3u3s8RL2StU0ipe5gao+bFhMRyY9XU3tvvvkmvvzyS0RFReHuu++GWq12eP7UqVPdMjii3sLc5oaMThebc2qPiEg2vEqkpk+f3s3DIOrdrG2m6zpeI8XF5kREcuNVIvXqq6929ziIejX7GimFwt2mxVxsTkQkN16tkQKAuro6/P73v8fSpUtx9epVAM1TepWVld02OKLewtLJ9jBAa/sDbhFDRCQfXlWkzpw5g+9+97vQ6XS4cOEC5s2bhwEDBmD37t24ePEitm/f3t3jJJK11q7mHf/bRepszrv2iIhkw6uKVE5ODubOnYvz588jODhYOp6eno7Dhw932+CIegv7XXueVKS4RQwRkXx4lUidOHEC8+fPdzp+1113obq6+rYHRdTb2JMjZQetDwBuEUNEJEdeJVLBwcEwGo1Ox7/44gt861vfuu1BEfU2FpsnU3vNz1m52JyISDa8SqSmTZuGVatWwWw2AwAUCgUqKirw8ssvY9asWd06QKLeoHWNlCcVKU7tERHJhVeJ1BtvvIFvvvkGkZGRuHXrFiZMmIDhw4cjLCwMv/nNb7p7jESyZ69IddT6AGi7aTErUkREcuHVXXvh4eE4evQo/va3v+HkyZOw2WwYPXo0vvvd73b3+Ih6BWvLGqmOtocB2ty1x8XmRESy0eVEymaz4Z133sGuXbtw4cIFKBQKxMXFQa/XQwgBhaLjXxREfZV9AbknFSkuNiciko8uTe0JIfAf//EfePbZZ1FZWYn77rsP3/72t3Hx4kXMnTsXM2bM8NU4iWTNPl2nVrpZbK5kRYqISG66VJF65513cPjwYfz1r3/FxIkTHZ47ePAgpk+fju3bt+MnP/lJtw6SSO6k9gfuKlJBrEgREclNlypSO3bswLJly5ySKACYNGkSXn75Zbz33nvdNjii3kK6a89NRcp+1x43LSYiko8uJVJnzpzBlClTOnw+PT0dpaWltz0oot7GXpFSu6lIcdNiIiL56VIidfXqVURFRXX4fFRUFK5du3bbgyLqbcxSRYpTe0REvUmXEimr1QqVquNlVUqlEhaL5bYHRdTbSBUpTu0REfUqXVpsLoTA3LlzodVqXT7f1NTULYMi6m0sHrQ/UEubFrMiRUQkF11KpObMmdNpDO/YI3Lm0V57LYmUycKKFBGRXHQpkdq2bZuvxkHUq9mn69x2NmcfKSIi2fFqrz0i6hqzB+0PNOxsTkQkOwFPpDZu3Ii4uDgEBwcjMTERR44ccRtfVFSExMREBAcHY+jQodi8ebNTTH5+PuLj46HVahEfH4/du3c7PH/48GE8+eSTiImJgUKhwAcffOB0jrlz50KhUDg8xowZc1uflfouz9oftCRSnNojIpKNgCZSeXl5yM7OxvLly1FSUoLU1FSkp6ejoqLCZXx5eTmmTp2K1NRUlJSUYNmyZVi4cCHy8/OlGIPBgIyMDGRmZqK0tBSZmZmYPXs2jh8/LsXcuHEDDzzwANavX+92fFOmTEFVVZX0KCgo6J4PTn2OJ+0P1Krmv45NvGuPiEg2urxpcXdau3YtnnnmGTz77LMAgLfeegsff/wxNm3ahNzcXKf4zZs3Y8iQIXjrrbcAAKNGjUJxcTHeeOMNzJo1SzrH448/jqVLlwIAli5diqKiIrz11lvYsWMHgObGoenp6Z2OT6vVQq/Xd8dHpT7OarPftdf5Xntmq40bgBMRyUTAKlImkwknT55EWlqaw/G0tDQcO3bM5WsMBoNT/OTJk1FcXAyz2ew2pqNzunPo0CFERkbinnvuwbx581BTU+M2vqmpCUaj0eFBBHi22Ny+RkqI1sSLiIh6toAlUrW1tbBarU6d0qOiolBdXe3yNdXV1S7jLRYLamtr3cZ0dM6OpKen47333sPBgwfx5ptv4sSJE5g0aZLbXlm5ubnQ6XTSY/DgwV16T+q9zB60P9CoWp/jgnMiInkI6NQeAKfpi86mNFzFtz/e1XO6kpGRIX2dkJCApKQkxMbG4sMPP8TMmTNdvmbp0qXIycmRvjcajUymCICn7Q9aEymT1YYQKH0+LiIiuj0BS6QiIiKgVCqdKkU1NTUd7uen1+tdxqtUKgwcONBtjLs9Aj0RHR2N2NhYnD9/vsMYrVbbYdd36ts822uv9TkzF5wTEclCwKb2NBoNEhMTUVhY6HC8sLAQY8eOdfmalJQUp/j9+/cjKSkJarXabUxH5/TUlStXcOnSJURHR9/Weahv8mSxuUKhkNZJsbs5EZE8BHRqLycnB5mZmUhKSkJKSgq2bNmCiooKZGVlAWieKqusrMT27dsBAFlZWVi/fj1ycnIwb948GAwGbN26VbobDwAWLVqE8ePHY82aNZg2bRr27NmDAwcO4OjRo1LM9evX8a9//Uv6vry8HKdPn8aAAQMwZMgQXL9+HStXrsSsWbMQHR2NCxcuYNmyZYiIiMCMGTP8dHWoN/GkjxTQPPVnsrIiRUQkFwFNpDIyMnDlyhWsWrUKVVVVSEhIQEFBAWJjYwEAVVVVDj2l4uLiUFBQgMWLF2PDhg2IiYnBunXrpNYHADB27Fjs3LkTK1aswCuvvIJhw4YhLy8PycnJUkxxcTEmTpwofW9f1zRnzhy88847UCqVKCsrw/bt21FXV4fo6GhMnDgReXl5CAsL8/VloV7Ik87mQPOC8xsmKxMpIiKZUAj7am3qdkajETqdDvX19QgPDw/0cCiAsneW4IPTl7HiiVF4NnVoh3EP/+YAahqaULAwFfEx/DNDRBQIXfn9HfAtYoj6gtb2B51N7dn322NFiohIDphIEfmBtWVqT+nB1B7Q3P6AiIh6PiZSRH7QlcXmADcuJiKSCyZSRH7g6WJz+9QeK1JERPLARIrID6SKlJuGnEDr1B63iCEikgcmUkR+IFWk3DTkBLjYnIhIbphIEfmBfa89d1vEAJA6mzORIiKSByZSRH5g9bj9QfPzTVxsTkQkC0ykiPygq4vNWZEiIpIHJlJEfuBx+wP7YnNWpIiIZIGJFJEfWDysSGmVvGuPiEhOmEgR+YHZ5tlic/aRIiKSFyZSRH5gtXq42FzV/LyJU3tERLLARIrID1o3LeZicyKi3oSJFJEf2PtIddrZnIkUEZGsMJEi8gNPF5tzixgiInlhIkXkB9Ji804bcnKxORGRnDCRIvIDqbO5h3ftsY8UEZE8MJEi8jEhRBc2LW65a48VKSIiWWAiReRj9moU4MFicxUXmxMRyQkTKSIfs7RJpDzda89k4WJzIiI5YCJF5GNtq0udLTZn+wMiInlhIkXkY5Y2rQw672zORIqISE6YSBH5WNupPWWnFSluEUNEJCdMpIh8zGJr7WquUHi22Jx37RERyQMTKSIfs3jY+gAAtColAKDJzESKiEgOmEgR+Zh9vVNnzTgBIFjd/FeyyWL16ZiIiKh7MJEi8jF7M05NJ60PgDYVKa6RIiKSBSZSRD5mr0ipPUqk7BUpJlJERHLARIrIx+wLx+0Lyd2xV6QazZzaIyKSAyZSRD5m34C4s+1hAECrZkWKiEhOmEgR+Zh9jVRXpvasNgELWyAQEfV4TKSIfMzsxdQewKoUEZEcMJEi8rEmi+eLzdsmW0ykiIh6voAnUhs3bkRcXByCg4ORmJiII0eOuI0vKipCYmIigoODMXToUGzevNkpJj8/H/Hx8dBqtYiPj8fu3bsdnj98+DCefPJJxMTEQKFQ4IMPPnA6hxACK1euRExMDEJCQvDoo4/i888/v63PSn1T6117na+RUgYppDj2kiIi6vkCmkjl5eUhOzsby5cvR0lJCVJTU5Geno6KigqX8eXl5Zg6dSpSU1NRUlKCZcuWYeHChcjPz5diDAYDMjIykJmZidLSUmRmZmL27Nk4fvy4FHPjxg088MADWL9+fYdje/3117F27VqsX78eJ06cgF6vx+OPP46GhobuuwDUJ3Sl/QEABLO7ORGRbCiEEKLzMN9ITk7G6NGjsWnTJunYqFGjMH36dOTm5jrFL1myBHv37sW5c+ekY1lZWSgtLYXBYAAAZGRkwGg0Yt++fVLMlClT0L9/f+zYscPpnAqFArt378b06dOlY0IIxMTEIDs7G0uWLAEANDU1ISoqCmvWrMH8+fM9+nxGoxE6nQ719fUIDw/36DXU++SdqMCS/DJ8d1Qkfj/noU7jk35diNrrJnycPR736sP8MEIiImqrK7+/A1aRMplMOHnyJNLS0hyOp6Wl4dixYy5fYzAYnOInT56M4uJimM1mtzEdndOV8vJyVFdXO5xHq9ViwoQJbs/T1NQEo9Ho8CAydeGuPYC9pIiI5CRgiVRtbS2sViuioqIcjkdFRaG6utrla6qrq13GWywW1NbWuo3p6JwdvY/9dV05T25uLnQ6nfQYPHiwx+9JvZe5C4vNAXY3JyKSk4AvNlcoHBfgCiGcjnUW3/54V8/ZXWNbunQp6uvrpcelS5e6/J7U+3R1jZRGxY2LiYjkQhWoN46IiIBSqXSq8NTU1DhVguz0er3LeJVKhYEDB7qN6eicHb0P0FyZio6O9vg8Wq0WWq3W4/ehvsFksfeR8iyZ16q52JyISC4CVpHSaDRITExEYWGhw/HCwkKMHTvW5WtSUlKc4vfv34+kpCSo1Wq3MR2d05W4uDjo9XqH85hMJhQVFXXpPERA1ytSnNojIpKPgFWkACAnJweZmZlISkpCSkoKtmzZgoqKCmRlZQFoniqrrKzE9u3bATTfobd+/Xrk5ORg3rx5MBgM2Lp1q8PdeIsWLcL48eOxZs0aTJs2DXv27MGBAwdw9OhRKeb69ev417/+JX1fXl6O06dPY8CAARgyZAgUCgWys7Px2muvYcSIERgxYgRee+01hIaG4oc//KGfrg71Fl1fbM6pPSIiuQhoIpWRkYErV65g1apVqKqqQkJCAgoKChAbGwsAqKqqcugpFRcXh4KCAixevBgbNmxATEwM1q1bh1mzZkkxY8eOxc6dO7FixQq88sorGDZsGPLy8pCcnCzFFBcXY+LEidL3OTk5AIA5c+bgnXfeAQC89NJLuHXrFp577jlcu3YNycnJ2L9/P8LCeDs6dU2X+0jZp/ZYkSIi6vEC2keqt2MfKQKAX+z5DNsNF7HwsRHIefyeTuMXvH8KfzlThZVPxmPuI3F+GCEREbUliz5SRH2FtGmxB1vEAG36SLEiRUTU4zGRIvIxk6WLa6TULWukeNceEVGPx0SKyMe8v2uPi82JiHo6JlJEPmbvI6VWdW2LGC42JyLq+ZhIEflY19dIsSJFRCQXTKSIfMzU1ak9rpEiIpINJlJEPiZVpDi1R0TU6zCRIvIxcxc7mwe3VKRumTm1R0TU0zGRIvKx1jVSnv11C9U0V6RumZhIERH1dEykiHxMumvP40SqeeemmyaLz8ZERETdg4kUkY+1Ljb37K49e0XqJitSREQ9HhMpIh+TGnJ6uNiciRQRkXwwkSLyMXPLFjGer5GyT+0xkSIi6umYSBH5WFe3iGmtSHGNFBFRT8dEisjHTF3sIxViv2vPbIUQwmfjIiKi28dEisjHzF1cbN6vZWpPCKCR3c2JiHo0JlJEPmZvyOnpGqkQtVL6+gan94iIejQmUkQ+ZLUJWG1d62weFKSQkik25SQi6tmYSBH5kH1aD/C8/QHQuuCcFSkiop6NiRSRD7XdeNjTqT2gdcE5WyAQEfVsTKSIfKipZePhIIXni82B1gXnnNojIurZmEgR+ZD9rrtgtRIKheeJlL0idaOJU3tERD0ZEykiH2qyNFeUtF1YHwW0rpG6ZWZFioioJ2MiReRDbStSXWHfJuZGExMpIqKejIkUkQ81tlSkup5IcZsYIiI5YCJF5ENNLRWprk7t9dOyjxQRkRwwkSLyocaWNU7aLlakQtQtU3tMpIiIejQmUkQ+JE3teVmR4tQeEVHPxkSKyIekqb0uVqTCgpsrUsZb5m4fExERdR8mUkQ+5G1FSheiBgAYG1mRIiLqyZhIEfmQt+0P7IlUPStSREQ9GhMpIh+SFpt3sSIVHsxEiohIDphIEfmQfdPirlakwu1Te0ykiIh6NCZSRD5k37Q4WO3dGilWpIiIeraAJ1IbN25EXFwcgoODkZiYiCNHjriNLyoqQmJiIoKDgzF06FBs3rzZKSY/Px/x8fHQarWIj4/H7t27u/y+c+fOhUKhcHiMGTPm9j4s9TmtU3veVaSaLDbpHERE1PMENJHKy8tDdnY2li9fjpKSEqSmpiI9PR0VFRUu48vLyzF16lSkpqaipKQEy5Ytw8KFC5Gfny/FGAwGZGRkIDMzE6WlpcjMzMTs2bNx/PjxLr/vlClTUFVVJT0KCgp8cyGo12qd2uvaX7UwrQoKRfPXnN4jIuq5FEIIEag3T05OxujRo7Fp0ybp2KhRozB9+nTk5uY6xS9ZsgR79+7FuXPnpGNZWVkoLS2FwWAAAGRkZMBoNGLfvn1SzJQpU9C/f3/s2LHD4/edO3cu6urq8MEHH3j9+YxGI3Q6Herr6xEeHu71eUi+sneW4IPTl7HiiVF4NnVol177wC/3o/6WGQdyxmN4ZJiPRkhERO115fd3wCpSJpMJJ0+eRFpamsPxtLQ0HDt2zOVrDAaDU/zkyZNRXFwMs9nsNsZ+zq6876FDhxAZGYl77rkH8+bNQ01NjdvP1NTUBKPR6PCgvq3Ry732ACA8pLkpJ9dJERH1XAFLpGpra2G1WhEVFeVwPCoqCtXV1S5fU11d7TLeYrGgtrbWbYz9nJ6+b3p6Ot577z0cPHgQb775Jk6cOIFJkyahqampw8+Um5sLnU4nPQYPHtzJVaDersni3V57ABecExHJgSrQA1DYF4K0EEI4Hessvv1xT87ZWUxGRob0dUJCApKSkhAbG4sPP/wQM2fOdDm2pUuXIicnR/reaDQymerjvG3ICbTpbn6L3c2JiHqqgCVSERERUCqVTtWnmpoap2qRnV6vdxmvUqkwcOBAtzH2c3rzvgAQHR2N2NhYnD9/vsMYrVYLrVbb4fPU99i3iPFqao9NOYmIeryATe1pNBokJiaisLDQ4XhhYSHGjh3r8jUpKSlO8fv370dSUhLUarXbGPs5vXlfALhy5QouXbqE6Ohozz4gEVo3LfamInVnaPOf6Ws3Td06JiIi6j4BndrLyclBZmYmkpKSkJKSgi1btqCiogJZWVkAmqfKKisrsX37dgDNd+itX78eOTk5mDdvHgwGA7Zu3SrdjQcAixYtwvjx47FmzRpMmzYNe/bswYEDB3D06FGP3/f69etYuXIlZs2ahejoaFy4cAHLli1DREQEZsyY4ccrRHLn7abFABBxR3N185uGjtflERFRYAU0kcrIyMCVK1ewatUqVFVVISEhAQUFBYiNjQUAVFVVOfR2iouLQ0FBARYvXowNGzYgJiYG69atw6xZs6SYsWPHYufOnVixYgVeeeUVDBs2DHl5eUhOTvb4fZVKJcrKyrB9+3bU1dUhOjoaEydORF5eHsLCeBs6ec5ekfJmsXlkGBMpIqKeLqB9pHo79pGipF8Xova6CR9lp2Kkvmt/Bj76rBpZ757EdwbfiQ+ef8RHIyQiovZk0UeKqC9o7SPlRUUqnBUpIqKejokUkY8IIXDD1Ny6oJ/m9qb2WDgmIuqZmEgR+Uij2QZ7/tNP2/XliN9qSaRMVhvqbrIFAhFRT8REishH7NUoAAjxYrG5VqWUWiDUcHqPiKhHYiJF5CM3m5pbH4RqlAgK6rhbvzvfammBUNPQ2G3jIiKi7sNEishH7BWpUI33XUbsC86/NrIiRUTUEzGRIvKRm/aF5tquT+vZDe4fCgCouHqzW8ZERETdi4kUkY/ckKb2vK9IxQ7sBwC4UHujW8ZERETdi4kUkY/caPK+9YFdXERzRerCFSZSREQ9ERMpIh+5YWqpSHnR+sDu7ojmilR57Q32kiIi6oGYSBH5iL0idcdtrJGKHdCcSDU0WnCNvaSIiHocJlJEPmK81Zz4hGnVXp8jRKNEtC4YAFBee71bxkVERN2HiRSRjzS0VKTCQ7yf2gOA4ZF3AADOVjXc9piIiKh7MZEi8pGGxpaKVLD3FSkA+M7gOwEAZy7V3eaIiIiouzGRIvIR462WilTw7VWk7h90JwCg9N91tzkiIiLqbkykiHzE2E0VqQcG6QAA52uu43qTpZNoIiLyJyZSRD5ibLSvkbq9RCoyPBh33RkCIYDiC1e7Y2hERNRNmEgR+UjrGqnbm9oDgPH3RAAA/vaPmts+FxERdR8mUkQ+UtfS96l/qOa2zzXx3kgAwMEvatiYk4ioB2EiReQDVpvAtZsmAED/frc3tQcAjwyPgEYVhEtXb6Gssv62z0dERN2DiRSRD9TfMsNeOOqOilQ/rQpTvq0HAOw8cem2z0dERN2DiRSRD1y90VyNCg9WQa3snr9mP3h4MABgT0kl6lqqXUREFFhMpIh8wD6tN6Df7Vej7FKGDsSo6HDcMFmx5fBX3XZeIiLyHhMpIh+4cr0JQPcmUgqFAou/OwIAsPVoOcprb3TbuYmIyDtMpIh8oLq+EQAQFR7cred9PD4K44ZHoMliw5L8M7DZeAcfEVEgMZEi8oEqo28SKYVCgdyZ9yFUo8Sn5Vfx9l/Pd+v5iYioa5hIEfnA1y0VKb2uexMpABg8IBSrpiUAAN7+63nsOV3Z7e9BRESeYSJF5ANV9kSqmytSdt9PHIRnxsUBAHL+pxQFZVU+eR8iInKPiRSRD1y8chMAMGRgqM/eY9nUUZg5+i5YbQIv7CjBn4rZX4qIyN+YSBF1s1smK6pb1kjFDezns/dRBinw399/ADMfbE6m/uvPZ5C77xysXIBOROQ3TKSIupm9LYEuRI3+3dj+wBVlkAJvPPUAFk4aDgD4bdFX+Ok7J1Db0n6BiIh8i4kUUTf77HLzXnijosP88n5BQQrkpN2Lt3/wHWhVQTj8z28w9e0jMHx5xS/vT0TUlzGRIupmZ/5dBwC4f9Cdfn3fad+5C3sWPILhkXegpqEJP/r9J/j/Cv8Js9Xm13EQEfUlAU+kNm7ciLi4OAQHByMxMRFHjhxxG19UVITExEQEBwdj6NCh2Lx5s1NMfn4+4uPjodVqER8fj927d3f5fYUQWLlyJWJiYhASEoJHH30Un3/++e19WOoTjp6vBQCMHtLf7+89Uh+OvQsewVOJg2ATze0Rpr59BH85cxlNFqsUZ7baUF3fiM8q63H+6wZcb7L4faxERL2BKpBvnpeXh+zsbGzcuBGPPPIIfvvb3yI9PR1nz57FkCFDnOLLy8sxdepUzJs3D++++y7+/ve/47nnnsO3vvUtzJo1CwBgMBiQkZGBX/3qV5gxYwZ2796N2bNn4+jRo0hOTvb4fV9//XWsXbsW77zzDu655x78+te/xuOPP44vvvgCYWH+mbIh+Sn7dz0uXLkJjTII40ZEBGQMoRoV/vupBzBuRAR++b9ncb7mOha8XwJlkALfukOLW2Yr6m+ZHV6jUAD3RoXhobsH4KG4AXj47gEd9sAyW22oqmvEpWs3UXH1Ji5dvYkr102ICNNgaMQdGBUdjmGR/aBVKf3xcYmIAkohhAjYLT7JyckYPXo0Nm3aJB0bNWoUpk+fjtzcXKf4JUuWYO/evTh37px0LCsrC6WlpTAYDACAjIwMGI1G7Nu3T4qZMmUK+vfvjx07dnj0vkIIxMTEIDs7G0uWLAEANDU1ISoqCmvWrMH8+fM9+nxGoxE6nQ719fUIDw/vwpUhOTJZbHjmjydw5Hwtpn0nBm//4MFADwl1N03YerQceScuoabBcQG6MkiBAf00MFlsTokVAPTTKBEZHgyNMgjKIAUsNhuu3jDh6g0TOrsxUBWkwLBv3YFR0WG4Rx+GULUSVtF8jRrNVjRarGg0WdFotjV/bbZCpQxCdHgwYu4MwaD+IRg8IBR39Q/BHRoVgoIU3XlZAsZksaHupgnXbppRd9OEultmqIIUiAoPhl4XjIH9NFAoesdnJZKzrvz+DlhFymQy4eTJk3j55ZcdjqelpeHYsWMuX2MwGJCWluZwbPLkydi6dSvMZjPUajUMBgMWL17sFPPWW295/L7l5eWorq52eC+tVosJEybg2LFjHSZSTU1NaGpq/WVlNBrdXAHvHT1fiwPnvu7weVe5cfsj7UNEuwhX6XVn52gf4fQeLs/ZyWs6ec/2r3f1IudzCLfPezYOxyM2IXC6og6X6xuhUQVh4WMjXJzV/+4M1eDnafci5/F7UG1sxDcNTQjVKDGgnxZ3hqilBKWmoREnL1zDpxeu4sSFqzh72YgbJmuHGyNrVUEY1D8EQwaEYvCAUETcoUVNQyPOf30d56qMMDZa8MXXDfji64Zu+RwaZRCC1UEIVisRolEiWKVEsEaJEHUQQtTK5uPq5mMaZZD08xFo/VkKCAjR+rNsPi6kr9vHAYBVCJgsNpgsNpitNpiszV+brM3HhRDSe4domv+rVQXBZLXhlsmKmyYrjI1m1N0049pNE26aWqdXXX5OVRDuujMEMXcGQxeilj6n2kUi6WnCJYSQroP9s9laPrv9c7e9NvbvIX0vYGvztf2yNVmsaLLY0GS2tX5tsUGhALSq5usQrA6CVqV0+q8ySOHwd8jxZ9L697r1e8fn0f55D15ntdl/fgImqw3mdj9TlVLR8nNUIdT+89QooWp37dt+19HPgLmwf40bHoHHRkUF7P0DlkjV1tbCarUiKsrxw0dFRaG6utrla6qrq13GWywW1NbWIjo6usMY+zk9eV/7f13FXLx4scPPlJubi1/+8pcdPt9dzlTW4Z1jF3z+PtR1EXdo8fr378Owb90R6KE4UCgUiNaFIFoX4vL5yLBgpN8XjfT7ogEAjWYrquobUWNshMUmYLEJKBXNFayIOzSIuEPbYZVICIGq+kb8o9qIc1UN+FfNdZitNgQpFFArgxCiCWpOENRKKTkKVivRZLGhqu4WLtffwqWrt/Dvazdx7WZzpczU8gvP2Cj/tVxBipbWGKEa3BmqhslqQ3V9E2qvN8FksaG89kaHCSwROQtRK/tmImXXPqMXQrj9l5ar+PbHPTlnd8W0tXTpUuTk5EjfG41GDB48uMN4b40e0h8LJg53OOZqWE6HXAS1P9I+ROF8FhcxLt67fYwH/0Trjvd2fR3a/1w7HYrznwWXMY7fD+ofikeGD0SoJuB/rW5bsFqJuIh+iIvoekNRhUKBmDtDEHNnCCaNvL3/uTVXdSxobJkSvGWyosnSPCV4y2TFLXPztGCj2f51c3VBoWjzM1M0/wmw/7wUULT5us1xh/+HNMcFKZqrRBpVENTKIGhb/qtRBkGtCkKQAs1jMTdPVdrHo1YGIbSlohEeosadLYlT/1ANwoJdT1U2Waz4ur4Jl+tv4XLdLTQ0Wlo+mw1Wm+Odl55VUYX0WRXtrkPb4wpF62cPUrQ73vZaObwe0KpbK0zN1SclNKogCNGciDe1/Mzs/7V/3WS2SlPDbf8Otf15tf2+7c/N8ft2zzv9/9vxdWplcyJv/1lqVEHQtBxTK4NgFaL5z5TJiptmK26ZLLhpsjpOY7uoorW/9i6r5ORTyXEDA/r+Afs/fkREBJRKpVP1qaamxqkSZKfX613Gq1QqDBw40G2M/ZyevK9erwfQXJmKjo72aGxA8/SfVqvt8PnuMmboQIwZGtg/OET+YJ9e6Qu0KiWGDAz16bZCRNT9Atb+QKPRIDExEYWFhQ7HCwsLMXbsWJevSUlJcYrfv38/kpKSoFar3cbYz+nJ+8bFxUGv1zvEmEwmFBUVdTg2IiIi6oNEAO3cuVOo1WqxdetWcfbsWZGdnS369esnLly4IIQQ4uWXXxaZmZlS/FdffSVCQ0PF4sWLxdmzZ8XWrVuFWq0Wf/7zn6WYv//970KpVIrVq1eLc+fOidWrVwuVSiU++eQTj99XCCFWr14tdDqd2LVrlygrKxNPP/20iI6OFkaj0ePPV19fLwCI+vr627lMRERE5Edd+f0d0ERKCCE2bNggYmNjhUajEaNHjxZFRUXSc3PmzBETJkxwiD906JB48MEHhUajEXfffbfYtGmT0zn/9Kc/iXvvvVeo1WoxcuRIkZ+f36X3FUIIm80mXn31VaHX64VWqxXjx48XZWVlXfpsTKSIiIjkpyu/vwPaR6q3Yx8pIiIi+enK7++AbxFDREREJFdMpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEuqQA+gN7M3jTcajQEeCREREXnK/nvbk81fmEj5UENDAwBg8ODBAR4JERERdVVDQwN0Op3bGO6150M2mw2XL19GWFgYFApFoIfjV0ajEYMHD8alS5e4z6ALvD7u8fp0jtfIPV4f93h93BNCoKGhATExMQgKcr8KihUpHwoKCsKgQYMCPYyACg8P519SN3h93OP16RyvkXu8Pu7x+nSss0qUHRebExEREXmJiRQRERGRl5hIkU9otVq8+uqr0Gq1gR5Kj8Tr4x6vT+d4jdzj9XGP16f7cLE5ERERkZdYkSIiIiLyEhMpIiIiIi8xkSIiIiLyEhMpIiIiIi8xkSKPXbhwAc888wzi4uIQEhKCYcOG4dVXX4XJZHKIq6iowJNPPol+/fohIiICCxcudIopKyvDhAkTEBISgrvuugurVq1y2tOoqKgIiYmJCA4OxtChQ7F582aff0Z/2bhxI+Li4hAcHIzExEQcOXIk0EPqdrm5uXjooYcQFhaGyMhITJ8+HV988YVDjBACK1euRExMDEJCQvDoo4/i888/d4hpamrCCy+8gIiICPTr1w//8R//gX//+98OMdeuXUNmZiZ0Oh10Oh0yMzNRV1fn64/YrXJzc6FQKJCdnS0d6+vXp7KyEj/+8Y8xcOBAhIaG4jvf+Q5OnjwpPd+Xr4/FYsGKFSuk/x8PHToUq1atgs1mk2L68vXxK0HkoX379om5c+eKjz/+WHz55Zdiz549IjIyUvz85z+XYiwWi0hISBATJ04Up06dEoWFhSImJkYsWLBAiqmvrxdRUVHiBz/4gSgrKxP5+fkiLCxMvPHGG1LMV199JUJDQ8WiRYvE2bNnxe9+9zuhVqvFn//8Z79+Zl/YuXOnUKvV4ne/+504e/asWLRokejXr5+4ePFioIfWrSZPniy2bdsmPvvsM3H69GnxxBNPiCFDhojr169LMatXrxZhYWEiPz9flJWViYyMDBEdHS2MRqMUk5WVJe666y5RWFgoTp06JSZOnCgeeOABYbFYpJgpU6aIhIQEcezYMXHs2DGRkJAgvve97/n1896OTz/9VNx9993i/vvvF4sWLZKO9+Xrc/XqVREbGyvmzp0rjh8/LsrLy8WBAwfEv/71LymmL1+fX//612LgwIHiL3/5iygvLxd/+tOfxB133CHeeustKaYvXx9/YiJFt+X1118XcXFx0vcFBQUiKChIVFZWSsd27NghtFqtqK+vF0IIsXHjRqHT6URjY6MUk5ubK2JiYoTNZhNCCPHSSy+JkSNHOrzX/PnzxZgxY3z5cfzi4YcfFllZWQ7HRo4cKV5++eUAjcg/ampqBABRVFQkhBDCZrMJvV4vVq9eLcU0NjYKnU4nNm/eLIQQoq6uTqjVarFz504pprKyUgQFBYmPPvpICCHE2bNnBQDxySefSDEGg0EAEP/4xz/88dFuS0NDgxgxYoQoLCwUEyZMkBKpvn59lixZIsaNG9fh8339+jzxxBPiP//zPx2OzZw5U/z4xz8WQvD6+BOn9ui21NfXY8CAAdL3BoMBCQkJiImJkY5NnjwZTU1NUkneYDBgwoQJDo3gJk+ejMuXL+PChQtSTFpamsN7TZ48GcXFxTCbzT78RL5lMplw8uRJp8+WlpaGY8eOBWhU/lFfXw8A0p+X8vJyVFdXO1wLrVaLCRMmSNfi5MmTMJvNDjExMTFISEiQYgwGA3Q6HZKTk6WYMWPGQKfTyeKaPv/883jiiSfw3e9+1+F4X78+e/fuRVJSEp566ilERkbiwQcfxO9+9zvp+b5+fcaNG4e//vWv+Oc//wkAKC0txdGjRzF16lQAvD7+xESKvPbll1/i//7f/4usrCzpWHV1NaKiohzi+vfvD41Gg+rq6g5j7N93FmOxWFBbW9vtn8VfamtrYbVaXX42+2fvjYQQyMnJwbhx45CQkACg9Wft7lpUV1dDo9Ggf//+bmMiIyOd3jMyMrLHX9OdO3fi1KlTyM3NdXqur1+fr776Cps2bcKIESPw8ccfIysrCwsXLsT27dsB8PosWbIETz/9NEaOHAm1Wo0HH3wQ2dnZePrppwHw+vgTEynCypUroVAo3D6Ki4sdXnP58mVMmTIFTz31FJ599lmH5xQKhdN7CCEcjrePES0LzbsaI1euPltv+FwdWbBgAc6cOYMdO3Y4PefNtejsz5On5wmkS5cuYdGiRXj33XcRHBzcYVxfvT42mw2jR4/Ga6+9hgcffBDz58/HvHnzsGnTJoe4vnp98vLy8O677+L999/HqVOn8Mc//hFvvPEG/vjHPzrE9dXr409MpAgLFizAuXPn3D7sVQSgOYmaOHEiUlJSsGXLFodz6fV6p3+lXLt2DWazWfqXkauYmpoaAOg0RqVSYeDAgd3zwQMgIiICSqXS5Wdr/y/H3uKFF17A3r178be//Q2DBg2Sjuv1egBwey30ej1MJhOuXbvmNubrr792et9vvvmmR1/TkydPoqamBomJiVCpVFCpVCgqKsK6deugUqmcqrR2feX6REdHIz4+3uHYqFGjUFFRAYB/fv7rv/4LL7/8Mn7wgx/gvvvuQ2ZmJhYvXixVN/v69fEnJlKEiIgIjBw50u3D/i/myspKPProoxg9ejS2bduGoCDHP0IpKSn47LPPUFVVJR3bv38/tFotEhMTpZjDhw87tETYv38/YmJicPfdd0sxhYWFDufev38/kpKSoFarfXEZ/EKj0SAxMdHpsxUWFmLs2LEBGpVvCCGwYMEC7Nq1CwcPHkRcXJzD83FxcdDr9Q7XwmQyoaioSLoWiYmJUKvVDjFVVVX47LPPpJiUlBTU19fj008/lWKOHz+O+vr6Hn1NH3vsMZSVleH06dPSIykpCT/60Y9w+vRpDB06tE9fn0ceecSpXcY///lPxMbGAuCfn5s3bzr9/1epVErtD/r69fErf69uJ/mqrKwUw4cPF5MmTRL//ve/RVVVlfSws7c/eOyxx8SpU6fEgQMHxKBBgxzaH9TV1YmoqCjx9NNPi7KyMrFr1y4RHh7usv3B4sWLxdmzZ8XWrVt7XfuDrVu3irNnz4rs7GzRr18/ceHChUAPrVv97Gc/EzqdThw6dMjhz8rNmzelmNWrVwudTid27dolysrKxNNPP+3y9uxBgwaJAwcOiFOnTolJkya5vD37/vvvFwaDQRgMBnHffffJ8vbstnftCdG3r8+nn34qVCqV+M1vfiPOnz8v3nvvPREaGireffddKaYvX585c+aIu+66S2p/sGvXLhERESFeeuklKaYvXx9/YiJFHtu2bZsA4PLR1sWLF8UTTzwhQkJCxIABA8SCBQscWh0IIcSZM2dEamqq0Gq1Qq/Xi5UrV0qtD+wOHTokHnzwQaHRaMTdd98tNm3a5PPP6C8bNmwQsbGxQqPRiNGjR0stAXqTjv6sbNu2TYqx2Wzi1VdfFXq9Xmi1WjF+/HhRVlbmcJ5bt26JBQsWiAEDBoiQkBDxve99T1RUVDjEXLlyRfzoRz8SYWFhIiwsTPzoRz8S165d88On7F7tE6m+fn3+93//VyQkJAitVitGjhwptmzZ4vB8X74+RqNRLFq0SAwZMkQEBweLoUOHiuXLl4umpiYppi9fH39SCNGunTQREREReYRrpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEtMpIiIiIi8xESKiIiIyEv/DzLm3kpgxnNuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e3f272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1239.000000\n",
       "mean      102.202583\n",
       "std       366.482829\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%        12.000000\n",
       "75%        58.000000\n",
       "max      6246.000000\n",
       "Name: region_1, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3d9dc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monterey County',\n",
       " 'Barossa Valley',\n",
       " 'South Eastern Australia',\n",
       " 'Margaux',\n",
       " 'Amador County',\n",
       " 'Rías Baixas',\n",
       " 'Mendocino',\n",
       " 'Dundee Hills',\n",
       " 'Mendocino County',\n",
       " 'Colli Orientali del Friuli',\n",
       " 'South Australia',\n",
       " 'Oregon',\n",
       " 'Oakville',\n",
       " 'Sierra Foothills',\n",
       " 'Franciacorta',\n",
       " 'Haut-Médoc',\n",
       " 'Conegliano Valdobbiadene Prosecco Superiore',\n",
       " 'Virginia',\n",
       " 'Livermore Valley',\n",
       " 'Bordeaux Blanc',\n",
       " 'Wahluke Slope',\n",
       " 'Navarra',\n",
       " 'Rueda',\n",
       " 'Lake County',\n",
       " 'Bolgheri',\n",
       " \"Barbera d'Alba\",\n",
       " 'Pauillac',\n",
       " 'Bordeaux',\n",
       " 'Barossa',\n",
       " 'North Coast',\n",
       " 'Médoc',\n",
       " 'Priorat',\n",
       " 'Vino de la Tierra de Castilla',\n",
       " 'Pomerol',\n",
       " \"Vin de Pays d'Oc\",\n",
       " 'Uco Valley',\n",
       " 'Valpolicella Superiore Ripasso',\n",
       " 'Toro',\n",
       " 'Bourgogne',\n",
       " 'Arroyo Seco',\n",
       " 'Sauternes',\n",
       " 'Luján de Cuyo',\n",
       " 'Rogue Valley',\n",
       " \"Barbera d'Asti\",\n",
       " 'Howell Mountain',\n",
       " 'Meursault',\n",
       " 'Chehalem Mountains',\n",
       " 'Rosso di Montalcino',\n",
       " 'Clare Valley',\n",
       " 'El Dorado',\n",
       " 'Valpolicella Classico Superiore Ripasso',\n",
       " \"Montepulciano d'Abruzzo\",\n",
       " 'Saint-Estèphe',\n",
       " 'Saint-Julien',\n",
       " 'Margaret River',\n",
       " 'Collio',\n",
       " 'Soave Classico',\n",
       " 'Chianti',\n",
       " 'Bordeaux Supérieur',\n",
       " 'Tupungato',\n",
       " 'Côtes du Rhône',\n",
       " 'Prosecco di Valdobbiadene',\n",
       " 'Arroyo Grande Valley',\n",
       " 'Shenandoah Valley (CA)',\n",
       " 'Green Valley',\n",
       " 'Mount Veeder',\n",
       " 'Amarone della Valpolicella',\n",
       " 'Napa',\n",
       " 'Eola-Amity Hills',\n",
       " 'Vino Nobile di Montepulciano',\n",
       " 'Yarra Valley',\n",
       " 'Bolgheri Superiore',\n",
       " 'St. Helena',\n",
       " 'Jumilla',\n",
       " 'Beaune',\n",
       " 'Pouilly-Fumé',\n",
       " 'Salento',\n",
       " 'Campo de Borja',\n",
       " 'Coonawarra',\n",
       " \"Barbera d'Asti Superiore\",\n",
       " 'Diamond Mountain District',\n",
       " 'Graves',\n",
       " 'Umpqua Valley',\n",
       " 'Veneto',\n",
       " 'Delle Venezie',\n",
       " 'Maremma',\n",
       " 'Stags Leap District',\n",
       " 'Pouilly-Fuissé',\n",
       " \"Dolcetto d'Alba\",\n",
       " 'Vino de la Tierra de Castilla y León',\n",
       " 'Cariñena',\n",
       " 'Prosecco',\n",
       " 'Knights Valley',\n",
       " 'Cafayate',\n",
       " 'Langhe',\n",
       " 'Chassagne-Montrachet',\n",
       " 'Bierzo',\n",
       " 'Etna',\n",
       " 'Calaveras County',\n",
       " \"Moscato d'Asti\",\n",
       " 'Nuits-St.-Georges',\n",
       " 'San Juan',\n",
       " 'Vouvray',\n",
       " 'Puglia',\n",
       " 'Gevrey-Chambertin',\n",
       " 'Isola dei Nuraghi',\n",
       " 'Puligny-Montrachet',\n",
       " 'Umbria',\n",
       " 'Jerez',\n",
       " 'Prosecco di Conegliano e Valdobbiadene',\n",
       " 'Hermitage',\n",
       " 'Oak Knoll District',\n",
       " 'Sonoma Mountain',\n",
       " 'La Mancha',\n",
       " 'Adelaide Hills',\n",
       " 'Victoria',\n",
       " 'Western Australia',\n",
       " 'Penedès',\n",
       " 'Hunter Valley',\n",
       " 'Venezia Giulia',\n",
       " 'Châteauneuf-du-Pape',\n",
       " 'Neuquén',\n",
       " 'New York',\n",
       " 'Morellino di Scansano',\n",
       " 'Soave',\n",
       " 'Roero',\n",
       " 'Pommard',\n",
       " 'San Luis Obispo County',\n",
       " 'Montsant',\n",
       " 'Southern Oregon',\n",
       " 'Chalk Hill',\n",
       " 'Calatayud',\n",
       " 'Savigny-lès-Beaune',\n",
       " 'Barsac',\n",
       " 'Bordeaux Rosé',\n",
       " 'Columbia Valley (OR)',\n",
       " 'Coteaux du Languedoc',\n",
       " 'Madiran',\n",
       " 'Lugana',\n",
       " 'Mercurey',\n",
       " 'Valpolicella Classico Superiore',\n",
       " \"Crémant d'Alsace\",\n",
       " 'Côtes de Gascogne',\n",
       " 'Fiano di Avellino',\n",
       " 'Vin Mousseux',\n",
       " 'Côtes du Rhône Villages',\n",
       " 'Cornas',\n",
       " 'Crémant de Bourgogne',\n",
       " 'Minervois',\n",
       " 'Rattlesnake Hills',\n",
       " 'Clarksburg',\n",
       " 'Monticello',\n",
       " 'San Rafael',\n",
       " 'Los Carneros',\n",
       " 'Red Hills Lake County',\n",
       " \"Coteaux d'Aix-en-Provence\",\n",
       " 'Colli della Toscana Centrale',\n",
       " 'Mt. Harlan',\n",
       " 'Yamhill-Carlton District',\n",
       " 'Yountville',\n",
       " 'Eden Valley',\n",
       " 'Vin de Pays des Côtes de Gascogne',\n",
       " 'Chianti Rufina',\n",
       " 'Gaillac',\n",
       " 'Corbières',\n",
       " 'Okanagan Valley',\n",
       " 'Beaujolais-Villages',\n",
       " 'Redwood Valley',\n",
       " 'New Mexico',\n",
       " 'Crozes-Hermitage',\n",
       " 'Beaujolais',\n",
       " 'Walla Walla Valley (OR)',\n",
       " 'Carmel Valley',\n",
       " 'Mendocino Ridge',\n",
       " 'Long Island',\n",
       " 'Prosecco del Veneto',\n",
       " 'Contra Costa County',\n",
       " 'Bergerac',\n",
       " 'Trentino',\n",
       " 'Happy Canyon of Santa Barbara',\n",
       " 'Muscadet Sèvre et Maine',\n",
       " 'McMinnville',\n",
       " 'Aglianico del Vulture',\n",
       " 'Terre Siciliane',\n",
       " 'Mâcon-Villages',\n",
       " 'Morgon',\n",
       " \"Barbera d'Asti Superiore Nizza\",\n",
       " 'Anjou',\n",
       " 'Volnay',\n",
       " 'Piedmont',\n",
       " 'Chambolle-Musigny',\n",
       " 'Langhorne Creek',\n",
       " 'Campania',\n",
       " 'Irpinia',\n",
       " 'Trento',\n",
       " \"Sant'Antimo\",\n",
       " 'Sagrantino di Montefalco',\n",
       " 'Marche',\n",
       " 'Calistoga',\n",
       " 'Maremma Toscana',\n",
       " 'Chalone',\n",
       " 'Valdepeñas',\n",
       " 'Chinon',\n",
       " 'Vosne-Romanée',\n",
       " 'Moulis-en-Médoc',\n",
       " 'Lazio',\n",
       " 'Saint-Joseph',\n",
       " 'Applegate Valley',\n",
       " 'Atlas Peak',\n",
       " \"Pays d'Oc\",\n",
       " 'Napa County',\n",
       " 'Côtes de Bourg',\n",
       " 'Vernaccia di San Gimignano',\n",
       " 'Friuli Grave',\n",
       " 'Santenay',\n",
       " 'Listrac-Médoc',\n",
       " 'Greco di Tufo',\n",
       " 'Bergerac Sec',\n",
       " 'Taurasi',\n",
       " \"Barbera d'Alba Superiore\",\n",
       " 'Utiel-Requena',\n",
       " 'Salta',\n",
       " 'Somontano',\n",
       " 'Vermentino di Sardegna',\n",
       " 'Temecula Valley',\n",
       " 'Blaye Côtes de Bordeaux',\n",
       " 'Chianti Colli Senesi',\n",
       " 'Bennett Valley',\n",
       " 'Seneca Lake',\n",
       " 'Rockpile',\n",
       " 'Ribbon Ridge',\n",
       " 'Yorkville Highlands',\n",
       " 'Valpolicella Superiore',\n",
       " 'Vigneti delle Dolomiti',\n",
       " 'Costières de Nîmes',\n",
       " 'Valencia',\n",
       " 'Santa Clara Valley',\n",
       " 'Prosecco Superiore di Cartizze',\n",
       " 'Cayuga Lake',\n",
       " 'Recioto della Valpolicella Classico',\n",
       " 'Côtes de Provence Sainte-Victoire',\n",
       " 'Côte Rôtie',\n",
       " 'Bandol',\n",
       " 'Snipes Mountain',\n",
       " 'Rully',\n",
       " 'Niagara Peninsula',\n",
       " 'Fiddletown',\n",
       " 'Valpolicella Classico',\n",
       " 'Gigondas',\n",
       " 'Saint-Aubin',\n",
       " 'Saumur',\n",
       " 'Corton-Charlemagne',\n",
       " 'Temecula',\n",
       " 'Rutherglen',\n",
       " 'Calchaquí Valley',\n",
       " 'Rosso di Montepulciano',\n",
       " 'Clarendon',\n",
       " 'Premieres Côtes de Bordeaux',\n",
       " 'High Valley',\n",
       " 'Maipú',\n",
       " 'Valdeorras',\n",
       " 'Castillon Côtes de Bordeaux',\n",
       " 'San Benito County',\n",
       " 'Friuli Isonzo',\n",
       " 'Tierra de Castilla',\n",
       " 'Catalunya',\n",
       " 'Famatina Valley',\n",
       " 'Saint-Véran',\n",
       " 'Fleurie',\n",
       " 'Alicante',\n",
       " 'Gavi',\n",
       " 'Montefalco Rosso',\n",
       " 'Salice Salentino',\n",
       " 'Marin County',\n",
       " 'Fronton',\n",
       " 'Adelaide',\n",
       " 'Argentina',\n",
       " 'Sonoma-Napa',\n",
       " 'Dolcetto di Dogliani',\n",
       " 'Menetou-Salon',\n",
       " 'Montecucco',\n",
       " 'Primitivo di Manduria',\n",
       " 'Clos de Vougeot',\n",
       " 'Savennières',\n",
       " 'Columbia Gorge (OR)',\n",
       " 'Crémant de Loire',\n",
       " 'Cienega Valley',\n",
       " 'Río Negro Valley',\n",
       " 'Pennsylvania',\n",
       " 'Sangiovese di Romagna',\n",
       " 'Barbera del Monferrato',\n",
       " 'Patagonia',\n",
       " 'Lalande de Pomerol',\n",
       " 'Clear Lake',\n",
       " 'Australia',\n",
       " 'Tasmania',\n",
       " 'Marsannay',\n",
       " 'Agrelo',\n",
       " 'Terre di Chieti',\n",
       " 'Montagny',\n",
       " 'Padthaway',\n",
       " 'Prosecco di Conegliano',\n",
       " 'Heathcote',\n",
       " 'Pernand-Vergelesses',\n",
       " 'Terra Alta',\n",
       " 'Napa-Sonoma',\n",
       " 'Piave',\n",
       " 'Dunnigan Hills',\n",
       " 'Ribeiro',\n",
       " 'Texas',\n",
       " 'Premieres Côtes de Blaye',\n",
       " 'Touraine',\n",
       " 'Castel del Monte',\n",
       " 'Sangiovese di Romagna Superiore',\n",
       " 'Perdriel',\n",
       " 'Valdobbiadene Superiore di Cartizze',\n",
       " 'Fronsac',\n",
       " 'Jurançon',\n",
       " 'Cortona',\n",
       " 'Condrieu',\n",
       " 'Barbera del Monferrato Superiore',\n",
       " 'Missouri',\n",
       " 'Moulin-à-Vent',\n",
       " 'Orange',\n",
       " 'Yecla',\n",
       " 'Monferrato',\n",
       " 'Spain',\n",
       " 'Lake Chelan',\n",
       " 'Brouilly',\n",
       " 'The Hamptons, Long Island',\n",
       " 'Pemberton',\n",
       " 'Faugères',\n",
       " 'La Rioja',\n",
       " 'Cannonau di Sardegna',\n",
       " 'Chianti Superiore',\n",
       " 'Juliénas',\n",
       " 'Veronese',\n",
       " 'La Consulta',\n",
       " 'Torgiano',\n",
       " 'Sannio',\n",
       " 'Valpolicella',\n",
       " 'Vin de France',\n",
       " 'Tulum Valley',\n",
       " 'Corton',\n",
       " 'El Dorado County',\n",
       " 'Côtes de Bergerac',\n",
       " \"Nebbiolo d'Alba\",\n",
       " 'Columbia Gorge (WA)',\n",
       " 'Italy',\n",
       " 'Lacryma Christi del Vesuvio',\n",
       " 'Potter Valley',\n",
       " \"Trebbiano d'Abruzzo\",\n",
       " 'Entre-Deux-Mers',\n",
       " 'Chianti Colli Fiorentini',\n",
       " 'Terre del Volturno',\n",
       " 'Carmignano',\n",
       " 'Aloxe-Corton',\n",
       " 'Rosso del Veronese',\n",
       " 'Carignano del Sulcis',\n",
       " 'Jurançon Sec',\n",
       " 'Montagne-Saint-Émilion',\n",
       " 'Languedoc',\n",
       " 'Colline Pescaresi',\n",
       " 'Côtes du Tarn',\n",
       " 'York Mountain',\n",
       " 'Suisun Valley',\n",
       " 'Vin Santo del Chianti Classico',\n",
       " 'Limestone Coast',\n",
       " 'Frankland River',\n",
       " 'Ribeira Sacra',\n",
       " 'Cerasuolo di Vittoria',\n",
       " 'Valpolicella Ripasso',\n",
       " 'Idaho',\n",
       " 'Forlì',\n",
       " 'Echézeaux',\n",
       " 'Coteaux Varois',\n",
       " 'Tuscany',\n",
       " 'Fair Play',\n",
       " 'Almansa',\n",
       " 'Pla de Bages',\n",
       " 'Yolo County',\n",
       " 'Saint-Chinian',\n",
       " 'Limoux',\n",
       " 'Bendigo',\n",
       " 'Paicines',\n",
       " 'Cigales',\n",
       " 'Fort Ross-Seaview',\n",
       " 'Bourgogne Hautes Côtes de Nuits',\n",
       " 'Great Southern',\n",
       " 'Verdicchio dei Castelli di Jesi Classico Superiore',\n",
       " 'Mornington Peninsula',\n",
       " 'Quincy',\n",
       " 'Nagambie Lakes',\n",
       " 'Tavel',\n",
       " 'Côtes du Roussillon Villages',\n",
       " 'Northern Sonoma',\n",
       " 'Monbazillac',\n",
       " 'Falerno del Massico',\n",
       " 'Montefalco Sagrantino',\n",
       " 'Buzet',\n",
       " 'Côtes de Bordeaux',\n",
       " 'Dominio de Valdepusa',\n",
       " 'Lirac',\n",
       " 'South Coast',\n",
       " 'Guenoc Valley',\n",
       " 'Roero Arneis',\n",
       " 'Cochise County',\n",
       " 'Petit Chablis',\n",
       " 'Clements Hills',\n",
       " 'Vacqueyras',\n",
       " 'Isonzo del Friuli',\n",
       " 'Valle de Uco',\n",
       " 'Adelaida District',\n",
       " 'Santa Barbara',\n",
       " 'Asti',\n",
       " 'Cadillac Côtes de Bordeaux',\n",
       " 'Hudson River Region',\n",
       " 'Basilicata',\n",
       " 'Côte de Nuits-Villages',\n",
       " 'Muscat de Beaumes de Venise',\n",
       " 'Minervois La Liviniere',\n",
       " 'San Francisco Bay',\n",
       " 'Coteaux Varois en Provence',\n",
       " 'Vi de la Terra Illes Balears',\n",
       " 'Central Ranges',\n",
       " 'Soave Classico Superiore',\n",
       " 'New Jersey',\n",
       " 'Oltrepò Pavese',\n",
       " 'Vin de Table Francais',\n",
       " 'Napa County-Sonoma County',\n",
       " 'Grand Valley',\n",
       " 'Vin de Pays Vignobles de France',\n",
       " 'Vista Flores',\n",
       " \"Montepulciano d'Abruzzo Cerasuolo\",\n",
       " 'Rosso Piceno Superiore',\n",
       " 'Bardolino',\n",
       " 'Côtes de Castillon',\n",
       " 'Taburno',\n",
       " 'Chorey-lès-Beaune',\n",
       " 'Alto Adige Valle Isarco',\n",
       " 'Lambrusco Grasparossa di Castelvetro',\n",
       " 'Val di Cornia Suvereto',\n",
       " 'Contessa Entellina',\n",
       " 'Rubicone',\n",
       " 'Saint-Mont',\n",
       " 'Passito di Pantelleria',\n",
       " 'Coteaux du Layon',\n",
       " 'Emilia-Romagna',\n",
       " 'Rosso Piceno',\n",
       " 'Marsala',\n",
       " 'Savennières-Roche-Aux-Moines',\n",
       " 'Terra degli Osci',\n",
       " 'Ancient Lakes',\n",
       " 'Reuilly',\n",
       " 'Coteaux du Giennois',\n",
       " 'Bourgueil',\n",
       " 'Val de Loire',\n",
       " 'Valpolicella Ripasso Classico',\n",
       " 'Morey-Saint-Denis',\n",
       " 'Valli di Porto Pino',\n",
       " 'Chiroubles',\n",
       " 'Shenandoah Valley',\n",
       " 'Pyrenees',\n",
       " 'Viré-Clessé',\n",
       " 'Vin de Pays du Comté Tolosan',\n",
       " 'Côtes du Roussillon',\n",
       " 'Wrattonbully',\n",
       " 'Riverina',\n",
       " 'Getariako Txakolina',\n",
       " 'Augusta',\n",
       " 'Molise',\n",
       " 'Rosso Conero',\n",
       " 'King Valley',\n",
       " 'Chevalier-Montrachet',\n",
       " 'Charmes-Chambertin',\n",
       " 'Vin de Pays Var',\n",
       " 'Ribera del Guadiana',\n",
       " 'Bardolino Chiaretto',\n",
       " 'Bourgogne Hautes Côtes de Beaune',\n",
       " 'Saint-Amour',\n",
       " 'Costers del Segre',\n",
       " 'Bâtard-Montrachet',\n",
       " 'Montlouis-sur-Loire',\n",
       " 'Orvieto Classico Superiore',\n",
       " 'Orcia',\n",
       " 'Monthélie',\n",
       " 'Ben Lomond Mountain',\n",
       " 'Vin de Pays du Val de Loire',\n",
       " 'Vin de Pays des Côtes Catalanes',\n",
       " 'Bardolino Classico',\n",
       " 'Chiles Valley',\n",
       " 'Côte de Brouilly',\n",
       " 'Conero',\n",
       " 'Verdicchio dei Castelli di Jesi Classico',\n",
       " 'Côtes du Lot',\n",
       " 'Veneto Orientale',\n",
       " \"Brachetto d'Acqui\",\n",
       " 'Recioto della Valpolicella',\n",
       " 'Ballard Canyon',\n",
       " 'Empordà',\n",
       " 'Grand River Valley',\n",
       " 'Vermentino di Gallura',\n",
       " 'Moscadello di Montalcino',\n",
       " 'Vittoria',\n",
       " 'Montescudaio',\n",
       " 'Friuli Aquileia',\n",
       " 'Chelan County',\n",
       " 'Givry',\n",
       " 'Lussac Saint-Émilion',\n",
       " 'Calabria',\n",
       " 'Saint-Péray',\n",
       " 'Sardinia',\n",
       " \"Montepulciano d'Abruzzo Colline Teramane\",\n",
       " 'Montilla-Moriles',\n",
       " 'Vin de Pays du Jardin de la France',\n",
       " 'Vinos de Madrid',\n",
       " 'Chambertin Clos de Bèze',\n",
       " 'Paso Robles Willow Creek District',\n",
       " 'Coombsville',\n",
       " 'Albana di Romagna',\n",
       " 'Chambertin',\n",
       " 'Corbières-Boutenac',\n",
       " 'Rosso di Toscana',\n",
       " 'Amarone della Valpolicella Valpantena',\n",
       " 'Touraine Mesland',\n",
       " 'Monterrei',\n",
       " 'Auxey-Duresses',\n",
       " 'Frascati Superiore',\n",
       " 'San Carlos',\n",
       " 'Friuli',\n",
       " 'Cabardes',\n",
       " 'Marca Trevigiana',\n",
       " 'Soave Superiore',\n",
       " 'Pécharmant',\n",
       " 'Quarts de Chaume',\n",
       " 'Alcamo',\n",
       " 'Orvieto Classico',\n",
       " 'Côtes du Luberon',\n",
       " 'Coteaux du Languedoc Pic Saint Loup',\n",
       " 'Saumur-Champigny',\n",
       " 'Mount Harlan',\n",
       " 'Pacherenc du Vic Bilh',\n",
       " 'Mâcon-Lugny',\n",
       " 'Fixin',\n",
       " 'Cole Ranch',\n",
       " 'Côtes du Marmandais',\n",
       " 'Abruzzo',\n",
       " 'San Pasqual',\n",
       " 'Colline Teatine',\n",
       " 'Humboldt County',\n",
       " 'Mâcon-Chardonnay',\n",
       " 'Cerasuolo di Vittoria Classico',\n",
       " 'Arizona',\n",
       " 'Ohio',\n",
       " 'Gavi di Gavi',\n",
       " 'France',\n",
       " 'Alghero',\n",
       " 'Uclés',\n",
       " 'Trinity County',\n",
       " 'Custoza',\n",
       " 'Lago di Corbara',\n",
       " 'Côte Chalonnaise',\n",
       " 'New South Wales',\n",
       " 'Gattinara',\n",
       " 'Bourgogne Aligoté',\n",
       " 'Puget Sound',\n",
       " 'Mudgee',\n",
       " 'Beneventano',\n",
       " 'Ruché di Castagnole Monferrato',\n",
       " 'Sonoma County-Monterey County-Santa Barbara County',\n",
       " 'Primitivo del Salento',\n",
       " 'Côtes de Duras',\n",
       " 'Beamsville Bench',\n",
       " 'Malibu-Newton Canyon',\n",
       " 'Coteaux Bourguignons',\n",
       " 'Montrachet',\n",
       " \"Rosé d'Anjou\",\n",
       " 'Cirò',\n",
       " 'Vougeot',\n",
       " 'Málaga',\n",
       " 'Côtes de Provence La Londe',\n",
       " 'Saint-Bris',\n",
       " 'Aglianico del Taburno',\n",
       " 'Contea di Sclafani',\n",
       " 'Vino de la Tierra Contraviesa Alpujarra',\n",
       " 'Marcillac',\n",
       " 'Cheverny',\n",
       " 'Val di Neto',\n",
       " 'Niagara-On-The-Lake',\n",
       " 'Tierra de León',\n",
       " 'Valpolicella Ripasso Valpantena Superiore',\n",
       " 'Banyuls',\n",
       " 'Vin Santo del Chianti',\n",
       " 'Vin de Pays de la Méditerranée',\n",
       " 'Vino da Tavola',\n",
       " 'Vino Spumante',\n",
       " 'Lot',\n",
       " 'Madera',\n",
       " 'Vin Santo di Montepulciano',\n",
       " 'Piccadilly Valley',\n",
       " \"Dolcetto d'Asti\",\n",
       " 'Vin Santo del Chianti Rufina',\n",
       " 'Napa-Mendocino-Sonoma',\n",
       " 'Napa-Mendocino-Sonoma-Marin',\n",
       " 'Alta Mesa',\n",
       " 'Solano County',\n",
       " 'Cucamonga Valley',\n",
       " 'Chapelle-Chambertin',\n",
       " 'Pine Mountain-Cloverdale Peak',\n",
       " 'Romangia',\n",
       " \"Dolcetto di Diano d'Alba\",\n",
       " 'Bienvenues Bâtard-Montrachet',\n",
       " 'Beaujolais Blanc',\n",
       " 'Côte de Beaune-Villages',\n",
       " 'Pomino',\n",
       " 'Montravel',\n",
       " \"Cabernet d'Anjou\",\n",
       " 'Pouilly-Vinzelles',\n",
       " 'San Francisco Bay-Livermore Valley',\n",
       " 'Campi Flegrei',\n",
       " 'Bonnes-Mares',\n",
       " 'Emilia',\n",
       " 'Corse',\n",
       " 'Southern Flinders Ranges',\n",
       " 'Falanghina del Sannio',\n",
       " 'Beaujolais Rosé',\n",
       " 'Fitou',\n",
       " 'Ribera del Queiles',\n",
       " 'Hautes Côtes de Nuits',\n",
       " 'Vin de Pays du Lot',\n",
       " 'Tierra del Viños de Zamora',\n",
       " 'Fleurieu Peninsula',\n",
       " 'Nuragus di Cagliari',\n",
       " 'Lenswood',\n",
       " 'Leelanau Peninsula',\n",
       " 'Venezie',\n",
       " 'Lambrusco Reggiano',\n",
       " 'Monica di Sardegna',\n",
       " 'Conca de Barberà',\n",
       " 'Bolgheri Sassicaia',\n",
       " 'McLaren Vale-Adelaide Hills',\n",
       " 'Spring Mountain District',\n",
       " 'Châteaumeillant',\n",
       " 'Vino Tierra de León',\n",
       " 'Lison-Pramaggiore',\n",
       " 'Old Mission Peninsula',\n",
       " 'Mokelumne River',\n",
       " 'Vin de Pays du Gard',\n",
       " 'Madrid',\n",
       " 'Manchuela',\n",
       " 'Ladoix',\n",
       " 'Côtes-du-Ventoux',\n",
       " 'Côte de Beaune',\n",
       " 'Swan Creek',\n",
       " 'Conero Riserva',\n",
       " 'Vi de la Terra Mallorca',\n",
       " 'Moscato di Noto',\n",
       " 'Bordeaux Clairet',\n",
       " 'Murgia',\n",
       " 'Mediterranée',\n",
       " 'Saint-Romain',\n",
       " 'Régnié',\n",
       " 'Catalonia',\n",
       " \"Cerasuolo d'Abruzzo\",\n",
       " 'Valdadige',\n",
       " 'San Gimignano',\n",
       " 'Mazis-Chambertin',\n",
       " 'Alella',\n",
       " 'Colli Aprutini',\n",
       " 'Dolcetto di Monferrato',\n",
       " 'Bergerac Rosé',\n",
       " 'Tarantino',\n",
       " 'Valtellina Superiore',\n",
       " 'Vin de Pays des Collines Rhodaniennes',\n",
       " 'Vin de Liqueur',\n",
       " 'Colli Piacentini',\n",
       " 'Anjou Villages',\n",
       " 'Colli di Rimini',\n",
       " 'Sonoma-Napa-Mendocino',\n",
       " 'Extremadura',\n",
       " 'Monterey-Santa Barbara',\n",
       " \"Vin de Pays de L'Herault\",\n",
       " 'Cesanese del Piglio',\n",
       " 'Southeastern New England',\n",
       " 'Coteaux du Layon Saint Aubin',\n",
       " 'Patrimonio',\n",
       " 'Canon-Fronsac',\n",
       " 'Saint-Nicolas-de-Bourgueil',\n",
       " 'St.-Romain',\n",
       " 'Hames Valley',\n",
       " 'Soave Colli Scaligeri',\n",
       " 'Crémant de Jura',\n",
       " 'Hilltops',\n",
       " 'Carneros-Napa Valley',\n",
       " 'Mentrida',\n",
       " 'Garda',\n",
       " 'Valpolicella Ripasso Valpantena',\n",
       " 'Colline Novaresi',\n",
       " 'Pavia',\n",
       " 'Crémant de Limoux',\n",
       " 'Teroldego Rotaliano',\n",
       " 'Colli Bolognesi',\n",
       " 'Chénas',\n",
       " 'Kangaroo Island',\n",
       " 'Lambrusco di Sorbara',\n",
       " 'Vin de Savoie',\n",
       " 'Puisseguin Saint-Émilion',\n",
       " 'Colli di Faenza',\n",
       " 'Dogliani Superiore',\n",
       " 'Recioto di Soave',\n",
       " 'Arbois',\n",
       " 'Alto Valle del Río Negro',\n",
       " \"Sant' Agata dei Goti\",\n",
       " 'Offida Pecorino',\n",
       " 'Sonoma County-Napa County',\n",
       " 'San Luis Obispo',\n",
       " 'Coste della Sesia',\n",
       " 'Vino de la Tierra de Cádiz',\n",
       " 'Clos de la Roche',\n",
       " 'Elkton Oregon',\n",
       " 'Romagna',\n",
       " 'Placer County',\n",
       " 'Friuli Venezia Giulia',\n",
       " 'Mendocino-Lake',\n",
       " 'Vin Santo di Carmignano',\n",
       " 'Salina',\n",
       " 'Monteregio di Massa Marittima',\n",
       " 'Pompeiano',\n",
       " 'Les Baux de Provence',\n",
       " 'Noto',\n",
       " 'Grands-Echezeaux',\n",
       " 'Colorado',\n",
       " 'Colli di Conegliano',\n",
       " \"Costa d'Amalfi\",\n",
       " 'Central Victoria',\n",
       " 'Recioto di Soave Classico',\n",
       " 'Vino de la Tierra del Bajo Aragón',\n",
       " 'Lake County-Mendocino County',\n",
       " 'Western Plains',\n",
       " 'Castelli Romani',\n",
       " 'San Lucas',\n",
       " 'Custoza Superiore',\n",
       " 'Côtes de Nuits Villages',\n",
       " 'Dogliani',\n",
       " 'Templeton Gap District',\n",
       " 'Vin de Pays du Val de Cesse',\n",
       " 'Mount Barker',\n",
       " 'Cadillac',\n",
       " 'Erice',\n",
       " 'Roccamonfina',\n",
       " 'Mâcon-Fuissé',\n",
       " 'Chianti Colli Aretini',\n",
       " 'Olevano Romano',\n",
       " 'Castilla La Mancha',\n",
       " 'Gioia del Colle',\n",
       " 'Goulburn Valley',\n",
       " 'Zonda Valley',\n",
       " 'Vin de Pays des Cévennes',\n",
       " 'Burgundy',\n",
       " 'Bizkaiko Txakolina',\n",
       " 'Provincia di Pavia',\n",
       " 'Bardolino Classico Superiore',\n",
       " 'Tarragona',\n",
       " 'Corton Vergennes',\n",
       " 'Clos Saint-Denis',\n",
       " 'Santa Cruz County',\n",
       " 'Columbia Valley-Walla Walla Valley',\n",
       " 'Luberon',\n",
       " 'Lake Michigan Shore',\n",
       " 'Est! Est!! Est!!! di Montefiascone',\n",
       " 'Faro',\n",
       " 'Moon Mountain District Sonoma County',\n",
       " 'Vin de Pays de Vaucluse',\n",
       " 'Côtes de Thongue',\n",
       " 'Prosecco di Valdobbiadene Superiore',\n",
       " 'Vino de la Tierra de Castelló',\n",
       " 'Falerio dei Colli Ascolani',\n",
       " 'Rosé de Loire',\n",
       " \"Vin de Pays de L'Aude\",\n",
       " 'Riverland',\n",
       " 'North Carolina',\n",
       " 'Comté Toulosan',\n",
       " 'Napa-Amador',\n",
       " 'Vin de Pays Cité de Carcassonne',\n",
       " 'Yamhill County',\n",
       " 'Terre di Franciacorta',\n",
       " 'Grampians',\n",
       " 'Rivesaltes',\n",
       " 'Leverano',\n",
       " 'Mendocino-Amador',\n",
       " \"Lacrima di Morro d'Alba\",\n",
       " 'Nevada County',\n",
       " 'Colli Etruria Centrale',\n",
       " 'Verdicchio dei Castelli di Jesi',\n",
       " 'Bonnezeaux',\n",
       " 'Vittoria Frappato',\n",
       " 'Colli Trevigiani',\n",
       " 'La Clape',\n",
       " 'Yadkin Valley',\n",
       " 'Sonoma County-Santa Barbara County',\n",
       " 'Maury',\n",
       " 'Maranges',\n",
       " 'Mendocino-Sonoma-Amador',\n",
       " 'Curtefranca',\n",
       " 'Breganze',\n",
       " 'Côtes Catalanes',\n",
       " 'Montello e Colli Asolani',\n",
       " 'Ile de Beauté',\n",
       " 'Vino de la Tierra Ribera del Gállego-Cinco Villas',\n",
       " 'Pouilly-Loché',\n",
       " 'Colli Perugini',\n",
       " 'Vino de Mesa',\n",
       " 'Monti Lessini',\n",
       " 'Alto Valle de Uco',\n",
       " 'River Junction',\n",
       " 'Napa-Carneros',\n",
       " 'Arcole',\n",
       " 'Garda Classico',\n",
       " 'Menfi',\n",
       " 'Aminga Valley',\n",
       " 'Currency Creek',\n",
       " 'Mâcon La Roche Vineuse',\n",
       " 'Emporadà-Costa Brava',\n",
       " 'Coteaux du Vendômois',\n",
       " 'Périgord',\n",
       " 'Corton-Bressandes',\n",
       " 'Muscat de Rivesaltes',\n",
       " 'Adelaide Plains',\n",
       " 'Lambrusco di Modena',\n",
       " 'Lombardy',\n",
       " 'Donnici',\n",
       " 'Colli di Luni',\n",
       " 'Crémant de Bordeaux',\n",
       " 'Vin de Pays des Portes de Méditerranée',\n",
       " 'Colli Pesaresi',\n",
       " 'Iowa',\n",
       " 'Saussignac',\n",
       " 'Blanquette de Limoux',\n",
       " 'Offida Passerina',\n",
       " 'Cuyo',\n",
       " 'Prosecco Treviso',\n",
       " 'Kentucky',\n",
       " 'Sainte-Foy Bordeaux',\n",
       " 'Vin de Pays des Coteaux de Peyriac',\n",
       " 'Criots-Bâtard-Montrachet',\n",
       " 'Vin de Pays de France',\n",
       " 'Meursault-Blagny',\n",
       " 'Barco Reale di Carmignano',\n",
       " 'Muscadet Coteaux de la Loire',\n",
       " 'Mount Benson',\n",
       " 'Eloro',\n",
       " 'Picpoul de Pinet',\n",
       " 'Manzanilla-Sanlúcar de Barrameda',\n",
       " 'Controguerra',\n",
       " 'North Yuba',\n",
       " 'Montefalco',\n",
       " 'St.-Véran',\n",
       " 'Naches Heights',\n",
       " 'Sable de Camargue',\n",
       " 'Tehema Foothills',\n",
       " 'Francs Côtes de Bordeaux',\n",
       " 'Lake County-Sonoma County',\n",
       " 'Lake Erie North Shore',\n",
       " 'Murray-Darling',\n",
       " 'Candia Dei Colli Apuani',\n",
       " 'Cilento',\n",
       " 'Savennières-Coulée de Serrant',\n",
       " 'Latricières-Chambertin',\n",
       " 'Venezia',\n",
       " 'Capay Valley',\n",
       " 'Coteaux du Layon La Faye',\n",
       " 'Alto Adige Terlano',\n",
       " 'Mâcon',\n",
       " 'Ghemme',\n",
       " 'Sebino',\n",
       " 'Falanghina del Beneventano',\n",
       " 'Aglianico del Beneventano',\n",
       " 'Offida Rosso',\n",
       " 'Casorzo',\n",
       " 'Bourgogne Côtes d’Auxerre',\n",
       " 'Pouilly-sur-Loire',\n",
       " 'Tierra Manchuela',\n",
       " 'Beaumes-de-Venise',\n",
       " 'Colli Asolani Prosecco',\n",
       " 'Cortese di Gavi',\n",
       " 'Ramona Valley',\n",
       " 'Vin de Pays des Côtes de Thau',\n",
       " 'Penisola Sorrentina',\n",
       " 'Riviera Ligure di Ponente',\n",
       " \"Dolcetto d'Acqui\",\n",
       " 'Vino de la Tierra Ribera del Jiloca',\n",
       " 'Granite Belt',\n",
       " \"Coteaux d'Ancenis\",\n",
       " 'San Marino',\n",
       " 'Bourgogne Grand Ordinaire',\n",
       " 'Vin Doux Naturel Rasteau',\n",
       " 'Gravina',\n",
       " 'Barossa-Adelaide Hills',\n",
       " 'Mendocino-Solano',\n",
       " 'Moscato di Pantelleria',\n",
       " 'Jahant',\n",
       " 'Saddle Rock-Malibu',\n",
       " 'Vino de la Tierra de Zamora',\n",
       " 'Nardò',\n",
       " 'Tumbarumba',\n",
       " 'Bullas',\n",
       " 'Barossa Valley-Clare Valley',\n",
       " \"Dolcetto d'Alba Superiore\",\n",
       " \"Coteaux de l'Aubance\",\n",
       " 'Sangiovese di Toscana',\n",
       " 'McDowell Valley',\n",
       " 'Mâcon-Verze',\n",
       " 'Gundagai',\n",
       " 'Macon-Verge',\n",
       " 'Mâcon-Cruzille',\n",
       " 'Romanée-St.-Vivant',\n",
       " 'Corton-Rognet',\n",
       " 'Verdicchio di Matelica',\n",
       " 'Ventoux',\n",
       " 'Copertino',\n",
       " 'Muscadet',\n",
       " 'Lanzarote',\n",
       " 'Charentais',\n",
       " 'Mâcon Chaintré',\n",
       " 'Chianti Colli Pisani',\n",
       " 'Colli di Salerno',\n",
       " 'Costa Toscana',\n",
       " 'Barbera di Piemonte',\n",
       " 'Chianti Montespertoli',\n",
       " 'Orvieto',\n",
       " 'Bourgogne Epineuil',\n",
       " 'Sonoma',\n",
       " 'Muscadet Côtes de Grandlieu',\n",
       " 'Chianti Montalbano',\n",
       " 'Napa County-Sonoma County-San Joaquin County',\n",
       " 'Touraine Amboise',\n",
       " 'Saint-Croix-du-Mont',\n",
       " 'San Antonio Valley',\n",
       " 'Sonoma-Napa-Lake',\n",
       " 'Malvasia delle Lipari',\n",
       " 'Alta Langa',\n",
       " 'Lake Erie',\n",
       " 'Terrasses du Larzac',\n",
       " 'Dolcetto di Dogliani Superiore',\n",
       " 'Primitivo del Tarantino',\n",
       " 'Bardolino Superiore',\n",
       " 'San Bernabe',\n",
       " \"Diano d'Alba\",\n",
       " 'Bordeaux Côtes de Francs ',\n",
       " 'Ribera del Júcar',\n",
       " 'Muscat de Saint-Jean de Minervois',\n",
       " 'Monterey-Santa Barbara-Sonoma',\n",
       " 'Mâcon Solutré',\n",
       " 'Colline Lucchesi',\n",
       " 'Middleburg',\n",
       " 'Montecarlo',\n",
       " 'Canada',\n",
       " 'Clare Valley-Coonawarra',\n",
       " 'Mâcon-Vinzelles',\n",
       " 'Southern Highlands',\n",
       " \"Lambrusco dell'Emilia\",\n",
       " 'Circeo',\n",
       " 'Var',\n",
       " 'Barossa-Langhorne Creek',\n",
       " 'Currency Creek-McLaren Vale',\n",
       " 'Irrouléguy',\n",
       " 'Short Hills Bench',\n",
       " \"Virginia's Eastern Shore\",\n",
       " 'Solano County Green Valley',\n",
       " 'Palette',\n",
       " 'Biferno Bianco',\n",
       " 'Vin de Pays des Coteaux de Bessilles',\n",
       " 'Corton Les Renardes',\n",
       " 'Haut-Poitou',\n",
       " 'Terrazze Retiche di Sondrio',\n",
       " 'Gers',\n",
       " 'Collines Rhôdaniennes',\n",
       " 'Cirò Classico',\n",
       " 'Falerio',\n",
       " 'Gambellara Classico',\n",
       " 'California-Washington',\n",
       " 'Chaume',\n",
       " 'Anderson Valley-Sonoma County-Cole Ranch',\n",
       " 'Apulia',\n",
       " 'Bianco di Custoza',\n",
       " 'Coteaux du Layon Beaulieu',\n",
       " 'Epomeo',\n",
       " 'Mâcon-Prissé',\n",
       " 'Sonoma-Napa-Monterey',\n",
       " 'Massachusetts',\n",
       " 'Vin de Pays de la Haute Vallée de l’Aude',\n",
       " 'Côtes de Frontonnais',\n",
       " 'Henty',\n",
       " 'Ohio River Valley',\n",
       " 'Barossa Valley-McLaren Vale',\n",
       " 'Mendocino-Lake County-Napa',\n",
       " 'Torgiano Rosso Riserva',\n",
       " 'Southern Fleurieu',\n",
       " 'Todi',\n",
       " 'Macedon Ranges',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_region = list(region_counts[region_counts < 500].index)\n",
    "replace_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0554b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in replace_region:\n",
    "    wine_df.region_1 = wine_df.region_1.replace(i,\"Other\")\n",
    "\n",
    "region_counts = wine_df.region_1.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acabaf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Density'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAGdCAYAAADKXt17AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSAElEQVR4nO3deXxU5b0/8M9k1iQkQxbIJCwhLDWGKEIoIQiCWwJopeotYG2qva0vUn/IVi+LYqW2QvBa6svLVlsulmsvUA2o9aISXCJIRAmRvagQCGQxZJsJ2SYz8/z+mJwThixMkpk5M+Hzfr3mxc2Z7znnmXNj55Pnec5zVEIIASIiIiLyuCClG0BERETUVzFoEREREXkJgxYRERGRlzBoEREREXkJgxYRERGRlzBoEREREXkJgxYRERGRlzBoEREREXmJRukG3OgcDgdKS0sRFhYGlUqldHOIiIjIDUII1NXVIS4uDkFBnfdbMWgprLS0FEOGDFG6GURERNQDFy9exODBgzt9n0FLYWFhYQCc/48KDw9XuDVERETkDovFgiFDhsjf451h0FKYNFwYHh7OoEVERBRgrjfth5PhiYiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iALAByfKsS73G1yoqle6KURE1A0apRtARF37n/zzeO6dkwCAv39xAXsWTkFMuEHhVhERkTvYo0Xkxxqtdrz04Rn556p6K1796FsFW0RERN3BoEXkxz48WY66JhsGRwTjf3+VCgB4u7AETS12hVtGRETuYNAi8mNvFVwCAPxbymBMHB6FWKMB9VY7DnxbqXDLiIjIHQxaRH6q0WrHoaIqAMADY+IQFKRCxmgTAOD9E+VKNo2IiNzEoEXkpwqLa9BiFzCFG5AQHQoAuOfmGADAF+eqlGwaERG5iUGLyE99UVQNAEgdHgmVSgUAGDu0P4JUQEltI8rNTUo2j4iI3MCgReSnvpKCVkKUvC1Ur0GiKRwAcKS4RpF2ERGR+xi0iPyQEAInS80AgFsHG13eS4mPAAAUXGDQIiLydwxaRH6o1NwES5MNmiAVRsX0c3lPCl6nSi1KNI2IiLqBQYvID51uDVEjB/aDXqN2eU8aOjzzfR2EED5vGxERuY9Bi8gPnSpzBq2k2PB2742K6QeVCqiut6LyitXXTSMiom5g0CLyQ2e+rwMAJMaGtXvPoFVjWJRzuYcz5XU+bRcREXUPgxaRHyq6XA8AGDGgX4fv3xTjDGBSICMiIv/EoEXkZ4QQuFDlDFrxrT1X1/pB6wT57yoYtIiI/BmDFpGfuXylGfVWO4JUwJDI4A5rhrWuFH++ssGXTSMiom5i0CLyMxeqnOEprn9wuzsOJVJP1/nWni8iIvJPDFpEfqao0hmepOcbdkR6r8zchKYWu0/aRURE3cegReRn2uZnhXRaExGiRbhB01rP4UMiIn/FoEXkZ6R5V8M6mQgPACqVSp6nJfWAERGR/2HQIvIz0ryrroLW1e9f4DwtIiK/xaBF5EecSzu09mhFdz50CACDIpx3JJbWNnq9XURE1DMMWkR+pLahBVeabQCAwRHXCVr9nUGrpLbJ6+0iIqKeYdAi8iOlZmfvVFSoDgZtx0s7SNqCFnu0iIj8FYMWkR8pa+2diu1vuG4thw6JiPwfgxaRHylr7dGKNXa8IvzVYo3OMGZubBtuJCIi/8KgReRHSs3OHq044/V7tMIMbWtpsVeLiMg/MWgR+ZGy1sAU1//6PVoAMKh1wjznaRER+ScGLSI/UirP0XIzaLXO5SqpYdAiIvJHDFpEfkS669CdoUOg7c5DDh0SEfknxYPWxo0bkZCQAIPBgJSUFOzfv7/L+ry8PKSkpMBgMGD48OHYvHlzu5qcnBwkJSVBr9cjKSkJu3fv7vZ5d+3ahYyMDERHR0OlUuHrr79ud4zm5mY89dRTiI6ORmhoKB544AFcunSpexeAqJXDIfC9pXs9WnEMWkREfk3RoLVz504sWrQIzz77LAoLCzFlyhTMmDEDxcXFHdYXFRVh5syZmDJlCgoLC/HMM89gwYIFyMnJkWvy8/MxZ84cZGZm4ujRo8jMzMTs2bNx6NChbp23vr4et99+O7Kzsztt/6JFi7B7927s2LEDBw4cwJUrV3D//ffDbrd74OrQjabySjNa7AJBKiAmTO/WPtISD5yjRUTkp4SCJkyYILKysly2JSYmiuXLl3dYv3TpUpGYmOiybd68eWLixInyz7NnzxbTp093qcnIyBBz587t0XmLiooEAFFYWOiyvba2Vmi1WrFjxw55W0lJiQgKChIffPBBh+3viNlsFgCE2Wx2ex/qmwqLa0T8svdE6ov73N7n8PkqEb/sPTF57UdebBkREV3L3e9vxXq0rFYrCgoKkJ6e7rI9PT0dBw8e7HCf/Pz8dvUZGRk4fPgwWlpauqyRjtmT83akoKAALS0tLseJi4tDcnJyl8dpbm6GxWJxeREBbXccurNYqWRgmLP2e0szhBBeaRcREfWcYkGrsrISdrsdMTExLttjYmJQXl7e4T7l5eUd1ttsNlRWVnZZIx2zJ+ftrC06nQ4RERHdOs6aNWtgNBrl15AhQ9w+J/Vt0vysmDD3g9aA1iFGq80Bc2OLV9pFREQ9p/hkeJVK5fKzEKLdtuvVX7vdnWN297zuut5xVqxYAbPZLL8uXrzY63NS33D5SjMAYGC4e/OzAMCgVaN/iBYAUFHX7JV2ERFRzykWtKKjo6FWq9v1/lRUVLTrbZKYTKYO6zUaDaKiorqskY7Zk/N21har1YqamppuHUev1yM8PNzlRQQAl1uD0kA3J8JLYuThwyaPt4mIiHpHsaCl0+mQkpKC3Nxcl+25ubmYNGlSh/ukpaW1q9+7dy/Gjx8PrVbbZY10zJ6ctyMpKSnQarUuxykrK8OJEye6dRwiiRS0BnQzaEk9YN9b2KNFRORvNEqefMmSJcjMzMT48eORlpaG1157DcXFxcjKygLgHGYrKSnBtm3bAABZWVlYv349lixZgieeeAL5+fnYsmULtm/fLh9z4cKFuOOOO7B27VrMmjUL77zzDvbt24cDBw64fV4AqK6uRnFxMUpLSwEAZ86cAeDsyTKZTDAajfjlL3+J3/zmN4iKikJkZCSefvpp3HLLLbjnnnu8fu2o75GGDrsdtNijRUTkv7x+/+N1bNiwQcTHxwudTifGjRsn8vLy5Pcee+wxMXXqVJf6Tz/9VIwdO1bodDoxbNgwsWnTpnbHfPPNN8VNN90ktFqtSExMFDk5Od06rxBCbN26VQBo93r++eflmsbGRjF//nwRGRkpgoODxf333y+Ki4u79fm5vANJJryYK+KXvSeOXazt1n5r3z8t4pe9J55/54SXWkZERNdy9/tbJQTvCVeSxWKB0WiE2WzmfK0bmMMhMGrl+7A7BL5YcTdMbj6CBwD+dvA8nn/3JGYkm7DpZylebCUREUnc/f5W/K5DIgJqGqywO5x/80T103Vr3xh5jhaHDomI/A2DFpEfkJZmiAzVQavu3n+WA8PbFi0lIiL/wqBF5Ad6urTD1ftcruPq8ERE/oZBi8gP9HRph6v3sdodqG3g6vBERP6EQYvID8hLO/TrftDSa9SIaF0d/vs6ztMiIvInDFpEfqA3PVoAEN0a0KquWD3WJiIi6j0GLSI/4KmgVXmFE+KJiPwJgxaRH+ht0JKWhKhkjxYRkV9h0CLyAz19/I6EPVpERP6JQYvID/RmeQcAiG7t0api0CIi8isMWkQKa7bZYW50LsswoJ/7j965WluPFocOiYj8CYMWkcKk3iydOgjhwZoeHSNKvuuQPVpERP6EQYtIYdKSDFH9dFCpVD06RjQnwxMR+SUGLSKFVdc7w1FkaPceJn21qyfD8zE8RET+g0GLSGGeCFrS8g7NNgeuNNs80i4iIuo9Bi0ihUlBK6oXQStEp0GITg2Aq8MTEfkTBi0ihVW1Bq2IXgQtgGtpERH5IwYtIoXVeKBHC+Dq8ERE/ohBi0hhVfIcrZ4tViphjxYRkf9h0CJSWHW9MxhFhmp7dZy21eHZo0VE5C8YtIgUVtPgXBWePVpERH0PgxaRwqTV3HuzvAPQNserqp5Bi4jIXzBoESmoxe6Apcm57lVvg1Z06wOpK+s4dEhE5C8YtIgUVNPgDEVBKqB/cO/maEW1Dj1WskeLiMhvMGgRKUharDQiRIegoJ4951AyIKx1eYc6Bi0iIn/BoEWkoGoPLVYKtE2mtzTZ0GJ39Pp4RETUewxaRAryxHMOJcZgLVStnWLSkCQRESmLQYtIQXLQCul90FIHqeR5XjX1Lb0+HhER9R6DFpGC5KDVr/dBC2jrGZOOS0REymLQIlJQtYeecyiRghaHDomI/AODFpGCrr7r0BOk41SxR4uIyC8waBEpSO7R8vDQYQ2DFhGRX2DQIlKQJ+86BNqWieAcLSIi/8CgRaQgTw8dSncvco4WEZF/YNAiUogQQg5Enh46ZI8WEZF/YNAiUohzBXcBwIM9WrzrkIjIrzBoESlEmrAeqlPDoFV75JgR8mR4LlhKROQPGLSIFFLl4cVKgbY5WlX1fLA0EZE/YNAiUkiNfMeh3mPHjAh1PoKnqcWBRqvdY8clIqKeYdAiUkjbcw61HjtmP70GWrXzydLVnKdFRKQ4Bi0ihUhBKMJDa2gBgEqlkifWc9FSIiLlMWgRKaS2wTlh3VN3HEq4xAMRkf9g0CJSiLnRGYT6B3tu6BDgEg9ERP6EQYtIIdISDP09OEcL4GN4iIj8CYMWkUJqpR4tTw8dhjBoERH5CwYtIoVIc7TYo0VE1HcxaBEpxGuT4VuDG+doEREpj0GLSCFSEDJ6ejJ8P+cCqOzRIiJSHoMWkQKaWuxotjkAeHYdLaBtjhafd0hEpDwGLSIFSL1ZmiAVQnWeeaC0RHoMD1eGJyJSnuJBa+PGjUhISIDBYEBKSgr279/fZX1eXh5SUlJgMBgwfPhwbN68uV1NTk4OkpKSoNfrkZSUhN27d3f7vEIIrFq1CnFxcQgODsa0adNw8uRJl5ry8nJkZmbCZDIhNDQU48aNw1tvvdWDq0A3mraJ8DqoVCqPHlteR6veCiGER49NRETdo2jQ2rlzJxYtWoRnn30WhYWFmDJlCmbMmIHi4uIO64uKijBz5kxMmTIFhYWFeOaZZ7BgwQLk5OTINfn5+ZgzZw4yMzNx9OhRZGZmYvbs2Th06FC3zvvSSy9h3bp1WL9+Pb766iuYTCbce++9qKurk2syMzNx5swZvPvuuzh+/DgeeughzJkzB4WFhV64WtSXeOuOQ6Btcr3NIWBpsnn8+ERE1A1CQRMmTBBZWVku2xITE8Xy5cs7rF+6dKlITEx02TZv3jwxceJE+efZs2eL6dOnu9RkZGSIuXPnun1eh8MhTCaTyM7Olt9vamoSRqNRbN68Wd4WGhoqtm3b5nKcyMhI8de//rXTz3wts9ksAAiz2ez2PhT49hwrFfHL3hMPb/zcK8e/+bn3Rfyy90TR5SteOT4R0Y3O3e9vxXq0rFYrCgoKkJ6e7rI9PT0dBw8e7HCf/Pz8dvUZGRk4fPgwWlpauqyRjunOeYuKilBeXu5So9frMXXqVJe2TZ48GTt37kR1dTUcDgd27NiB5uZmTJs2rdPP3dzcDIvF4vKiG09tY9vQoTdIvVpVvPOQiEhRigWtyspK2O12xMTEuGyPiYlBeXl5h/uUl5d3WG+z2VBZWdlljXRMd84r/Xu9tu3cuRM2mw1RUVHQ6/WYN28edu/ejREjRnT6udesWQOj0Si/hgwZ0mkt9V3SZHhvDB0CbfO0ajkhnohIUYpPhr92IrAQosvJwR3VX7vdnWN6omblypWoqanBvn37cPjwYSxZsgQ/+clPcPz48U7bv2LFCpjNZvl18eLFTmup7zLLi5V6J2j1lxct5RIPRERK0ih14ujoaKjV6na9VxUVFe16kiQmk6nDeo1Gg6ioqC5rpGO6c16TyQTA2bMVGxvbYc3Zs2exfv16nDhxAqNHjwYAjBkzBvv378eGDRs6vBsScA5B6vX6Tq4K3SjaerS8M3R49Z2HRESkHMV6tHQ6HVJSUpCbm+uyPTc3F5MmTepwn7S0tHb1e/fuxfjx46HVaruskY7pznkTEhJgMplcaqxWK/Ly8uSahoYGAEBQkOslVKvVcDgc178AdEPz5l2HQNscLT6Gh4hIWYr1aAHAkiVLkJmZifHjxyMtLQ2vvfYaiouLkZWVBcA5zFZSUoJt27YBALKysrB+/XosWbIETzzxBPLz87FlyxZs375dPubChQtxxx13YO3atZg1axbeeecd7Nu3DwcOHHD7vCqVCosWLcLq1asxatQojBo1CqtXr0ZISAh++tOfAgASExMxcuRIzJs3Dy+//DKioqLw9ttvIzc3F++9956vLiEFKDloBXt3MjyDFhGRshQNWnPmzEFVVRVeeOEFlJWVITk5GXv27EF8fDwAoKyszGVtq4SEBOzZsweLFy/Ghg0bEBcXh1dffRUPP/ywXDNp0iTs2LEDK1euxHPPPYcRI0Zg586dSE1Ndfu8ALB06VI0NjbiySefRE1NDVJTU7F3716EhYUBALRaLfbs2YPly5fjRz/6Ea5cuYKRI0fib3/7G2bOnOntS0cBrrbRu5PhpdXh+RgeIiJlqYTg0tFKslgsMBqNMJvNCA8PV7o55CM/fHEfLtc14/8WTMboOKPHj//Po6V4anshUhMisXNemsePT0R0o3P3+1vxuw6JbjRCCPmuQ2+vo8WhQyIiZTFoEflYY4sdVrvzhglvLe8gDx1yeQciIkUxaBH5mBR+dOogBGvVXjmH3KPFB0sTESmKQYvIx2qvWhW+q8V5e+PqB0tfaeaDpYmIlMKgReRj3l5DCwCCdWoYtM7/vHnnIRGRchi0iHzM22toSSI5IZ6ISHEMWkQ+5u0HSkukOxqrGbSIiBTDoEXkY+ZG7w8dAm3PO6xl0CIiUgyDFpGPSQ96jvDSGloSKchVc44WEZFiGLSIfKy2tUfLyB4tIqI+j0GLyMek4OP9Hq3WOVr1DFpEREph0CLysba7Dr3co9XaY1bL1eGJiBTDoEXkY7WN3n3OoSQilD1aRERKY9Ai8rFaHy3vwAdLExEpj0GLyIeEED5ZGR5g0CIi8gcMWkQ+dKXZBpvD+ZBnb0+Gjwh1BrmahhY+WJqISCEMWkQ+JPVm6TVBMGjVXj2XFOSsNgcarHavnouIiDrGoEXkQ1LQ8nZvFgCE6NTQaVofLM3hQyIiRTBoEflQbaNvJsIDgEqlQkTreWq4OjwRkSIYtIh8qMZHE+ElnBBPRKQsBi0iHzJLSzsEe3/oEGDQIiJSGoMWkQ/5ukdLet5hDRctJSJSBIMWkQ+1raHlmx4tKdBV8zE8RESKYNAi8iFfToYH2nq0ajl0SESkCAYtIh9qW97BN0FL6jnj8w6JiJTBoEXkQ1LPktFHk+EjW1eHr+XQIRGRIhi0iHyIPVpERDcWBi0iH6pt9O1k+MgQztEiIlISgxaRjzgcQg48vl6wtJpBi4hIEQxaRD5S12yDQzj/b2Owj4JW6xytphYHGvlgaSIin2PQIvIRc+v8rGCtGgat2ifn7KfXQBOkAsDV4YmIlMCgReQjNT4eNgRaHywdysfwEBEphUGLyEd8PRFeIt3hWFPPJR6IiHyNQYvIR+SJ8D6anyXhg6WJiJTDoEXkI+ZG3z5QWsKgRUSkHAYtIh+Rhu58PnQozdHi0CERkc8xaBH5iK8fKC2R52ixR4uIyOcYtIh8RFrewddztCJ51yERkWIYtIh8pFahOVp83iERkXIYtIh8pG0dLd/O0YpsXR1eeqA1ERH5DoMWkY8oNXTYn3cdEhEphkGLyEeUWrA0UgpaHDokIvI5Bi0iH3A4RNuCpQqto1VvtaPZxgdLExH5Uo+CVlFRkafbQdSn1TXb4BDO/9vo46HDMIMG6tYHS3OeFhGRb/UoaI0cORJ33nkn3njjDTQ1NXm6TUR9jjQ/K1irhkGr9um5g4JU8rwwztMiIvKtHgWto0ePYuzYsfjNb34Dk8mEefPm4csvv/R024j6DKUWK5VIq8NziQciIt/qUdBKTk7GunXrUFJSgq1bt6K8vByTJ0/G6NGjsW7dOly+fNnT7SQKaDUNykyEl0irw3PokIjIt3o1GV6j0eDBBx/EP/7xD6xduxZnz57F008/jcGDB+PnP/85ysrKPNVOooAmT4T38fwsSQQXLSUiUkSvgtbhw4fx5JNPIjY2FuvWrcPTTz+Ns2fP4uOPP0ZJSQlmzZrlqXYSBTSzQqvCS6SgVcs5WkREPtWjoLVu3TrccsstmDRpEkpLS7Ft2zZcuHABf/jDH5CQkIDbb78df/7zn3HkyJHrHmvjxo1ISEiAwWBASkoK9u/f32V9Xl4eUlJSYDAYMHz4cGzevLldTU5ODpKSkqDX65GUlITdu3d3+7xCCKxatQpxcXEIDg7GtGnTcPLkyXbHyc/Px1133YXQ0FD0798f06ZNQ2Nj43U/N91YahsUDlryHC0OHRIR+VKPgtamTZvw05/+FMXFxXj77bdx//33IyjI9VBDhw7Fli1bujzOzp07sWjRIjz77LMoLCzElClTMGPGDBQXF3dYX1RUhJkzZ2LKlCkoLCzEM888gwULFiAnJ0euyc/Px5w5c5CZmYmjR48iMzMTs2fPxqFDh7p13pdeegnr1q3D+vXr8dVXX8FkMuHee+9FXV2dy7mmT5+O9PR0fPnll/jqq68wf/78dteCSKnH70ja5mixR4uIyKdEDxQVFQm73d5uu8PhEBcuXHD7OBMmTBBZWVku2xITE8Xy5cs7rF+6dKlITEx02TZv3jwxceJE+efZs2eL6dOnu9RkZGSIuXPnun1eh8MhTCaTyM7Olt9vamoSRqNRbN68Wd6WmpoqVq5c6c5H7ZTZbBYAhNls7tVxyL8t3lEo4pe9JzZ/+p0i59/5VbGIX/aeeOy/DylyfiKivsbd7+8edb2MGDEClZWV7bZXV1cjISHBrWNYrVYUFBQgPT3dZXt6ejoOHjzY4T75+fnt6jMyMnD48GG0tLR0WSMd053zFhUVoby83KVGr9dj6tSpck1FRQUOHTqEgQMHYtKkSYiJicHUqVNx4MCBLj93c3MzLBaLy4v6vlo/maNVw7sOiYh8qkdBSwjR4fYrV67AYDC4dYzKykrY7XbExMS4bI+JiUF5eXmH+5SXl3dYb7PZ5ODXWY10THfOK/3bVc25c+cAAKtWrcITTzyBDz74AOPGjcPdd9+Nb7/9ttPPvWbNGhiNRvk1ZMiQTmup75CGDo3BygwdRoa2LljKuw6JiHxK053iJUuWAABUKhV++9vfIiQkRH7Pbrfj0KFDuO2227rVAJVK5fKzEKLdtuvVX7vdnWP2tsbhcAAA5s2bh1/84hcAgLFjx+Kjjz7Cf//3f2PNmjUdtn/FihXydQQAi8XCsHUDkFaGj1CoR6u/3KPFoEVE5EvdClqFhYUAnIHj+PHj0Ona/jrX6XQYM2YMnn76abeOFR0dDbVa3a73qqKiol1PksRkMnVYr9FoEBUV1WWNdEx3zmsymQA4e7ZiY2M7rJG2JyUluRzn5ptv7nQyP+AcgtTr9Z2+T31T29ChQj1areeta7Khxe6AVs0bNoiIfKFb/2v7ySef4JNPPsFjjz2G999/X/75k08+wYcffog///nPGDVqlFvH0ul0SElJQW5ursv23NxcTJo0qcN90tLS2tXv3bsX48ePh1ar7bJGOqY7501ISIDJZHKpsVqtyMvLk2uGDRuGuLg4nDlzxuU433zzDeLj4926BnRjcDhE24KlCvVohQdrIXXQcnV4IiIf8vas/K7s2LFDaLVasWXLFnHq1CmxaNEiERoaKs6fPy+EEGL58uUiMzNTrj937pwICQkRixcvFqdOnRJbtmwRWq1WvPXWW3LN559/LtRqtcjOzhanT58W2dnZQqPRiC+++MLt8wohRHZ2tjAajWLXrl3i+PHj4pFHHhGxsbHCYrHINX/6059EeHi4ePPNN8W3334rVq5cKQwGg/juO/fvLONdh31fbYNVxC97T8Qve080Wm2KteO2330o4pe9J86UW65fTEREXXL3+9vtocOHHnoIr7/+OsLDw/HQQw91Wbtr1y63jjlnzhxUVVXhhRdeQFlZGZKTk7Fnzx65R6isrMxlGC4hIQF79uzB4sWLsWHDBsTFxeHVV1/Fww8/LNdMmjQJO3bswMqVK/Hcc89hxIgR2LlzJ1JTU90+LwAsXboUjY2NePLJJ1FTU4PU1FTs3bsXYWFhcs2iRYvQ1NSExYsXo7q6GmPGjEFubi5GjBjh1uenG4M0PytYq4ZBq1asHREhOtQ0tHBCPBGRD6mE6OQWwmv84he/wKuvvoqwsDB58ndntm7d6pHG3QgsFguMRiPMZjPCw8OVbg55wbFLtXhg/eeINRqQv+Juxdrx8KaDKLhQg80/G4fpybHX34GIiDrl7ve32z1aV4cnBiki90lzoowKPVBaIt3xyLW0iIh8p0e3HjU2NqKhoUH++cKFC3jllVewd+9ejzWMqK+QllSIUOiOQ4l0/moOHRIR+UyPgtasWbOwbds2AEBtbS0mTJiAP/7xj5g1axY2bdrk0QYSBTqzwqvCS6QHS/N5h0REvtOjoHXkyBFMmTIFAPDWW2/BZDLhwoUL2LZtG1599VWPNpAo0ElDh4oHLblHi0OHRES+0qOg1dDQIN99t3fvXjz00EMICgrCxIkTceHCBY82kCjQKf34HYk0R4s9WkREvtOjoDVy5Ei8/fbbuHjxIj788EP54csVFRW8c47oGko/fkciDR1WM2gREflMj4LWb3/7Wzz99NMYNmwYUlNTkZaWBsDZuzV27FiPNpAo0NX6yxytEGmOFocOiYh8pVvPOpT827/9GyZPnoyysjKMGTNG3n733XfjwQcf9FjjiPqCWj8ZOowMdQY93nVIROQ7PQpagPPBy9LDlyUTJkzodYOI+ppaPxk6lB5obWlqgc3ugIYPliYi8roeBa36+npkZ2fjo48+QkVFBRwOh8v7586d80jjiPqCtqFDZXu0+rcumCqEc8mJqH56RdtDRHQj6FHQ+tWvfoW8vDxkZmYiNjYWKpXK0+0i6hMcDiEPHSo9R0ujDkK4QQNLkw01DQxaRES+0KOg9f777+P//u//cPvtt3u6PUR9yhWrDY7Wp4kq/QgeAIgM1bUGLc7TIiLyhR5N0oiIiEBkZKSn20LU59S2Lg4arFXDoFUr3Jq24csaTognIvKJHgWt3//+9/jtb3/r8rxDImqvttE/hg0lka1rabFHi4jIN3o0dPjHP/4RZ8+eRUxMDIYNGwat1vVL5MiRIx5pHFGgk+449IdhQ6At8NVwLS0iIp/oUdD68Y9/7OFmEPVNNX4yEV4SyaFDIiKf6lHQev755z3dDqI+ydworaGl7NIOkggOHRIR+VSPVyysra3FX//6V6xYsQLV1dUAnEOGJSUlHmscUaCThg79pUdLCnzV9Rw6JCLyhR71aB07dgz33HMPjEYjzp8/jyeeeAKRkZHYvXs3Lly4gG3btnm6nUQBqW2Olp/0aLUGvlr2aBER+USPerSWLFmCxx9/HN9++y0MBoO8fcaMGfjss8881jiiQOcvi5VKpKHDagYtIiKf6FHQ+uqrrzBv3rx22wcNGoTy8vJeN4qor5DmQkX6yxyt1nbU8q5DIiKf6FHQMhgMsFgs7bafOXMGAwYM6HWjiPqKar+bo9U2dOiQlqwnIiKv6VHQmjVrFl544QW0tDi/RFQqFYqLi7F8+XI8/PDDHm0gUSCTllGQFgpVmrQyvEMAlib2ahEReVuPgtbLL7+My5cvY+DAgWhsbMTUqVMxcuRIhIWF4cUXX/R0G4kCljR0GOEnQUunCUI/vfMeGC5aSkTkfT266zA8PBwHDhzAJ598goKCAjgcDowbNw733HOPp9tHFLBa7A7UNdkA+M8cLQCICNXiSrMN1fVWJESHKt0cIqI+rdtBy+Fw4PXXX8euXbtw/vx5qFQqJCQkwGQyQQgBlUrljXYSBRypNytIBYT7ySN4AOeE+IvVjVzigYjIB7o1dCiEwAMPPIBf/epXKCkpwS233ILRo0fjwoULePzxx/Hggw96q51EAaemvu05h+og//kDpG3RUgYtIiJv61aP1uuvv47PPvsMH330Ee68806X9z7++GP8+Mc/xrZt2/Dzn//co40kCkT+Nj9L0nbnIedoERF5W7d6tLZv345nnnmmXcgCgLvuugvLly/H3//+d481jiiQyXcc+tH8LICLlhIR+VK3gtaxY8cwffr0Tt+fMWMGjh492utGEfUF1X7boyUtWsqgRUTkbd0KWtXV1YiJien0/ZiYGNTU1PS6UUR9gdSjFeEni5VK5B4tztEiIvK6bgUtu90OjabzaV1qtRo2m63XjSLqC6R1qvyvR8sZ/LiOFhGR93VrMrwQAo8//jj0en2H7zc3N3ukUUR9gb/O0ZLaU8MeLSIir+tW0HrssceuW8M7Domc/HWOlvQYHvZoERF5X7eC1tatW73VDqI+p22Oln8FLem5i7UNVi4yTETkZT161iERXZ/UoxUZ6l+T4fu3ztGyOQTqmjmnkojImxi0iLyktnVleH/r0TJo1QjRqQFwnhYRkbcxaBF5gdXmkHuLIv1sjhbQFv44T4uIyLsYtIi8oPbqB0ob/GvoEAAiWocz2aNFRORdDFpEXiDNz+ofokOQHz1QWtLWo8WgRUTkTQxaRF5QI8/P8r/eLKAtaHF1eCIi72LQIvKCGvmOQ/+bnwW0BcBaztEiIvIqBi0iL5B6ivr72R2HEvl5hxw6JCLyKgYtIi/w18fvSKShw1oGLSIir2LQIvICf32gtETu0eIcLSIir2LQIvKCGj9dFV4SycnwREQ+waBF5AX+PkcrOszZrsorDFpERN7EoEXkBXKPlr8GrX56AM522uwOhVtDRNR3MWgReYEUtPx2jlaIDkEqQAgOHxIReZPiQWvjxo1ISEiAwWBASkoK9u/f32V9Xl4eUlJSYDAYMHz4cGzevLldTU5ODpKSkqDX65GUlITdu3d3+7xCCKxatQpxcXEIDg7GtGnTcPLkyQ7bJITAjBkzoFKp8Pbbb7v/4anPqr7i3+toqYNUiAx19mpdvtKscGuIiPouRYPWzp07sWjRIjz77LMoLCzElClTMGPGDBQXF3dYX1RUhJkzZ2LKlCkoLCzEM888gwULFiAnJ0euyc/Px5w5c5CZmYmjR48iMzMTs2fPxqFDh7p13pdeegnr1q3D+vXr8dVXX8FkMuHee+9FXV1du3a98sorUKn87zErpIxGqx31VjsAIKqffwYtAIjux3laREReJxQ0YcIEkZWV5bItMTFRLF++vMP6pUuXisTERJdt8+bNExMnTpR/nj17tpg+fbpLTUZGhpg7d67b53U4HMJkMons7Gz5/aamJmE0GsXmzZtd9vv666/F4MGDRVlZmQAgdu/efZ1P7cpsNgsAwmw2d2s/8l8Xq+tF/LL3xKhn9giHw6F0czr1s79+IeKXvSfeOnxR6aYQEQUcd7+/FevRslqtKCgoQHp6usv29PR0HDx4sMN98vPz29VnZGTg8OHDaGlp6bJGOqY75y0qKkJ5eblLjV6vx9SpU13a1tDQgEceeQTr16+HyWTqzsenPkya8xTVT+fXPZ3ShPhKDh0SEXmNRqkTV1ZWwm63IyYmxmV7TEwMysvLO9ynvLy8w3qbzYbKykrExsZ2WiMd053zSv92VHPhwgX558WLF2PSpEmYNWuWux8bzc3NaG5u+2KzWCxu70uBocrP52dJ2oYOGbSIiLxFsaAlufYvfiFEl70AHdVfu92dY/a25t1338XHH3+MwsLCTtvakTVr1uB3v/tdt/ahwCIFl6jWHiN/1dajxTlaRETeotjQYXR0NNRqdbveq4qKinY9SRKTydRhvUajQVRUVJc10jHdOa80DNhVzccff4yzZ8+if//+0Gg00GicmfXhhx/GtGnTOv3cK1asgNlsll8XL17stJYCU1Xr0GG03/dotd51WMceLSIib1EsaOl0OqSkpCA3N9dle25uLiZNmtThPmlpae3q9+7di/Hjx0Or1XZZIx3TnfMmJCTAZDK51FitVuTl5ck1y5cvx7Fjx/D111/LLwD405/+hK1bt3b6ufV6PcLDw11e1LdcPUfLn0WHcY4WEZG3KTp0uGTJEmRmZmL8+PFIS0vDa6+9huLiYmRlZQFw9v6UlJRg27ZtAICsrCysX78eS5YswRNPPIH8/Hxs2bIF27dvl4+5cOFC3HHHHVi7di1mzZqFd955B/v27cOBAwfcPq9KpcKiRYuwevVqjBo1CqNGjcLq1asREhKCn/70pwCcvV4dTYAfOnQoEhISvHbNyP9JwUVap8pfDeBkeCIir1M0aM2ZMwdVVVV44YUXUFZWhuTkZOzZswfx8fEAgLKyMpe1rRISErBnzx4sXrwYGzZsQFxcHF599VU8/PDDcs2kSZOwY8cOrFy5Es899xxGjBiBnTt3IjU11e3zAsDSpUvR2NiIJ598EjU1NUhNTcXevXsRFhbmgytDgUyaDO//PVptD5a2OwTUQf57hyQRUaBSCWk2OSnCYrHAaDTCbDZzGLGP+NF/HcDxEjP++/HxuCux4/mG/sBmd2DUyvchBPDVs/dgQJh/98AREfkTd7+/FX8ED1FfUyXddejnQ4cadZD80GsOHxIReQeDFpEHCSFQWR8Y62gBXLSUiMjbGLSIPOhKsw1WmwOA/8/RAtrmaTFoERF5B4MWkQdJSzuE6NQI0Sm+HvB1yT1adVy0lIjIGxi0iDyoMkDuOJRw6JCIyLsYtIg8qCpA1tCScHV4IiLvYtAi8qDqAHn8jkR6sPRl9mgREXkFgxaRB1UFyON3JG2P4eEcLSIib2DQIvKgQHn8joSP4SEi8i4GLSIPkh6/Ex0oPVqtQau63gqHgw+JICLyNAYtIg+qqm9dFT5AglZUPx1UKsDuEKhu4PAhEZGnMWgReZB0996AfgaFW+IerToIUa0T9yssHD4kIvI0Bi0iD5KC1sDwwJijBQADw5yh8Pu6JoVbQkTU9zBoEXmI1eZATUMLgLZJ5oEgpjUUVlgYtIiIPI1Bi8hDpDv3tGoVjMFahVvjvpjw1h4tDh0SEXkcgxaRh0jDhtH99AgKUincGvcNlIMWe7SIiDyNQYvIQ+SJ8GGBM2wItA0dskeLiMjzGLSIPKRCmggfaEGrdTJ8BSfDExF5HIMWkYcEbo8Whw6JiLyFQYvIQy5fcQaVQLrjEGgbOrxc1ww7V4cnIvIoBi0iDwnUHq2ofnqog1RwCKCKzzwkIvIoBi0iD6mQg1ZgrAovUQep5F44TognIvIsBi0iDwnUHi2gbfiwnPO0iIg8ikGLyAOEEG2P3wnAoMW1tIiIvINBi8gD6pptaLY5ADgXLA00fAwPEZF3MGgReUBF69ymML0GwTq1wq3pPmktLc7RIiLyLAYtIg+Q52eFB15vFnDVWlpctJSIyKMYtIg84HLrsgiBtoaWZKA0Gd7MoEVE5EkMWkQeEMh3HAKAycjJ8ERE3sCgReQB0iTyQA1acf2DAQA1DS1otNoVbg0RUd/BoEXkAdL6U7HGwFqsVBJu0KKfXgMAKDU3KtwaIqK+g0GLyAPKWuc2mYzBCrek5+L6O0NiaS2DFhGRpzBoEXmANLfJFB6YPVoAENsaEstqOU+LiMhTGLSIekkIIfdoBerQIdA2T6uEPVpERB7DoEXUSzUNLbC2rgo/MEDX0QKAQRw6JCLyOAYtol6S1p6KCtVBrwm8VeEl8tAh19IiIvIYBi2iXiq3OHuATAE8bAi0DR2yR4uIyHMYtIh6qdzsXKw0kOdnAcCgq+ZoCSEUbg0RUd/AoEXUS+XmvtGjFWN0zi9rtjlQ09CicGuIiPoGBi2iXpLX0ArgpR0AQK9Ryyvbc/iQiMgzGLSIeklaFT6QFyuVcIkHIiLPYtAi6qXyPrCGliSu9TOUMWgREXkEgxZRL0lBKybAhw6Bq+485BIPREQewaBF1AtXmm2oa7YBCPzJ8MBVQ4c17NEiIvIEBi2iXpB6s8IMGvTTaxRuTe8NiXAGrYs1DQq3hIiob2DQIuqFvjQ/CwCGRoUAAIqrGbSIiDyBQYuoF0rlNbQC/45DABgS4QxatQ0tMDdyLS0iot5i0CLqhUutc5kGR/SNoBWq1yC6n3MtrYvs1SIi6jUGLaJeuNQ6l6mvBC0AGBrp/CwcPiQi6j0GLaJekO7Ok54T2BcMjeQ8LSIiT1E8aG3cuBEJCQkwGAxISUnB/v37u6zPy8tDSkoKDAYDhg8fjs2bN7erycnJQVJSEvR6PZKSkrB79+5un1cIgVWrViEuLg7BwcGYNm0aTp48Kb9fXV2Np556CjfddBNCQkIwdOhQLFiwAGazuYdXggJR29BhiMIt8RwpaF2oYtAiIuotRYPWzp07sWjRIjz77LMoLCzElClTMGPGDBQXF3dYX1RUhJkzZ2LKlCkoLCzEM888gwULFiAnJ0euyc/Px5w5c5CZmYmjR48iMzMTs2fPxqFDh7p13pdeegnr1q3D+vXr8dVXX8FkMuHee+9FXV0dAKC0tBSlpaV4+eWXcfz4cbz++uv44IMP8Mtf/tJLV4v8jc3ukB+/06eGDqNCAXCOFhGRRwgFTZgwQWRlZblsS0xMFMuXL++wfunSpSIxMdFl27x588TEiRPln2fPni2mT5/uUpORkSHmzp3r9nkdDocwmUwiOztbfr+pqUkYjUaxefPmTj/PP/7xD6HT6URLS0unNdcym80CgDCbzW7vQ/6huKpexC97T4x6Zo+w2x1KN8djDp2rEvHL3hNT1n6sdFOIiPyWu9/fivVoWa1WFBQUID093WV7eno6Dh482OE++fn57eozMjJw+PBhtLS0dFkjHdOd8xYVFaG8vNylRq/XY+rUqZ22DQDMZjPCw8Oh0XS+cGVzczMsFovLiwKT9ODlQRHBCApSKdwaz5GGDktqG9FidyjcGiKiwKZY0KqsrITdbkdMTIzL9piYGJSXl3e4T3l5eYf1NpsNlZWVXdZIx3TnvNK/3WlbVVUVfv/732PevHmdfmYAWLNmDYxGo/waMmRIl/Xkvy71wYnwADAwTA+9Jgh2h0BZLZ95SETUG4pPhlepXHsChBDttl2v/trt7hzTUzUAYLFYcN999yEpKQnPP/98p20HgBUrVsBsNsuvixcvdllP/qsvLu0AAEFBKgzhnYdERB6hWNCKjo6GWq1u10NUUVHRridJYjKZOqzXaDSIiorqskY6pjvnNZlMAOBW2+rq6jB9+nT069cPu3fvhlar7fJz6/V6hIeHu7woMPW1xUqvJt95WF2vcEuIiAKbYkFLp9MhJSUFubm5Lttzc3MxadKkDvdJS0trV793716MHz9eDjid1UjHdOe8CQkJMJlMLjVWqxV5eXkubbNYLEhPT4dOp8O7774Lg6FvPO+O3CP19vSlpR0k8a3PPDxfyaBFRNQbnc/a9oElS5YgMzMT48ePR1paGl577TUUFxcjKysLgHOYraSkBNu2bQMAZGVlYf369ViyZAmeeOIJ5OfnY8uWLdi+fbt8zIULF+KOO+7A2rVrMWvWLLzzzjvYt28fDhw44PZ5VSoVFi1ahNWrV2PUqFEYNWoUVq9ejZCQEPz0pz8F4OzJSk9PR0NDA9544w2Xie0DBgyAWq32yTUk5VyocoaQYdGhCrfE80YM6AcA+K7iisItISIKbIoGrTlz5qCqqgovvPACysrKkJycjD179iA+Ph4AUFZW5rK2VUJCAvbs2YPFixdjw4YNiIuLw6uvvoqHH35Yrpk0aRJ27NiBlStX4rnnnsOIESOwc+dOpKamun1eAFi6dCkaGxvx5JNPoqamBqmpqdi7dy/CwsIAAAUFBfLaXCNHjnT5XEVFRRg2bJjHrxf5j0arHd9bmgEAw6L6Xo+WFLTOXmaPFhFRb6iENJucFGGxWGA0GuWlISgwnCmvQ8Yrn8EYrMXR59Ovv0OAuVzXjB++uA8qFXD6hekwaNlDS0R0NXe/vxW/65AoEJ1vHTaM74O9WQAQ3U+HcIMGQgBFnKdFRNRjDFpEPXBBDlp9b34W4JynOGKgNHzIeVpERD3FoEXUA+dbH7jcF+dnSUZK87Qq2KNFRNRTDFpEPdDXe7QAyD1a37FHi4ioxxi0iHrgfGXf79GS7zzkEg9ERD3GoEXUTU0tdpSanavCD+3DQWtka4/WucorcDh4czIRUU8waBF1U1FlPYQAwgwaDOinV7o5XjMkIhhatQpNLQ6U1DYq3RwiooDEoEXUTdJq6aMG9uvyAeiBTqMOwrDWOWhcIZ6IqGcYtIi6SQod0tBaX5YY61yE73S5ReGWEBEFJgYtom6S7sK7EYLWzbHOR06dLqtTuCVERIGJQYuom777Xho6DFO4Jd53s9SjVcYeLSKinmDQIuoGm90hP5LmRujRSmoNWucuX0FTi13h1hARBR4GLaJuuFjTCKvdAYM2CIP6ByvdHK8bGKZHZKgODgF88z2HD4mIuotBi6gbpInwIwb0Q1BQ373jUKJSqa6ap8XhQyKi7mLQIuqGM6133/0gpu/Pz5LcbHIOH54qZdAiIuouBi2ibjjV2qsjzV26Edwy2AgAOFZiVrglRESBh0GLqBtOtvbqJMXdOEFrzOD+AJyf3WpzKNsYIqIAw6BF5Ka6phZcqHI+TPpG6tGKjwqBMVgLq82Bf3HhUiKibmHQInLTv8qdd93FGQ2ICNUp3BrfUalUGDOkPwDg6MVaRdtCRBRoGLSI3HTqBhw2lNzWGrS+vsh5WkRE3cGgReQmOWjdQMOGktuGOCfEf32xRuGWEBEFFgYtIjdJd93diD1a0oT4s5frUVNvVbYxREQBhEGLyA31zTZ5Da2xQyMUbo3vRfXTy48c+vJ8tcKtISIKHAxaRG44eqkWDgEM6h+MmHCD0s1RRGpCJADg0DkGLSIidzFoEbmhsLgWAHDb0P6KtkNJqcOjAACHiqoUbgkRUeBg0CJyQ2GxcxL4uBtw2FAysbVH61SZBebGFoVbQ0QUGBi0iK5DCIEjrT1aY2/gHq2B4QYMjw6FEMCXRRw+JCJyB4MW0XWcq6xHdb0VOk0QRt+Adxxe7faR0QCAvG8qFG4JEVFgYNAiuo6D31UCAFKGRkCvUSvcGmXdmTgAAPDJvy5DCKFwa4iI/B+DFtF1fP6dc/L37SOjFG6J8tKGR0OnCUJJbSO+q7iidHOIiPwegxZRF+wOgYNnnT1ak1qHzW5kwTo10lrvPvzkDIcPiYiuh0GLqAsnS82wNNkQptfg1kFGpZvjF+68yTl8mHvqe4VbQkTk/xi0iLqw/1tnb1bq8Eho1PzPBQAykk0AgK/O16DM3Khwa4iI/Bu/OYi68OHJcgDAXYkxCrfEf8Qag/HDYc71xP7vWJnCrSEi8m8MWkSdKK1txLFLZqhUwL1JDFpXu//WOADAPxm0iIi6xKBF1AlpDlLK0AgMCNMr3Br/MuMWE4JUwNGLtbz7kIioCwxaRJ14/4SztyZ9NHuzrjUwzIC7EgcCALZ/Waxwa4iI/BeDFlEHLlY34Itz1VCpgBnJsUo3xy89mhoPAHir4BKaWuwKt4aIyD8xaBF14K2CSwCA20dEY0hkiMKt8U93/GAABvUPhrmxBe98XaJ0c4iI/BKDFtE1HA4hB62fjB+scGv8lzpIhccmOXu1Nn16FnYHH8lDRHQtBi2ia+Se/h4ltY0IN2iQMdqkdHP82qOp8egfosX5qga8d6xU6eYQEfkdBi2iqwghsPHTswCAn02Mh0F7Yz9E+npC9Rr88vYEAMAr+76F1eZQuEVERP6FQYvoKvlnq3D0Yi30miD8ojVAUNcev30YovvpUVRZj62fFyndHCIiv8KgRdTK7hBY8/6/AABzfjiEa2e5KcygxfIZiQCAVz/6FherGxRuERGR/2DQImr15uGLOF5iRphegwV3j1K6OQHlobGDMD4+AvVWO5b842tOjCciaqVRugFE/qCktlHuzVp07w8Q3Y+9Wd0RFKTCutm3Year+/HV+Rq89OG/sGLGzUo3i6jb6pttKKltRG1DC8yNLWixO6BTB0GvDUJkqA6D+gfDGKyFSqVSuqkUIBi06IZntTmwYHshzI0tGDOkP36eFq90kwLS0KgQrH7oFizYXog/553D4P7ByEwbpnSziDpldwgcLzHj8+8q8cW5Knz7/RWUW5quu18/vQaJpjAkDzLi1sFGTEiIxOAIrrdHHWPQohuawyHw9JtHUXChBmF6Df5r7lho1RxR76kHxsSh6HI9/rTvGzz3zkk02xz41ZThSjeLSFZc1YD9313GgW8rcfBsFcyNLe1qjMFaRIbqEB6shV4dhGa7A80tdlyua0ZVvRVXmm04fKEGhy/UyPskRIfi9pFRmDxyACaNjEK4QevLj0V+TCWE4GQKBVksFhiNRpjNZoSHhyvdnBtKU4sdS986hnePlkITpMJfHhuPO28aqHSzAp4QzpsKXvvsHADg31IG43cPjEaonn/Xke+ZG1pw8Gwl9n9XiQPfVqL4mps1wvQapI2IwuRR0UgeZMTw6FD0D9F1erymFjuKqxtwosSMY5fMOHqpFscumV3mJaqDVBg3tD/uGDUAU28agOQ4I4KCONTY17j7/a140Nq4cSP+8z//E2VlZRg9ejReeeUVTJkypdP6vLw8LFmyBCdPnkRcXByWLl2KrKwsl5qcnBw899xzOHv2LEaMGIEXX3wRDz74YLfOK4TA7373O7z22muoqalBamoqNmzYgNGjR8s1zc3NePrpp7F9+3Y0Njbi7rvvxsaNGzF4sPuriTNoKeNUqQX/8dZRnCy1QBOkwp/m3IYfjYlTull9hhACr312Dms/+BccAjCFG7BiZiLuvzUOan7hkBc1Wu0ouFCD/HOVOPBdFY5fqsXV92ZoglQYNzQCk0dFY/KoaNw6yAhNL3uxLU0tOHSuGge+vYz931Xi3OV6l/cjQ3WYMioad4wagCk/iMbAMEOvzkf+ISCC1s6dO5GZmYmNGzfi9ttvx5///Gf89a9/xalTpzB06NB29UVFRUhOTsYTTzyBefPm4fPPP8eTTz6J7du34+GHHwYA5OfnY8qUKfj973+PBx98ELt378Zvf/tbHDhwAKmpqW6fd+3atXjxxRfx+uuv4wc/+AH+8Ic/4LPPPsOZM2cQFhYGAPj1r3+Nf/7zn3j99dcRFRWF3/zmN6iurkZBQQHUavcWumTQ8h0hBE6WWvCX/efwz6OlcAigf4gWGx8dh0kjopVuXp+Uf7YKS3OO4mJ1IwBgaGQIfjZxKKaPjsXQKM5pod4RQuBSTSNOlppxvMSML4uq8fXFWrTYXb/WRg7sh8kjozFlVDRSh0ehn5d7Vy9WN+Czby/js28u4/PvqnCl2ebyfqIpDOPiIzBmsBFjhvTHqIFh/AMkAAVE0EpNTcW4ceOwadMmedvNN9+MH//4x1izZk27+mXLluHdd9/F6dOn5W1ZWVk4evQo8vPzAQBz5syBxWLB+++/L9dMnz4dERER2L59u1vnFUIgLi4OixYtwrJlywA4e69iYmKwdu1azJs3D2azGQMGDMD//M//YM6cOQCA0tJSDBkyBHv27EFGRoZb14BBy3uuNNtwqaYBp8ssOHrRjLxvLqOosu0vzZm3mLDqgdH869LLmlrs+Mtn5/DXA0Uu82FGDeyHcUMjcMtg53DNoIhgxBqDodNwjhw5ORwC5sYWVNVbUXWlGeWWJlyoamh91eO7y1dQ29B+jlWc0YCJI6KQNtw5JBhrDFag9U4tdgcKi2uR900FPvumEsdLzO1qDNogDIsKxfABoUiIDsWwqFAMDDdgQD89osN0iArVM4j5IXe/vxWbNGG1WlFQUIDly5e7bE9PT8fBgwc73Cc/Px/p6eku2zIyMrBlyxa0tLRAq9UiPz8fixcvblfzyiuvuH3eoqIilJeXu5xLr9dj6tSpOHjwIObNm4eCggK0tLS41MTFxSE5ORkHDx7sNGg1NzejublZ/tlisXRY11vvHSvF4fNtEzWvztNC3ib9LK75GVft57qXXHPNvh3t367mqgO31YgO9+mqBh2c22oTuNLcgvpmO64021Bdb+1wkqtOE4R7k2Lw66kjkDzI2O598jyDVo2n7h6FX05JwO7CErx3tAxfnq/GtxVX8G3FFew8fFGuVamAcIMWYQYNwlr/NWjV0KlV0AQFQaNWQasOglatav3iUcn7qa46BgCornoPuPp9976wrv0btOP/LqT32v930NF+7d8Xnb7X1Tna1XZxjmv36+i/w7b9uvOZ3duv/Tld37U7BJpaHGhssaOpxY5Gqx2Nrf/WNrZcd002rVqFm0xhSI4zYuzQ/kgbHo0hkcF+s/yCVh2ECQmRmJAQif/IACqvNOPLomocvVSLoxdrcfySGfVWO/5VXod/ldd1eIwglfNOx1C9BiE6NUJ0zn+DdWpogoKgDkLrvyr5pQlSIShIhauvwrWX5Op327939X6dX0s/uczXdf+tsUiJj1Tk3IoFrcrKStjtdsTExLhsj4mJQXl5eYf7lJeXd1hvs9lQWVmJ2NjYTmukY7pzXunfjmouXLgg1+h0OkRERLjdfgBYs2YNfve733X6vqccPFuF/z1U7PXz+DtjsBYjBoTitiERSImPwNSbBnh92IA6FqLT4NHUeDyaGo/aBiu+OFeNEyVmnCg142J1Ay7VNKLZ5oC5saU1JDcq3WTyE+EGDaL66TEgTI/4yBDER4UgPsrZ+zMqph/0msB5Jml0Pz1m3hKLmbfEAnAGzeLqBhRVXsG5y/UoqqxHcXUDLtc1o/KK8y5HhwAsTTZYmmzXOTp1ZtTAsBsvaEmuTcpCiOuk5/b1125355ieqrnW9WpWrFiBJUuWyD9bLBYMGTKky2P2xLQfDEBk650z1/5Ff/XG6/UCdFjT7jpdXdtZL0LnNW3HcW1Tx8fp+PgadRD66TXOl0EDY7AWcf2DGar8VP8QHaYnmzA92SRvE0Kgqt6K2oYWWJpaUNdkQ11TC5paHLDZHWhxCNjsDtjsAla7Aw5HW0/ndXtnO+k5FRBu/1V/bcG173X0O+7OcTv776AjPe+R6Hy/jt7vrD1df+bO9+uqVqVSIVjr7J0xaINg0KrlnyNCdIgI0fXp4WR1kAoJ0c7QeFdi+/dtdgeqG6yoa7KhodmOeqsNjVbnvw1WOxwOAZtDwN76b9vPDtgcnfeCAh31PHbdM3m9XlZ/NjpOuak5in0LRUdHQ61Wt+v9qaioaNeTJDGZTB3WazQaREVFdVkjHdOd85pMzv/xLy8vR2xsbKc1VqsVNTU1Lr1aFRUVmDRpUqefW6/XQ6/3/qrj6aNNSB9tun4hkZ9QqVSI7qfnqvxEV9GogzAwzICBYUq3hHpKsT8TdDodUlJSkJub67I9Nze306CSlpbWrn7v3r0YP348tFptlzXSMd05b0JCAkwmk0uN1WpFXl6eXJOSkgKtVutSU1ZWhhMnTnQZtIiIiOgGIhS0Y8cOodVqxZYtW8SpU6fEokWLRGhoqDh//rwQQojly5eLzMxMuf7cuXMiJCRELF68WJw6dUps2bJFaLVa8dZbb8k1n3/+uVCr1SI7O1ucPn1aZGdnC41GI7744gu3zyuEENnZ2cJoNIpdu3aJ48ePi0ceeUTExsYKi8Ui12RlZYnBgweLffv2iSNHjoi77rpLjBkzRthsNrevgdlsFgCE2Wzu0TUkIiIi33P3+1vRoCWEEBs2bBDx8fFCp9OJcePGiby8PPm9xx57TEydOtWl/tNPPxVjx44VOp1ODBs2TGzatKndMd98801x0003Ca1WKxITE0VOTk63ziuEEA6HQzz//PPCZDIJvV4v7rjjDnH8+HGXmsbGRjF//nwRGRkpgoODxf333y+Ki4u79fkZtIiIiAKPu9/fiq8Mf6PjOlpERESBx93v7757KwcRERGRwhi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISzRKN+BGJy3Mb7FYFG4JERERuUv63r7eA3YYtBRWV1cHABgyZIjCLSEiIqLuqqurg9Fo7PR9PutQYQ6HA6WlpQgLC4NKpVK6OT1msVgwZMgQXLx4kc9s7CVeS8/htfQcXkvP4bX0HCWvpRACdXV1iIuLQ1BQ5zOx2KOlsKCgIAwePFjpZnhMeHg4/4fDQ3gtPYfX0nN4LT2H19JzlLqWXfVkSTgZnoiIiMhLGLSIiIiIvIRBizxCr9fj+eefh16vV7opAY/X0nN4LT2H19JzeC09JxCuJSfDExEREXkJe7SIiIiIvIRBi4iIiMhLGLSIiIiIvIRBi4iIiMhLGLQIAHD+/Hn88pe/REJCAoKDgzFixAg8//zzsFqtLnXFxcX40Y9+hNDQUERHR2PBggXtao4fP46pU6ciODgYgwYNwgsvvNDuWVB5eXlISUmBwWDA8OHDsXnz5nZtysnJQVJSEvR6PZKSkrB7927Pf3A/tHHjRiQkJMBgMCAlJQX79+9Xukk+s2bNGvzwhz9EWFgYBg4ciB//+Mc4c+aMS40QAqtWrUJcXByCg4Mxbdo0nDx50qWmubkZTz31FKKjoxEaGooHHngAly5dcqmpqalBZmYmjEYjjEYjMjMzUVtb61Ljzu97oFizZg1UKhUWLVokb+O1dF9JSQl+9rOfISoqCiEhIbjttttQUFAgv89r6R6bzYaVK1fK3zXDhw/HCy+8AIfDIdf0uWspiIQQ77//vnj88cfFhx9+KM6ePSveeecdMXDgQPGb3/xGrrHZbCI5OVnceeed4siRIyI3N1fExcWJ+fPnyzVms1nExMSIuXPniuPHj4ucnBwRFhYmXn75Zbnm3LlzIiQkRCxcuFCcOnVK/OUvfxFarVa89dZbcs3BgweFWq0Wq1evFqdPnxarV68WGo1GfPHFF765IArZsWOH0Gq14i9/+Ys4deqUWLhwoQgNDRUXLlxQumk+kZGRIbZu3SpOnDghvv76a3HfffeJoUOHiitXrsg12dnZIiwsTOTk5Ijjx4+LOXPmiNjYWGGxWOSarKwsMWjQIJGbmyuOHDki7rzzTjFmzBhhs9nkmunTp4vk5GRx8OBBcfDgQZGcnCzuv/9++X13ft8DxZdffimGDRsmbr31VrFw4UJ5O6+le6qrq0V8fLx4/PHHxaFDh0RRUZHYt2+f+O677+QaXkv3/OEPfxBRUVHivffeE0VFReLNN98U/fr1E6+88opc09euJYMWdeqll14SCQkJ8s979uwRQUFBoqSkRN62fft2odfrhdlsFkIIsXHjRmE0GkVTU5Ncs2bNGhEXFyccDocQQoilS5eKxMREl3PNmzdPTJw4Uf559uzZYvr06S41GRkZYu7cuZ77gH5owoQJIisry2VbYmKiWL58uUItUlZFRYUAIPLy8oQQQjgcDmEymUR2drZc09TUJIxGo9i8ebMQQoja2lqh1WrFjh075JqSkhIRFBQkPvjgAyGEEKdOnRIAXIJ7fn6+ACD+9a9/CSHc+30PBHV1dWLUqFEiNzdXTJ06VQ5avJbuW7ZsmZg8eXKn7/Nauu++++4T//7v/+6y7aGHHhI/+9nPhBB981py6JA6ZTabERkZKf+cn5+P5ORkxMXFydsyMjLQ3Nwsd6Hn5+dj6tSpLovHZWRkoLS0FOfPn5dr0tPTXc6VkZGBw4cPo6WlpcuagwcPevQz+hOr1YqCgoJ2nzs9Pb1Pf+6umM1mAJB/D4uKilBeXu5yjfR6PaZOnSpfo4KCArS0tLjUxMXFITk5Wa7Jz8+H0WhEamqqXDNx4kQYjUaXmuv9vgeC//f//h/uu+8+3HPPPS7beS3d9+6772L8+PH4yU9+goEDB2Ls2LH4y1/+Ir/Pa+m+yZMn46OPPsI333wDADh69CgOHDiAmTNnAuib15JBizp09uxZ/Nd//ReysrLkbeXl5YiJiXGpi4iIgE6nQ3l5eac10s/Xq7HZbKisrOyyRjpGX1RZWQm73X7Dfe7OCCGwZMkSTJ48GcnJyQDafoe6ukbl5eXQ6XSIiIjosmbgwIHtzjlw4MAuf0+v/X33dzt27MCRI0ewZs2adu/xWrrv3Llz2LRpE0aNGoUPP/wQWVlZWLBgAbZt2waA17I7li1bhkceeQSJiYnQarUYO3YsFi1ahEceeQRA37yWDFp93KpVq6BSqbp8HT582GWf0tJSTJ8+HT/5yU/wq1/9yuU9lUrV7hxCCJft19aI1onwnqjp6Px9zY36ua81f/58HDt2DNu3b2/3Xk+u0fV+T3ta468uXryIhQsX4o033oDBYOi0jtfy+hwOB8aNG4fVq1dj7NixmDdvHp544gls2rTJpY7X8vp27tyJN954A//7v/+LI0eO4G9/+xtefvll/O1vf3Op60vXkkGrj5s/fz5Onz7d5UvqLQCcIevOO+9EWloaXnvtNZdjmUymdim/pqYGLS0t8l8FHdVUVFQAwHVrNBoNoqKiuqy59q+PviQ6OhpqtfqG+9wdeeqpp/Duu+/ik08+weDBg+XtJpMJALq8RiaTCVarFTU1NV3WfP/99+3Oe/ny5S5/T6/9ffdnBQUFqKioQEpKCjQaDTQaDfLy8vDqq69Co9G062mW8Fq2Fxsbi6SkJJdtN998M4qLiwHw97I7/uM//gPLly/H3LlzccsttyAzMxOLFy+We1374rVk0OrjoqOjkZiY2OVL+mu3pKQE06ZNw7hx47B161YEBbn+eqSlpeHEiRMoKyuTt+3duxd6vR4pKSlyzWeffeZye+zevXsRFxeHYcOGyTW5ubkux967dy/Gjx8PrVbbZc2kSZM8c2H8kE6nQ0pKSrvPnZub26c/99WEEJg/fz527dqFjz/+GAkJCS7vJyQkwGQyuVwjq9WKvLw8+RqlpKRAq9W61JSVleHEiRNyTVpaGsxmM7788ku55tChQzCbzS411/t992d33303jh8/jq+//lp+jR8/Ho8++ii+/vprDB8+nNfSTbfffnu7ZUa++eYbxMfHA+DvZXc0NDS0+25Rq9Xy8g598lp6bFo9BbSSkhIxcuRIcdddd4lLly6JsrIy+SWRboW9++67xZEjR8S+ffvE4MGDXW6Fra2tFTExMeKRRx4Rx48fF7t27RLh4eEdLu+wePFicerUKbFly5Z2yzt8/vnnQq1Wi+zsbHH69GmRnZ19Qy3vsGXLFnHq1CmxaNEiERoaKs6fP69003zi17/+tTAajeLTTz91+R1saGiQa7Kzs4XRaBS7du0Sx48fF4888kiHt34PHjxY7Nu3Txw5ckTcddddHd76feutt4r8/HyRn58vbrnllg5v/e7q9z3QXH3XoRC8lu768ssvhUajES+++KL49ttvxd///ncREhIi3njjDbmG19I9jz32mBg0aJC8vMOuXbtEdHS0WLp0qVzT164lgxYJIYTYunWrANDh62oXLlwQ9913nwgODhaRkZFi/vz5Lks5CCHEsWPHxJQpU4Rerxcmk0msWrVKXtpB8umnn4qxY8cKnU4nhg0bJjZt2tSuTW+++aa46aabhFarFYmJiSInJ8fzH9wPbdiwQcTHxwudTifGjRsnL21wI+jsd3Dr1q1yjcPhEM8//7wwmUxCr9eLO+64Qxw/ftzlOI2NjWL+/PkiMjJSBAcHi/vvv18UFxe71FRVVYlHH31UhIWFibCwMPHoo4+Kmpoalxp3ft8DybVBi9fSff/85z9FcnKy0Ov1IjExUbz22msu7/NausdisYiFCxeKoUOHCoPBIIYPHy6effZZ0dzcLNf0tWupEuKaJbuJiIiIyCM4R4uIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLyEQYuIiIjISxi0iIiIiLzk/wM+LpIgEUl5KAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4af8117a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Williams Selyem          374\n",
       "Testarossa               277\n",
       "DFJ Vinhos               258\n",
       "Chateau Ste. Michelle    226\n",
       "Columbia Crest           217\n",
       "                        ... \n",
       "Château Magondeau          1\n",
       "Château Haut-Lansac        1\n",
       "Anko                       1\n",
       "Alessandro Veglio          1\n",
       "Fullerton                  1\n",
       "Name: winery, Length: 14897, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winery_counts=wine_df.winery.value_counts()\n",
    "winery_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a986bde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Density'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "winery_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd4bfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14897.000000\n",
       "mean        10.192858\n",
       "std         17.394968\n",
       "min          1.000000\n",
       "25%          2.000000\n",
       "50%          4.000000\n",
       "75%         11.000000\n",
       "max        374.000000\n",
       "Name: winery, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winery_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfca1289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ruggeri & C.',\n",
       " 'Kana',\n",
       " 'Valdo',\n",
       " 'Conceito Vinhos',\n",
       " 'Huber',\n",
       " 'Francis Coppola',\n",
       " 'Burmester',\n",
       " 'Castello di Amorosa',\n",
       " 'Domaine Bruno Clair',\n",
       " \"Quinta de Sant'Ana\",\n",
       " 'Belhurst',\n",
       " 'Belle Glos',\n",
       " 'Feudo Montoni',\n",
       " 'BOND',\n",
       " 'Fiuza',\n",
       " 'Gritsch Mauritiushof',\n",
       " 'Laird',\n",
       " 'Portal Del Alto',\n",
       " 'Rivetto',\n",
       " 'Big Basin',\n",
       " 'Seven of Hearts',\n",
       " 'St. Clement',\n",
       " 'Nobilo',\n",
       " 'Fort Ross',\n",
       " 'Château Malartic-Lagravière',\n",
       " 'Casa do Valle',\n",
       " 'Hawley',\n",
       " 'Deutz',\n",
       " 'San Rustico',\n",
       " 'Lincourt',\n",
       " 'West Cape Howe',\n",
       " 'Dogwood',\n",
       " 'Davis Bynum',\n",
       " 'Gordon Brothers',\n",
       " 'Warwick',\n",
       " 'Cowhorn',\n",
       " 'Boedecker Cellars',\n",
       " 'Christian Lazo',\n",
       " 'Corley',\n",
       " 'Villa Mt. Eden',\n",
       " 'Máté',\n",
       " 'Alvaro Castro',\n",
       " 'Peters Family',\n",
       " 'Folie à Deux',\n",
       " 'Shingleback',\n",
       " 'Feudi di San Marzano',\n",
       " 'Ruca Malen',\n",
       " 'Escarpment',\n",
       " 'William Cole',\n",
       " 'Sella & Mosca',\n",
       " 'Koyle',\n",
       " 'Oak Knoll',\n",
       " 'Rieflé',\n",
       " 'Argiano',\n",
       " 'Bota Box',\n",
       " 'Allegrini',\n",
       " 'Condado de Oriza',\n",
       " 'Domaine Pouillon',\n",
       " 'G. H. Mumm',\n",
       " 'Stephen & Walker',\n",
       " 'Poggio Nardone',\n",
       " 'Drew',\n",
       " 'J. Christopher',\n",
       " 'Desert Wind',\n",
       " 'Lone Canary',\n",
       " \"Masies d'Avinyo\",\n",
       " 'Tapestry',\n",
       " 'Castello di Poppiano',\n",
       " 'Drappier',\n",
       " 'Setzer',\n",
       " \"Osprey's Dominion\",\n",
       " 'Callia',\n",
       " 'Wittmann',\n",
       " 'Señorío de Sarria',\n",
       " 'Hartford Court',\n",
       " 'Marquee',\n",
       " 'Finca Antigua',\n",
       " 'Fantelli',\n",
       " 'Artezin',\n",
       " 'Château Pape Clément',\n",
       " 'Talisman',\n",
       " 'Cru',\n",
       " 'Halter Ranch',\n",
       " 'Mount Eden',\n",
       " 'Schloss Saarstein',\n",
       " 'Pascal Jolivet',\n",
       " 'Cascina Adelaide',\n",
       " 'Jacopo Biondi-Santi',\n",
       " 'Pecchenino',\n",
       " 'Abadia Retuerta',\n",
       " 'Donati',\n",
       " 'Château de Cénac',\n",
       " 'Quinta do Vale Meão',\n",
       " 'Cramele Recas',\n",
       " 'Domaine de la Vougeraie',\n",
       " 'Wyndham Estate',\n",
       " 'Sandeman',\n",
       " 'Camigliano',\n",
       " 'Boeckel',\n",
       " 'Costa de Oro',\n",
       " 'Brotte',\n",
       " 'Giesen',\n",
       " 'Philipponnat',\n",
       " 'Michael David',\n",
       " 'Domäne Wachau',\n",
       " 'Oyster Bay',\n",
       " 'Northstar',\n",
       " 'Renato Ratti',\n",
       " 'Taz',\n",
       " 'Podere Guado al Melo',\n",
       " 'Stefano Accordini',\n",
       " 'Pepperwood Grove',\n",
       " 'Château de Tracy',\n",
       " 'Woollaston',\n",
       " 'Viña Albali',\n",
       " 'Castello del Terriccio',\n",
       " 'Collemassari',\n",
       " 'Franciscan',\n",
       " 'Coeur de Terre',\n",
       " 'Calistoga Cellars',\n",
       " 'Sean Minor',\n",
       " 'Castello di Monsanto',\n",
       " 'Castellani Michele & Figli',\n",
       " 'Fabiano',\n",
       " 'VJB',\n",
       " \"Château d'Aydie\",\n",
       " 'Château Léoville Las Cases',\n",
       " 'Château Palmer',\n",
       " 'Castello di Gabbiano',\n",
       " 'Château La Mission Haut-Brion',\n",
       " 'Viñas del Vero',\n",
       " 'Forest Glen',\n",
       " 'Le Cadeau',\n",
       " \"Il Feuduccio Di S. Maria D'Orni\",\n",
       " \"Angove's\",\n",
       " 'Groth',\n",
       " 'Château Carbonnieux',\n",
       " 'Albeno Munari',\n",
       " 'Whidbey Island Winery',\n",
       " 'Estate Biblia Chora',\n",
       " 'Gianni Gagliardo',\n",
       " 'Andis',\n",
       " 'Angel Vine',\n",
       " 'Caligiore',\n",
       " 'Terre da Vino',\n",
       " 'Proulx',\n",
       " 'The Colonial Estate',\n",
       " 'Rioja Vega',\n",
       " 'Luna',\n",
       " 'Conde de Velázquez',\n",
       " \"Stags' Leap Winery\",\n",
       " 'Alex Gambal',\n",
       " 'Kaleidos',\n",
       " 'Indaba',\n",
       " 'LangeTwins',\n",
       " 'Peter Nicolay',\n",
       " 'Green Point',\n",
       " 'Poggio al Tesoro',\n",
       " 'St Hallett',\n",
       " 'MacMurray Ranch',\n",
       " 'Villa Toscano',\n",
       " 'Marcarini',\n",
       " 'Tezza',\n",
       " 'JCB',\n",
       " 'Ocone',\n",
       " 'Burgess',\n",
       " 'Château de Fieuzal',\n",
       " 'Viñedos de Paganos',\n",
       " 'Monte Tondo',\n",
       " 'Lawer',\n",
       " \"Ciacci Piccolomini d'Aragona\",\n",
       " 'Conti Zecca',\n",
       " 'Zerba Cellars',\n",
       " 'Jurtschitsch',\n",
       " 'Pianetta',\n",
       " 'Louis Guntrum',\n",
       " 'Gancia',\n",
       " 'Horse & Plow',\n",
       " 'Bonny Doon',\n",
       " 'The Crossings',\n",
       " 'Eagle Castle',\n",
       " 'Domaine Ostertag',\n",
       " 'Wrath',\n",
       " 'Sonoma Coast Vineyards',\n",
       " 'Tenimenti Angelini',\n",
       " 'Sauvion',\n",
       " 'Château Olivier',\n",
       " \"Reilly's\",\n",
       " 'Christine Andrew',\n",
       " 'Brampton',\n",
       " 'Perlage',\n",
       " 'Field Stone',\n",
       " 'Psagot',\n",
       " 'Va Piano',\n",
       " 'Verve',\n",
       " 'Ruinart',\n",
       " 'Mount Pleasant Winery',\n",
       " 'Washington Hills',\n",
       " 'Domaine Vrignaud',\n",
       " 'Little Black Dress',\n",
       " 'Château Haut-Monplaisir',\n",
       " 'Cascina del Monastero',\n",
       " 'Arcadian',\n",
       " 'Château Lafite Rothschild',\n",
       " 'Hoodsport',\n",
       " 'Château Potensac',\n",
       " 'Dominio de Eguren',\n",
       " 'Château Latour-Martillac',\n",
       " 'Collovray et Terrier',\n",
       " 'Terra Valentine',\n",
       " 'Palacios Remondo',\n",
       " 'Bleasdale',\n",
       " 'Volker Eisele Family Estate',\n",
       " 'St. Pauls',\n",
       " 'Imagery',\n",
       " 'ZD',\n",
       " 'Plozner',\n",
       " 'Stottle',\n",
       " 'Substance',\n",
       " 'Taltarni',\n",
       " 'Bisol',\n",
       " 'Gernot and Heike Heinrich',\n",
       " 'Chappellet',\n",
       " 'Prospect 772',\n",
       " 'Gracia de Chile',\n",
       " 'W.H. Smith',\n",
       " 'Peter Franus',\n",
       " 'Leonesse Cellars',\n",
       " 'Maurigi',\n",
       " 'Vignerons de Bel Air',\n",
       " 'Bodega Noemía de Patagonia',\n",
       " 'Smith-Madrone',\n",
       " 'Paul Hobbs',\n",
       " 'Nigl',\n",
       " 'Marques de Griñon',\n",
       " 'Cantina Sociale della Valpantena',\n",
       " 'Lucas Vineyards',\n",
       " 'Kanonkop',\n",
       " 'Kenneth Volk',\n",
       " 'Tres Sabores',\n",
       " 'Glen Carlou',\n",
       " 'Rios de Chile',\n",
       " 'J. Rickards',\n",
       " 'Philo Ridge',\n",
       " \"Winter's Hill\",\n",
       " 'Rudi Pichler',\n",
       " 'Aldegheri',\n",
       " 'Niner',\n",
       " 'Quinta do Quetzal',\n",
       " 'Donna Olimpia 1898',\n",
       " 'Bollig-Lehnert',\n",
       " 'Arger-Martucci',\n",
       " 'Agustinos',\n",
       " 'Campus Oaks',\n",
       " 'Amici',\n",
       " 'Lieb',\n",
       " 'Chono',\n",
       " 'DiStefano',\n",
       " \"Henry's Drive Vignerons\",\n",
       " 'Château Sainte Roseline',\n",
       " 'Lumos',\n",
       " 'Willm',\n",
       " 'Mayacamas',\n",
       " 'Foss Marai',\n",
       " 'Trenel Fils',\n",
       " 'Redhawk',\n",
       " 'Umathum',\n",
       " 'Hanzell',\n",
       " 'Freestone',\n",
       " 'Ken Forrester',\n",
       " 'Bouchaine',\n",
       " 'Bighorn',\n",
       " 'Halleck',\n",
       " 'Silver Thread',\n",
       " \"Holly's Hill\",\n",
       " 'Casa Santos Lima',\n",
       " 'Gunn Estate',\n",
       " 'Round Pond',\n",
       " 'Cadaretta',\n",
       " 'Mauro Sebaste',\n",
       " 'Mauro Veglio',\n",
       " 'Valley View',\n",
       " 'Zeni',\n",
       " 'Sparkling Pointe',\n",
       " 'Vino Con Brio',\n",
       " 'Begali',\n",
       " 'Bennett Lane',\n",
       " 'Mas del Périé',\n",
       " 'Sandro de Bruno',\n",
       " 'Treana',\n",
       " 'Kemblefield',\n",
       " 'Pennywise',\n",
       " 'Steininger',\n",
       " 'Forefathers',\n",
       " 'Tiefenbrunner',\n",
       " 'Agate Ridge',\n",
       " 'Edgebaston',\n",
       " \"Bishop's Peak\",\n",
       " 'Giacomo Fenocchio',\n",
       " 'Domaines Paul Mas',\n",
       " \"Castello d'Albola\",\n",
       " 'Campo Viejo',\n",
       " 'Hartford',\n",
       " 'Quinta de Chocapalha',\n",
       " 'Pelassa',\n",
       " \"Murrieta's Well\",\n",
       " 'Antiyal',\n",
       " 'Fitz-Ritter',\n",
       " 'Mannina Cellars',\n",
       " 'La Scolca',\n",
       " 'Chambers Rosewood Vineyards',\n",
       " 'Plungerhead',\n",
       " 'Antinori',\n",
       " \"Terra d'Oro\",\n",
       " 'Benovia',\n",
       " 'Il Falchetto',\n",
       " 'D.R. Stephens',\n",
       " 'Newsome-Harlow',\n",
       " 'Finca El Portillo',\n",
       " 'Archery Summit',\n",
       " 'Piña',\n",
       " 'Altocedro',\n",
       " 'Giant Steps',\n",
       " 'Blue Rock',\n",
       " 'Saxum',\n",
       " 'Leone de Castris',\n",
       " 'Mercy',\n",
       " 'Gesellmann',\n",
       " 'Virna Borgogno',\n",
       " 'Gere Attila',\n",
       " 'Guy Saget',\n",
       " 'Bertrand Ambroise',\n",
       " 'Bourassa Vineyards',\n",
       " 'Vidigal',\n",
       " 'Numanthia',\n",
       " 'Rasa',\n",
       " 'Dinastía Vivanco',\n",
       " 'La Gerla',\n",
       " 'Jackson Estate',\n",
       " 'Hook & Ladder',\n",
       " 'Quinta dos Roques',\n",
       " 'Carter',\n",
       " 'Château Latour',\n",
       " 'Selene',\n",
       " 'Ànima Negra',\n",
       " 'Santi',\n",
       " 'Bischöfliche Weingüter Trier',\n",
       " 'Castello di Querceto',\n",
       " 'Domaine Zinck',\n",
       " 'Crossroads',\n",
       " 'Freeman',\n",
       " 'Castelluccio',\n",
       " \"Château Cos d'Estournel\",\n",
       " 'Trinity Hill',\n",
       " 'Swedish Hill',\n",
       " 'Ninquén',\n",
       " 'Quasar',\n",
       " 'Sawyer',\n",
       " 'Amity',\n",
       " 'Terralsole',\n",
       " 'Altesino',\n",
       " 'Castle',\n",
       " 'Vista Hills',\n",
       " 'Occasio',\n",
       " 'Castellani',\n",
       " 'Latah Creek',\n",
       " 'Sacred Hill',\n",
       " 'Novaia',\n",
       " 'Weingut Liebfrauenstift',\n",
       " 'Sorelle Bronca',\n",
       " 'Cornerstone',\n",
       " 'Adobe Road',\n",
       " 'Il Poggione',\n",
       " 'Quinta do Noval',\n",
       " 'Château Grand Jean',\n",
       " 'Anne Amie',\n",
       " 'Atlas Peak',\n",
       " 'Rivetti Massimo',\n",
       " 'Lavradores de Feitoria',\n",
       " 'Les Jamelles',\n",
       " 'Quinta da Romaneira',\n",
       " 'Keller',\n",
       " 'Château Coutet',\n",
       " 'Fitapreta Vinhos',\n",
       " 'Château Bouscaut',\n",
       " 'Pasqua',\n",
       " 'Jacquart',\n",
       " 'Joseph Jewell',\n",
       " 'Dutcher Crossing',\n",
       " 'Nederburg',\n",
       " 'Turnbull',\n",
       " 'Page Cellars',\n",
       " 'Waters',\n",
       " 'Napa Cellars',\n",
       " 'Helfrich',\n",
       " 'Aubry',\n",
       " 'Monteviejo',\n",
       " 'Mesa',\n",
       " 'Longview',\n",
       " 'Suavia',\n",
       " 'Tapeña',\n",
       " 'Lamadrid',\n",
       " 'Tenute Soletta',\n",
       " 'La Chiripada',\n",
       " 'Poliziano',\n",
       " 'Collosorbo',\n",
       " 'Boschendal',\n",
       " 'Tinazzi',\n",
       " 'Marqués de la Concordia',\n",
       " 'Natale Verga',\n",
       " 'Chalone Vineyard',\n",
       " 'Migration',\n",
       " 'Marc Sorrel',\n",
       " 'Rancho Arroyo Grande',\n",
       " 'Lovingston',\n",
       " 'Orfila',\n",
       " 'Michael Pozzan',\n",
       " 'Dumas Station',\n",
       " 'Bollinger',\n",
       " 'Domaine Laleure-Piot',\n",
       " 'Andreola',\n",
       " \"Les Maîtres Vignerons de la Presqu'île de Saint-Tropez\",\n",
       " 'Selaks',\n",
       " 'Oriel',\n",
       " 'Belle Vallée',\n",
       " 'Misiones de Rengo',\n",
       " \"Rosa d'Oro\",\n",
       " 'JR Wine',\n",
       " 'Real Companhia Velha',\n",
       " 'Château Cabredon',\n",
       " 'Tamarí',\n",
       " 'Atmosphere',\n",
       " 'Mill Creek',\n",
       " 'Sea Smoke',\n",
       " 'Flying Goat Cellars',\n",
       " 'Ernst Triebaumer',\n",
       " 'La Valentina',\n",
       " \"Tyrrell's\",\n",
       " 'Domaine Ste. Michelle',\n",
       " 'Patton Valley',\n",
       " 'Melipal',\n",
       " 'Château de Fuissé',\n",
       " 'Tapiz',\n",
       " 'Château Philippe-le-Hardi',\n",
       " 'Bonneau',\n",
       " 'Boscarelli',\n",
       " 'Sidewood',\n",
       " 'Tortoise Creek',\n",
       " 'Schloss Gobelsburg',\n",
       " 'Croft',\n",
       " 'Channing Daughters',\n",
       " 'Yorkville Cellars',\n",
       " 'Black Kite',\n",
       " 'San Fabiano Calcinaia',\n",
       " 'Deep Sea',\n",
       " 'Barossa Valley Estate',\n",
       " 'Domaine de Bellene',\n",
       " 'Baldacci',\n",
       " 'Alpha Omega',\n",
       " 'Castello di Monastero',\n",
       " 'Château Haut Selve',\n",
       " 'Billsboro',\n",
       " \"Terra d'Alter\",\n",
       " 'Sheldon',\n",
       " 'Dierberg',\n",
       " 'Roshambo',\n",
       " 'Yangarra Estate Vineyard',\n",
       " 'Volpe Pasini',\n",
       " 'Cloudlift Cellars',\n",
       " 'Domaine Laporte',\n",
       " 'Vini',\n",
       " 'J. Scott Cellars',\n",
       " 'Firesteed',\n",
       " 'Pierre Gimonnet et Fils',\n",
       " 'Toffoli',\n",
       " 'Yatir',\n",
       " 'Barros',\n",
       " 'Prinz Salm',\n",
       " 'Llopart',\n",
       " 'Schmitges',\n",
       " 'Small Vines',\n",
       " 'Charles Ellner',\n",
       " 'Robert Oatley',\n",
       " 'Echelon',\n",
       " 'Chacewater',\n",
       " 'Opolo',\n",
       " 'WesMar',\n",
       " 'Mount Cass',\n",
       " 'Biondi Santi',\n",
       " 'Standing Sun',\n",
       " 'Tardieu-Laurent',\n",
       " 'Château Montrose',\n",
       " 'Magnum Vinhos',\n",
       " 'Conterno Fantino',\n",
       " 'Felipe Rutini',\n",
       " 'Perbacco Cellars',\n",
       " 'Magnificent Wine Company',\n",
       " 'Cave Spring',\n",
       " 'Stoneleigh',\n",
       " 'The Williamsburg Winery',\n",
       " 'Pellegrini Vineyards',\n",
       " 'Juvé y Camps',\n",
       " 'Château Pichon Longueville',\n",
       " 'Brotherhood',\n",
       " 'Leonard Kreusch',\n",
       " 'Kangarilla Road',\n",
       " 'Sileni',\n",
       " 'Podere Sapaio',\n",
       " 'Spice Route',\n",
       " 'Alice White',\n",
       " 'Château des Karantes',\n",
       " 'Calicaro',\n",
       " 'Delicato',\n",
       " 'Batzella',\n",
       " 'Rustenberg',\n",
       " 'Eight Bells',\n",
       " 'Tenuta Rocca',\n",
       " 'Villa Monteleone',\n",
       " 'Pinord',\n",
       " 'Kaesler',\n",
       " 'Brugnano',\n",
       " 'Henriot',\n",
       " \"Sarah's Vineyard\",\n",
       " 'Krug',\n",
       " 'Hey Mambo',\n",
       " 'Excelsior',\n",
       " 'Hopper Creek',\n",
       " 'Bruliam',\n",
       " 'Alain Jaume et Fils',\n",
       " 'Antucura',\n",
       " 'Château Souverain',\n",
       " 'Monte Rossa',\n",
       " 'Pratesi',\n",
       " 'Pinino',\n",
       " 'One Hope',\n",
       " 'French Hill',\n",
       " 'Talus',\n",
       " 'Nicolis',\n",
       " 'Terre di Talamo',\n",
       " 'Joel Gott',\n",
       " 'Bedell',\n",
       " 'El Huique',\n",
       " 'Howard Park',\n",
       " 'Louis Bouillot',\n",
       " 'Bridgeview',\n",
       " 'Bonotto delle Tezze',\n",
       " 'Terre di Giurfo',\n",
       " 'Antonino Tringali-Casanuova',\n",
       " 'Domaine de la Sauveuse',\n",
       " 'Colutta',\n",
       " 'Byington',\n",
       " 'Elvio Cogno',\n",
       " 'Covington',\n",
       " 'Lucien Le Moine',\n",
       " 'Jones of Washington',\n",
       " 'I Capitani',\n",
       " 'Pieropan',\n",
       " 'Malat',\n",
       " 'Stadlmann',\n",
       " 'Torre Rosazza',\n",
       " 'Castello di Bossi',\n",
       " 'Ceago Vinegarden',\n",
       " 'Fairview',\n",
       " 'Castello Romitorio',\n",
       " 'Villa San Juliette',\n",
       " 'Tenute Silvio Nardi',\n",
       " 'RiverAerie',\n",
       " 'Spellbound',\n",
       " 'Philip Shaw',\n",
       " 'Tudal',\n",
       " 'Nicholson Ranch',\n",
       " 'Falesco',\n",
       " 'Guicciardini Strozzi',\n",
       " 'Norman',\n",
       " 'Château Laulerie',\n",
       " 'Ventosa',\n",
       " 'Teso La Monja',\n",
       " 'Geh. Rat Dr. von Bassermann-Jordan',\n",
       " 'Pannier',\n",
       " 'McFadden',\n",
       " 'Juris',\n",
       " 'El Circulo',\n",
       " 'Chateau Morrisette',\n",
       " 'Highway 12',\n",
       " 'Messina Hof',\n",
       " 'Pulenta Estate',\n",
       " 'Orchid Hill',\n",
       " 'Kessler-Haak',\n",
       " 'Petroni',\n",
       " 'Château Valandraud',\n",
       " 'Château Ducru Beaucaillou',\n",
       " 'Telavi',\n",
       " 'Two Vintners',\n",
       " 'Ross Andrew',\n",
       " 'Gosset',\n",
       " 'Anthony Road',\n",
       " 'Fuligni',\n",
       " 'Cobblestone',\n",
       " 'Château Larrivet Haut-Brion',\n",
       " 'Domaine du Grand Cros',\n",
       " 'Fattori',\n",
       " 'Santa Margherita',\n",
       " 'Falernia',\n",
       " 'Willi Haag',\n",
       " 'P.J. Valckenberg',\n",
       " 'Campo alla Sughera',\n",
       " 'Bodegas Julián Chivite',\n",
       " 'Lone Madrone',\n",
       " 'VinArte',\n",
       " 'Gini',\n",
       " 'Capture',\n",
       " 'Domaine Champy',\n",
       " 'Giribaldi',\n",
       " 'Boekenhoutskloof',\n",
       " 'Château Vignelaure',\n",
       " \"Castello d'Alba\",\n",
       " 'Martella',\n",
       " 'Jada Vineyard & Winery',\n",
       " 'Matarromera',\n",
       " 'La Poderina',\n",
       " 'Coppo',\n",
       " 'Kurtz Family',\n",
       " 'Brass Tacks',\n",
       " 'Aquinas',\n",
       " 'Ramey',\n",
       " 'Pol Roger',\n",
       " 'RouteStock Cellars',\n",
       " 'Fogdog',\n",
       " 'Bella Piazza',\n",
       " 'La Tordera',\n",
       " 'Giovanni Chiappini',\n",
       " 'Nasiakos',\n",
       " 'Root:1',\n",
       " 'Viña el Aromo',\n",
       " 'Jean Milan',\n",
       " 'Domaine Bott-Geyl',\n",
       " 'Tenute Rubino',\n",
       " 'Irony',\n",
       " 'Shiloh Winery',\n",
       " 'Orlando Abrigo',\n",
       " 'Chatom',\n",
       " 'Fattoria La Lecciaia',\n",
       " 'TerraMater',\n",
       " 'C.G. di Arie',\n",
       " 'Château Eugénie',\n",
       " 'Juslyn Vineyards',\n",
       " 'Haras',\n",
       " 'Hardys',\n",
       " 'Casas del Toqui',\n",
       " 'Fazi Battaglia',\n",
       " 'Happy Camper',\n",
       " 'Bortolin',\n",
       " 'Alain Voge',\n",
       " 'Katnook Estate',\n",
       " 'Marco Felluga',\n",
       " 'Librandi',\n",
       " 'Ehret',\n",
       " 'Château Bouissel',\n",
       " 'Poggio Verrano',\n",
       " 'Y Rousseau',\n",
       " 'Animale',\n",
       " 'Castello di Neive',\n",
       " 'Avide',\n",
       " 'Château la Rayre',\n",
       " 'Educated Guess',\n",
       " 'Finca Decero',\n",
       " 'John Duval Wines',\n",
       " 'Gifford Hirlinger',\n",
       " \"Barker's Marque\",\n",
       " 'Sallier de la Tour',\n",
       " 'Podere San Cristoforo',\n",
       " 'Sonoma-Cutrer',\n",
       " 'Hamacher',\n",
       " 'Capanna',\n",
       " 'Rocche Costamagna',\n",
       " 'Vinchio-Vaglio Serra',\n",
       " 'Le Grascete',\n",
       " 'Cantine Barbera',\n",
       " '3 Horse Ranch Vineyards',\n",
       " 'Willow Crest',\n",
       " 'Hilltown',\n",
       " 'Château Lamothe-Vincent',\n",
       " 'Spanish Vines',\n",
       " 'Viticcio',\n",
       " 'Cooperativa Reguengos de Monsaraz',\n",
       " 'JC Cellars',\n",
       " 'Venturini Massimino',\n",
       " 'Ghost Pines',\n",
       " 'Martin Alfaro',\n",
       " 'Giacomo Vico',\n",
       " 'Vall Llach',\n",
       " 'Château Ausone',\n",
       " 'Huntington',\n",
       " 'Domaine Courbis',\n",
       " 'Forrest Estate',\n",
       " 'Powers',\n",
       " 'Paul Cluver',\n",
       " 'Janzen',\n",
       " 'Haut Marin',\n",
       " 'Roth',\n",
       " 'Deerfield Ranch',\n",
       " 'Bock',\n",
       " 'Wiese & Krohn',\n",
       " 'Peconic Bay Winery',\n",
       " 'Tenuta delle Terre Nere',\n",
       " 'Podere Brizio',\n",
       " 'Zardetto',\n",
       " 'Phillips Hill',\n",
       " 'J. Dumangin Fils',\n",
       " 'Fleur Du Cap',\n",
       " 'Castell',\n",
       " 'Weingut Georg Albrecht Schneider',\n",
       " 'Hedges',\n",
       " 'Two Mountain',\n",
       " 'David Arthur',\n",
       " 'Corteforte',\n",
       " 'Caparzo',\n",
       " 'Mettler Family Vineyards',\n",
       " 'Scott Paul',\n",
       " 'Veranda',\n",
       " 'Robert Young',\n",
       " 'Zina Hyde Cunningham',\n",
       " 'Château La Joya',\n",
       " 'Domaine Gerovassiliou',\n",
       " 'Charles Smith',\n",
       " 'Cennatoio',\n",
       " 'Bellingham',\n",
       " 'Bouvet-Ladubay',\n",
       " 'Arbor Brook',\n",
       " \"Judd's Hill\",\n",
       " 'Mi Sueño',\n",
       " 'Roco',\n",
       " 'Knights Bridge',\n",
       " 'Olsen Estates',\n",
       " 'Rockroom Winemaking Cooperative',\n",
       " 'Villa Cafaggio',\n",
       " 'Castello di Meleto',\n",
       " 'Pommery',\n",
       " 'Viña Vilano',\n",
       " 'Canneto',\n",
       " 'R Wines',\n",
       " 'Bunchgrass',\n",
       " 'Indigené',\n",
       " 'Stuart Cellars',\n",
       " 'Saddleback',\n",
       " 'Addamo',\n",
       " 'Fattoria Le Pupille',\n",
       " 'Vistalba',\n",
       " 'Nikolaihof',\n",
       " 'Volteo',\n",
       " 'Sinclair Estate Vineyards',\n",
       " 'Hess',\n",
       " 'Viña La Fortuna',\n",
       " 'Caldora Vini',\n",
       " 'Domaine Weinbach',\n",
       " 'Veglio',\n",
       " 'Vision Cellars',\n",
       " 'Cable Car',\n",
       " 'Chandler Reach',\n",
       " 'Alberti 154',\n",
       " 'Morgenhof',\n",
       " 'Center of Effort',\n",
       " \"Ca'Romè\",\n",
       " 'Laurel Glen',\n",
       " 'Cave de Lugny',\n",
       " 'Argyros',\n",
       " 'Miro',\n",
       " 'Derby',\n",
       " 'Zimmermann',\n",
       " 'Colosi',\n",
       " 'Surh Luchtel',\n",
       " 'Santa Helena',\n",
       " 'Château Potelle',\n",
       " 'Monteci',\n",
       " 'Château Musar',\n",
       " 'Château Suduiraut',\n",
       " 'Porcupine Ridge',\n",
       " 'Maquis',\n",
       " 'Chamarré',\n",
       " 'Albet I Noya',\n",
       " 'Campo al Mare',\n",
       " 'Goldwater',\n",
       " 'Rocca',\n",
       " 'La Valle',\n",
       " 'Cullen',\n",
       " 'Estate Constantin Gofas',\n",
       " 'Cycles Gladiator',\n",
       " 'Longfellow',\n",
       " 'Campelo',\n",
       " 'Fritz Haag',\n",
       " 'Marqués de Murrieta',\n",
       " 'Giorgio Meletti Cavallari',\n",
       " 'Kontos',\n",
       " 'Joseph Cattin',\n",
       " 'Constant',\n",
       " \"Ca' del Solo\",\n",
       " 'Castello di Ama',\n",
       " 'Sequana',\n",
       " 'Cakebread',\n",
       " 'Fox Creek',\n",
       " 'La Vis',\n",
       " 'Boekenoogen',\n",
       " 'Three Families',\n",
       " 'Spier',\n",
       " 'Trimbach',\n",
       " 'I Balzini',\n",
       " 'Cavit',\n",
       " 'Terre del Principe',\n",
       " 'Remírez de Ganuza',\n",
       " 'Antonio Cesar Cavalli',\n",
       " 'Barboursville Vineyards',\n",
       " \"Lawson's Dry Hills\",\n",
       " 'A Donkey and Goat',\n",
       " 'Fattoria Fibbiano',\n",
       " 'Rizzi',\n",
       " 'Domaine du Castel',\n",
       " 'Bodegas Iranzo',\n",
       " 'Sundance',\n",
       " 'Calcu',\n",
       " 'Castelli del Grevepesa',\n",
       " 'Feudo di Santa Tresa',\n",
       " 'Palladino',\n",
       " 'Chime',\n",
       " 'Palazzo',\n",
       " 'Alliance Loire',\n",
       " 'Manzanita Creek',\n",
       " 'Madroña',\n",
       " 'Brassfield',\n",
       " 'Carl Ehrhard',\n",
       " 'York Mountain Winery',\n",
       " 'O•S Winery',\n",
       " 'Vincent',\n",
       " 'Oddero',\n",
       " 'Sculpterra',\n",
       " 'Langlois-Chateau',\n",
       " 'Dr. Bürklin-Wolf',\n",
       " 'Montemaggiore',\n",
       " 'Blanco Nieva',\n",
       " 'Howell Mountain Vineyards',\n",
       " 'Georg Breuer',\n",
       " 'Bersano',\n",
       " 'Bonacchi',\n",
       " 'Bin 36',\n",
       " 'Barlow',\n",
       " 'Cipriana',\n",
       " 'Apex',\n",
       " 'Araldica',\n",
       " 'Martinborough Vineyard',\n",
       " 'Giuseppe Lonardi',\n",
       " 'Shiloh Road',\n",
       " 'Château de Chantegrive',\n",
       " 'Maycas del Limari',\n",
       " 'Mönchhof',\n",
       " 'Galante',\n",
       " 'Vigneti Villabella',\n",
       " 'Crane Brothers',\n",
       " 'Craftsman',\n",
       " 'WillaKenzie Estate',\n",
       " 'Josef Weger',\n",
       " 'CK Mondavi',\n",
       " 'Fattoria Petrolo',\n",
       " 'Alain Brumont',\n",
       " 'Fog Crest',\n",
       " 'Venteux',\n",
       " 'Apolloni',\n",
       " 'Monte da Ravasqueira',\n",
       " 'Valiano',\n",
       " 'David Girard',\n",
       " 'Coastal Ridge',\n",
       " 'Savannah-Chanelle',\n",
       " 'Grans-Fassian',\n",
       " 'Two Angels',\n",
       " 'Caves Transmontanas',\n",
       " 'Five Rivers',\n",
       " 'Hawkstone',\n",
       " 'Musella',\n",
       " 'Mills Reef',\n",
       " 'Salvatore Principe',\n",
       " 'Simon Hackett',\n",
       " 'Southard',\n",
       " \"L'Antica Quercia\",\n",
       " 'Lost River',\n",
       " 'Pertinace',\n",
       " 'Barale Fratelli',\n",
       " 'Rietvallei Estate Wine',\n",
       " 'Napa Family Vineyards',\n",
       " 'Giuseppe Campagnola',\n",
       " 'Gualdo del Re',\n",
       " 'Château Cheval Blanc',\n",
       " 'Coopers Creek',\n",
       " 'Cascina Ballarin',\n",
       " 'Montalbera',\n",
       " 'Stuhlmuller Vineyards',\n",
       " 'Château Peyros',\n",
       " 'Darioush',\n",
       " 'Casal Paço Padreiro',\n",
       " 'oops',\n",
       " 'Château Nenin',\n",
       " \"Stephen's\",\n",
       " 'Naia',\n",
       " 'Gaia Wines',\n",
       " \"Monte dall'Ora\",\n",
       " 'Vineyard 7&8',\n",
       " 'Marziano Abbona',\n",
       " 'Elderton',\n",
       " 'Isabel Estate',\n",
       " 'Fife',\n",
       " 'Les Vignobles Gueissard',\n",
       " 'Patterson',\n",
       " 'Cantele',\n",
       " 'Queen of Hearts',\n",
       " 'Clautiere',\n",
       " 'Wilridge',\n",
       " 'Tenuta Villa Trasqua',\n",
       " 'Fulcrum',\n",
       " 'Feliz Noche',\n",
       " 'Camelot',\n",
       " 'Oakville Ranch',\n",
       " 'Gallo of Sonoma',\n",
       " 'Line 39',\n",
       " 'Christian Fischer',\n",
       " 'Château de Malle',\n",
       " 'Château Phélan-Ségur',\n",
       " 'Charles Heidsieck',\n",
       " 'Barrel Oak',\n",
       " 'Alta Maria',\n",
       " 'Mutt Lynch',\n",
       " 'Fischer',\n",
       " 'Yellow Tail',\n",
       " 'Happy Canyon Vineyard',\n",
       " 'Vignerons de Buzet',\n",
       " 'Antonelli',\n",
       " 'Foursight',\n",
       " 'Casa de la Ermita',\n",
       " 'Falchini',\n",
       " 'Mas de Cadenet',\n",
       " 'Cricova',\n",
       " 'I Giusti e Zanza',\n",
       " 'Baer',\n",
       " 'La Mannella',\n",
       " 'Château Jolys',\n",
       " 'Carpenè Malvolti',\n",
       " 'Morro Bay',\n",
       " 'Donkey & Goat',\n",
       " 'Darby',\n",
       " 'Condes de Albarei',\n",
       " 'Quinta do Vesuvio',\n",
       " 'Fabre Montmayou',\n",
       " 'Cascina Chicco',\n",
       " 'Iris Vineyards',\n",
       " 'Cecilia Beretta',\n",
       " 'Sattlerhof',\n",
       " 'Codorníu',\n",
       " 'Provam',\n",
       " 'Mommessin',\n",
       " 'Olson Ogden',\n",
       " 'Château Léoube',\n",
       " 'Eugenio Collavini',\n",
       " 'Fratelli Muratori',\n",
       " 'Sherwood House Vineyards',\n",
       " 'Domaine de Nizas',\n",
       " 'Dona Maria-Júlio Bastos',\n",
       " 'Barefoot Bubbly',\n",
       " 'McGregor',\n",
       " 'Pico Maccario',\n",
       " 'McCay Cellars',\n",
       " 'Forth',\n",
       " 'Costaripa',\n",
       " 'Lang & Reed',\n",
       " 'Montgó',\n",
       " 'Tenuta Valdipiatta',\n",
       " 'Louis Bernard',\n",
       " 'Di Giovanna',\n",
       " 'Bottega',\n",
       " 'Wine & Soul',\n",
       " 'Château Haut Bertinerie',\n",
       " 'Pikes',\n",
       " 'Melini',\n",
       " 'Château Pontet-Canet',\n",
       " 'Comartin',\n",
       " 'Leasingham',\n",
       " 'Villa Spinosa',\n",
       " 'Girlan',\n",
       " 'Domaine de la Sanglière',\n",
       " 'Duorum',\n",
       " 'Château la Louvière',\n",
       " 'Château Léoville Barton',\n",
       " 'Emile Beyer',\n",
       " 'Château Sainte Marguerite',\n",
       " 'Caccia al Piano 1868',\n",
       " 'Shea',\n",
       " 'Château Giscours',\n",
       " 'Bortoluzzi',\n",
       " 'Cramele Halewood',\n",
       " 'Fattoria Zerbina',\n",
       " 'Daniel Gehrs',\n",
       " 'Turner Road',\n",
       " 'Stemmari',\n",
       " 'Clos Solène',\n",
       " 'Den Hoed',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_winery = list(winery_counts[winery_counts < 30].index)\n",
    "replace_winery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe582541",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in replace_winery:\n",
    "    wine_df.winery = wine_df.winery.replace(i,\"Other\")\n",
    "\n",
    "winery_counts = wine_df.winery.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17666c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other                    85150\n",
       "Williams Selyem            374\n",
       "Testarossa                 277\n",
       "DFJ Vinhos                 258\n",
       "Chateau Ste. Michelle      226\n",
       "                         ...  \n",
       "Carol Shelton               30\n",
       "Merriam                     30\n",
       "Knipser                     30\n",
       "Borra                       30\n",
       "Finca Allende               30\n",
       "Name: winery, Length: 1185, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winery_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05e8031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b9c1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = wine_df.drop(columns=['description','designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdd74e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151835</th>\n",
       "      <td>US</td>\n",
       "      <td>87.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>Nero d'Avola</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151836</th>\n",
       "      <td>US</td>\n",
       "      <td>87.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>Roussanne</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151840</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>87.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Mendoza Province</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151841</th>\n",
       "      <td>France</td>\n",
       "      <td>87.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>France Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>Cinsault</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151842</th>\n",
       "      <td>US</td>\n",
       "      <td>87.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Rosé</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  points  price          province           region_1  \\\n",
       "151835         US    87.0   30.0             Texas              Other   \n",
       "151836         US    87.0   18.0             Texas              Other   \n",
       "151840  Argentina    87.0   30.0  Mendoza Province              Other   \n",
       "151841     France    87.0   23.0      France Other              Other   \n",
       "151842         US    87.0   18.0            Oregon  Willamette Valley   \n",
       "\n",
       "                 region_2                   variety winery  \n",
       "151835               None              Nero d'Avola  Other  \n",
       "151836               None                 Roussanne  Other  \n",
       "151840               None  Bordeaux-style Red Blend  Other  \n",
       "151841               None                  Cinsault  Other  \n",
       "151842  Willamette Valley                      Rosé  Other  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3446e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "float64\n",
      "float64\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "for col in wine_df:\n",
    "    print(wine_df[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c05fc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8bac756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/jordanravelo/opt/anaconda3/envs/mlenv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for col in wine_df:\n",
    "    if wine_df[col].dtype == 'object':\n",
    "        enc_col = wine_df[col]\n",
    "        wine_df = wine_df.drop(columns=col)\n",
    "        enc_col2 = pd.DataFrame(enc.fit_transform(enc_col.values.reshape(-1,1)))\n",
    "        enc_col2.columns = enc.get_feature_names([col])\n",
    "        wine_df = wine_df.merge(enc_col2,left_index=True,right_index=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "485dda8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>country_Argentina</th>\n",
       "      <th>country_Australia</th>\n",
       "      <th>country_Canada</th>\n",
       "      <th>country_France</th>\n",
       "      <th>country_Italy</th>\n",
       "      <th>country_Spain</th>\n",
       "      <th>country_US</th>\n",
       "      <th>province_Alsace</th>\n",
       "      <th>...</th>\n",
       "      <th>winery_William Hill Estate</th>\n",
       "      <th>winery_Williams Selyem</th>\n",
       "      <th>winery_Wilson</th>\n",
       "      <th>winery_Winderlea</th>\n",
       "      <th>winery_Woodward Canyon</th>\n",
       "      <th>winery_Wölffer</th>\n",
       "      <th>winery_Yalumba</th>\n",
       "      <th>winery_Zaca Mesa</th>\n",
       "      <th>winery_Zenato</th>\n",
       "      <th>winery_Zuccardi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 811 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   points  price  country_Argentina  country_Australia  country_Canada  \\\n",
       "0    96.0  235.0                0.0                0.0             0.0   \n",
       "1    96.0  110.0                0.0                0.0             0.0   \n",
       "2    96.0   90.0                0.0                0.0             0.0   \n",
       "3    96.0   65.0                0.0                0.0             0.0   \n",
       "4    95.0   66.0                0.0                0.0             0.0   \n",
       "\n",
       "   country_France  country_Italy  country_Spain  country_US  province_Alsace  \\\n",
       "0             0.0            0.0            0.0         1.0              0.0   \n",
       "1             0.0            0.0            1.0         0.0              0.0   \n",
       "2             0.0            0.0            0.0         1.0              0.0   \n",
       "3             0.0            0.0            0.0         1.0              0.0   \n",
       "4             1.0            0.0            0.0         0.0              0.0   \n",
       "\n",
       "   ...  winery_William Hill Estate  winery_Williams Selyem  winery_Wilson  \\\n",
       "0  ...                         0.0                     0.0            0.0   \n",
       "1  ...                         0.0                     0.0            0.0   \n",
       "2  ...                         0.0                     0.0            0.0   \n",
       "3  ...                         0.0                     0.0            0.0   \n",
       "4  ...                         0.0                     0.0            0.0   \n",
       "\n",
       "   winery_Winderlea  winery_Woodward Canyon  winery_Wölffer  winery_Yalumba  \\\n",
       "0               0.0                     0.0             0.0             0.0   \n",
       "1               0.0                     0.0             0.0             0.0   \n",
       "2               0.0                     0.0             0.0             0.0   \n",
       "3               0.0                     0.0             0.0             0.0   \n",
       "4               0.0                     0.0             0.0             0.0   \n",
       "\n",
       "   winery_Zaca Mesa  winery_Zenato  winery_Zuccardi  \n",
       "0               0.0            0.0              0.0  \n",
       "1               0.0            0.0              0.0  \n",
       "2               0.0            0.0              0.0  \n",
       "3               0.0            0.0              0.0  \n",
       "4               0.0            0.0              0.0  \n",
       "\n",
       "[5 rows x 811 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeacdb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points\n",
      "price\n",
      "country_Argentina\n",
      "country_Australia\n",
      "country_Canada\n",
      "country_France\n",
      "country_Italy\n",
      "country_Spain\n",
      "country_US\n",
      "province_Alsace\n",
      "province_Andalucia\n",
      "province_Arizona\n",
      "province_Australia Other\n",
      "province_Beaujolais\n",
      "province_Bordeaux\n",
      "province_British Columbia\n",
      "province_Burgundy\n",
      "province_California\n",
      "province_Catalonia\n",
      "province_Central Italy\n",
      "province_Central Spain\n",
      "province_Champagne\n",
      "province_Colorado\n",
      "province_France Other\n",
      "province_Galicia\n",
      "province_Idaho\n",
      "province_Iowa\n",
      "province_Italy Other\n",
      "province_Languedoc-Roussillon\n",
      "province_Levante\n",
      "province_Loire Valley\n",
      "province_Lombardy\n",
      "province_Massachusetts\n",
      "province_Mendoza Province\n",
      "province_Michigan\n",
      "province_Missouri\n",
      "province_New Jersey\n",
      "province_New Mexico\n",
      "province_New South Wales\n",
      "province_New York\n",
      "province_North Carolina\n",
      "province_Northeastern Italy\n",
      "province_Northern Spain\n",
      "province_Northwestern Italy\n",
      "province_Ohio\n",
      "province_Ontario\n",
      "province_Oregon\n",
      "province_Other\n",
      "province_Pennsylvania\n",
      "province_Piedmont\n",
      "province_Provence\n",
      "province_Rhône Valley\n",
      "province_Sicily & Sardinia\n",
      "province_South Australia\n",
      "province_Southern Italy\n",
      "province_Southwest France\n",
      "province_Spain Other\n",
      "province_Spanish Islands\n",
      "province_Tasmania\n",
      "province_Texas\n",
      "province_Tuscany\n",
      "province_Veneto\n",
      "province_Victoria\n",
      "province_Virginia\n",
      "province_Washington\n",
      "province_Western Australia\n",
      "region_1_Alexander Valley\n",
      "region_1_Alsace\n",
      "region_1_Alto Adige\n",
      "region_1_Amarone della Valpolicella Classico\n",
      "region_1_Anderson Valley\n",
      "region_1_Barbaresco\n",
      "region_1_Barolo\n",
      "region_1_Brunello di Montalcino\n",
      "region_1_Cahors\n",
      "region_1_California\n",
      "region_1_Carneros\n",
      "region_1_Cava\n",
      "region_1_Central Coast\n",
      "region_1_Chablis\n",
      "region_1_Champagne\n",
      "region_1_Chianti Classico\n",
      "region_1_Columbia Valley (WA)\n",
      "region_1_Côtes de Provence\n",
      "region_1_Dry Creek Valley\n",
      "region_1_Edna Valley\n",
      "region_1_Finger Lakes\n",
      "region_1_Horse Heaven Hills\n",
      "region_1_Lodi\n",
      "region_1_McLaren Vale\n",
      "region_1_Mendoza\n",
      "region_1_Monterey\n",
      "region_1_Napa Valley\n",
      "region_1_North Fork of Long Island\n",
      "region_1_Other\n",
      "region_1_Paso Robles\n",
      "region_1_Pessac-Léognan\n",
      "region_1_Red Mountain\n",
      "region_1_Ribera del Duero\n",
      "region_1_Rioja\n",
      "region_1_Russian River Valley\n",
      "region_1_Rutherford\n",
      "region_1_Saint-Émilion\n",
      "region_1_Sancerre\n",
      "region_1_Santa Barbara County\n",
      "region_1_Santa Cruz Mountains\n",
      "region_1_Santa Lucia Highlands\n",
      "region_1_Santa Maria Valley\n",
      "region_1_Santa Ynez Valley\n",
      "region_1_Sicilia\n",
      "region_1_Sonoma Coast\n",
      "region_1_Sonoma County\n",
      "region_1_Sonoma Valley\n",
      "region_1_Sta. Rita Hills\n",
      "region_1_Toscana\n",
      "region_1_Walla Walla Valley (WA)\n",
      "region_1_Washington\n",
      "region_1_Willamette Valley\n",
      "region_1_Yakima Valley\n",
      "region_2_California Other\n",
      "region_2_Central Coast\n",
      "region_2_Central Valley\n",
      "region_2_Columbia Valley\n",
      "region_2_Finger Lakes\n",
      "region_2_Long Island\n",
      "region_2_Mendocino/Lake Counties\n",
      "region_2_Napa\n",
      "region_2_Napa-Sonoma\n",
      "region_2_New York Other\n",
      "region_2_None\n",
      "region_2_North Coast\n",
      "region_2_Oregon Other\n",
      "region_2_Sierra Foothills\n",
      "region_2_Sonoma\n",
      "region_2_South Coast\n",
      "region_2_Southern Oregon\n",
      "region_2_Washington Other\n",
      "region_2_Willamette Valley\n",
      "variety_Aglianico\n",
      "variety_Albariño\n",
      "variety_Alicante Bouschet\n",
      "variety_Aligoté\n",
      "variety_Alsace white blend\n",
      "variety_Auxerrois\n",
      "variety_Barbera\n",
      "variety_Blaufränkisch\n",
      "variety_Bobal\n",
      "variety_Bonarda\n",
      "variety_Bordeaux-style Red Blend\n",
      "variety_Bordeaux-style White Blend\n",
      "variety_Cabernet Blend\n",
      "variety_Cabernet Franc\n",
      "variety_Cabernet Franc-Malbec\n",
      "variety_Cabernet Franc-Merlot\n",
      "variety_Cabernet Sauvignon\n",
      "variety_Cabernet Sauvignon-Cabernet Franc\n",
      "variety_Cabernet Sauvignon-Merlot\n",
      "variety_Cabernet Sauvignon-Sangiovese\n",
      "variety_Cabernet Sauvignon-Shiraz\n",
      "variety_Cabernet Sauvignon-Syrah\n",
      "variety_Cabernet-Shiraz\n",
      "variety_Cabernet-Syrah\n",
      "variety_Cannonau\n",
      "variety_Carignan\n",
      "variety_Carignan-Grenache\n",
      "variety_Carignane\n",
      "variety_Carineña\n",
      "variety_Cariñena-Garnacha\n",
      "variety_Carmenère\n",
      "variety_Carricante\n",
      "variety_Catarratto\n",
      "variety_Cesanese d'Affile\n",
      "variety_Chambourcin\n",
      "variety_Champagne Blend\n",
      "variety_Charbono\n",
      "variety_Chardonnay\n",
      "variety_Chardonnay-Sauvignon Blanc\n",
      "variety_Chardonnay-Semillon\n",
      "variety_Chardonnay-Viognier\n",
      "variety_Chasselas\n",
      "variety_Chenin Blanc\n",
      "variety_Chenin Blanc-Chardonnay\n",
      "variety_Ciliegiolo\n",
      "variety_Cinsault\n",
      "variety_Cococciola\n",
      "variety_Colombard-Sauvignon Blanc\n",
      "variety_Colombard-Ugni Blanc\n",
      "variety_Counoise\n",
      "variety_Dolcetto\n",
      "variety_Duras\n",
      "variety_Falanghina\n",
      "variety_Fer Servadou\n",
      "variety_Fiano\n",
      "variety_Frappato\n",
      "variety_Friulano\n",
      "variety_Fumé Blanc\n",
      "variety_G-S-M\n",
      "variety_Gaglioppo\n",
      "variety_Gamay\n",
      "variety_Gamay Noir\n",
      "variety_Garganega\n",
      "variety_Garnacha\n",
      "variety_Garnacha Blanca\n",
      "variety_Garnacha Tintorera\n",
      "variety_Garnacha-Syrah\n",
      "variety_Garnacha-Tempranillo\n",
      "variety_Gewürztraminer\n",
      "variety_Glera\n",
      "variety_Godello\n",
      "variety_Graciano\n",
      "variety_Grecanico\n",
      "variety_Greco\n",
      "variety_Grenache\n",
      "variety_Grenache Blanc\n",
      "variety_Grenache Blend\n",
      "variety_Grenache-Carignan\n",
      "variety_Grenache-Syrah\n",
      "variety_Grillo\n",
      "variety_Gros Manseng\n",
      "variety_Gros and Petit Manseng\n",
      "variety_Grüner Veltliner\n",
      "variety_Hondarrabi Zuri\n",
      "variety_Inzolia\n",
      "variety_Jacquère\n",
      "variety_Jaen\n",
      "variety_Lambrusco\n",
      "variety_Lambrusco Grasparossa\n",
      "variety_Lambrusco di Sorbara\n",
      "variety_Lemberger\n",
      "variety_Macabeo\n",
      "variety_Malbec\n",
      "variety_Malbec Blend\n",
      "variety_Malbec-Cabernet Sauvignon\n",
      "variety_Malbec-Merlot\n",
      "variety_Malbec-Petit Verdot\n",
      "variety_Malbec-Tannat\n",
      "variety_Malvasia\n",
      "variety_Malvasia Nera\n",
      "variety_Mantonico\n",
      "variety_Marsanne\n",
      "variety_Mauzac\n",
      "variety_Melon\n",
      "variety_Mencía\n",
      "variety_Meritage\n",
      "variety_Merlot\n",
      "variety_Merlot-Cabernet Sauvignon\n",
      "variety_Merlot-Malbec\n",
      "variety_Mission\n",
      "variety_Monastrell\n",
      "variety_Mondeuse\n",
      "variety_Montepulciano\n",
      "variety_Moscatel\n",
      "variety_Moscato\n",
      "variety_Mourvèdre\n",
      "variety_Muscat\n",
      "variety_Muscat Canelli\n",
      "variety_Müller-Thurgau\n",
      "variety_Nebbiolo\n",
      "variety_Negrette\n",
      "variety_Negroamaro\n",
      "variety_Nerello Cappuccio\n",
      "variety_Nerello Mascalese\n",
      "variety_Nero d'Avola\n",
      "variety_Norton\n",
      "variety_Orange Muscat\n",
      "variety_Palomino\n",
      "variety_Passerina\n",
      "variety_Pecorino\n",
      "variety_Pedro Ximénez\n",
      "variety_Petit Manseng\n",
      "variety_Petit Verdot\n",
      "variety_Petite Sirah\n",
      "variety_Petite Verdot\n",
      "variety_Picpoul\n",
      "variety_Pinot Auxerrois\n",
      "variety_Pinot Bianco\n",
      "variety_Pinot Blanc\n",
      "variety_Pinot Grigio\n",
      "variety_Pinot Gris\n",
      "variety_Pinot Nero\n",
      "variety_Pinot Noir\n",
      "variety_Pinot Noir-Gamay\n",
      "variety_Pinot Noir-Syrah\n",
      "variety_Port\n",
      "variety_Premsal\n",
      "variety_Primitivo\n",
      "variety_Prié Blanc\n",
      "variety_Provence red blend\n",
      "variety_Red Blend\n",
      "variety_Rhône-style Red Blend\n",
      "variety_Rhône-style White Blend\n",
      "variety_Riesling\n",
      "variety_Rkatsiteli\n",
      "variety_Romorantin\n",
      "variety_Rosado\n",
      "variety_Rosato\n",
      "variety_Rosé\n",
      "variety_Roussanne\n",
      "variety_Roussanne-Viognier\n",
      "variety_Sagrantino\n",
      "variety_Sangiovese\n",
      "variety_Sangiovese-Cabernet Sauvignon\n",
      "variety_Sangiovese-Syrah\n",
      "variety_Sauvignon\n",
      "variety_Sauvignon Blanc\n",
      "variety_Sauvignon Blanc-Chardonnay\n",
      "variety_Sauvignon Blanc-Semillon\n",
      "variety_Semillon-Sauvignon Blanc\n",
      "variety_Sherry\n",
      "variety_Shiraz\n",
      "variety_Shiraz-Viognier\n",
      "variety_Sparkling Blend\n",
      "variety_Sylvaner\n",
      "variety_Syrah\n",
      "variety_Syrah-Cabernet Sauvignon\n",
      "variety_Syrah-Grenache\n",
      "variety_Syrah-Merlot\n",
      "variety_Syrah-Mourvèdre\n",
      "variety_Syrah-Petite Sirah\n",
      "variety_Sémillon\n",
      "variety_Tannat\n",
      "variety_Tannat-Cabernet\n",
      "variety_Tannat-Merlot\n",
      "variety_Tempranillo\n",
      "variety_Tempranillo Blanco\n",
      "variety_Tempranillo Blend\n",
      "variety_Tempranillo-Cabernet Sauvignon\n",
      "variety_Tempranillo-Shiraz\n",
      "variety_Teroldego\n",
      "variety_Teroldego Rotaliano\n",
      "variety_Tinta Fina\n",
      "variety_Tinta de Toro\n",
      "variety_Tinto Fino\n",
      "variety_Tinto del Pais\n",
      "variety_Tocai Friulano\n",
      "variety_Torrontés\n",
      "variety_Touriga Nacional\n",
      "variety_Traminette\n",
      "variety_Trebbiano\n",
      "variety_Trepat\n",
      "variety_Turbiana\n",
      "variety_Ugni Blanc\n",
      "variety_Ugni Blanc-Colombard\n",
      "variety_Veltliner\n",
      "variety_Verdejo\n",
      "variety_Verdelho\n",
      "variety_Verdicchio\n",
      "variety_Vermentino\n",
      "variety_Vidal\n",
      "variety_Vignoles\n",
      "variety_Viognier\n",
      "variety_Viognier-Chardonnay\n",
      "variety_Viura\n",
      "variety_White Blend\n",
      "variety_Xarel-lo\n",
      "variety_Zibibbo\n",
      "variety_Zinfandel\n",
      "variety_Zweigelt\n",
      "winery_:Nota Bene\n",
      "winery_Abacela\n",
      "winery_Abbazia di Novacella\n",
      "winery_Acacia\n",
      "winery_Adelaida\n",
      "winery_Albert Bichot\n",
      "winery_Alexander Valley Vineyards\n",
      "winery_Alidis\n",
      "winery_Alma Rosa\n",
      "winery_Alta Vista\n",
      "winery_Amavi\n",
      "winery_Ampelos\n",
      "winery_Anam Cara\n",
      "winery_Angeline\n",
      "winery_Arbor Crest\n",
      "winery_Argento\n",
      "winery_Argyle\n",
      "winery_Arista\n",
      "winery_Armida\n",
      "winery_Artesa\n",
      "winery_Atwater\n",
      "winery_B Cellars\n",
      "winery_Babcock\n",
      "winery_Baglio di Pianetto\n",
      "winery_Baileyana\n",
      "winery_Ballentine\n",
      "winery_Balletto\n",
      "winery_Banfi\n",
      "winery_Barnett\n",
      "winery_Baron De Ley\n",
      "winery_Barone Ricasoli\n",
      "winery_Barton & Guestier\n",
      "winery_Beauregard\n",
      "winery_Benanti\n",
      "winery_Benegas\n",
      "winery_Benessere\n",
      "winery_Beni di Batasiolo\n",
      "winery_Beresan\n",
      "winery_Bergström\n",
      "winery_Bernard Magrez\n",
      "winery_Bernardus\n",
      "winery_Bianchi\n",
      "winery_Blackbird Vineyards\n",
      "winery_Bodega Catena Zapata\n",
      "winery_Bodega Norton\n",
      "winery_Bodega Renacer\n",
      "winery_Bodegas Dios Baco S.L.\n",
      "winery_Bodegas Fariña\n",
      "winery_Bodegas Valdemar\n",
      "winery_Bogle\n",
      "winery_Bonterra\n",
      "winery_Brander\n",
      "winery_Brian Carter Cellars\n",
      "winery_Buena Vista\n",
      "winery_Buttonwood Farm\n",
      "winery_Buty\n",
      "winery_Byron\n",
      "winery_CVNE\n",
      "winery_Calera\n",
      "winery_Cameron Hughes\n",
      "winery_Canoe Ridge\n",
      "winery_Cantina Produttori San Michele Appiano\n",
      "winery_Cantina Santadi\n",
      "winery_Cantina Terlano\n",
      "winery_Cantina di Soave\n",
      "winery_Capezzana\n",
      "winery_Carabella\n",
      "winery_Carol Shelton\n",
      "winery_Carpineto\n",
      "winery_Carr\n",
      "winery_Caruso & Minini\n",
      "winery_Cass\n",
      "winery_Castellare di Castellina\n",
      "winery_Castle Rock\n",
      "winery_Castoro Cellars\n",
      "winery_Cave de Ribeauvillé\n",
      "winery_Cave de Tain\n",
      "winery_Cecchi\n",
      "winery_Ceretto\n",
      "winery_Chakana\n",
      "winery_Chamisal Vineyards\n",
      "winery_Chanson Père et Fils\n",
      "winery_Charles Krug\n",
      "winery_Chateau Lafayette Reneau\n",
      "winery_Chateau St. Jean\n",
      "winery_Chateau Ste. Michelle\n",
      "winery_Château Bélingard\n",
      "winery_Château Haut-Brion\n",
      "winery_Château Lagrézette\n",
      "winery_Château Margaux\n",
      "winery_Château Moncontour\n",
      "winery_Château Tour des Gendres\n",
      "winery_Château d'Esclans\n",
      "winery_Cinnabar\n",
      "winery_Claiborne & Churchill\n",
      "winery_Clif Family\n",
      "winery_Clos La Chance\n",
      "winery_Clos Troteligotte\n",
      "winery_Clos du Bois\n",
      "winery_Collier Falls\n",
      "winery_Colterenzio\n",
      "winery_Columbia Crest\n",
      "winery_Columbia Winery\n",
      "winery_Concannon\n",
      "winery_Coquelicot\n",
      "winery_Cosentino\n",
      "winery_Coto de Hayas\n",
      "winery_Cottanera\n",
      "winery_Courtney Benham\n",
      "winery_Cusumano\n",
      "winery_Cuvaison\n",
      "winery_D'Arenberg\n",
      "winery_Damiani\n",
      "winery_David Hill\n",
      "winery_Davis Family\n",
      "winery_De Loach\n",
      "winery_DeLille\n",
      "winery_DeLorimier\n",
      "winery_Demetria\n",
      "winery_Di Meo\n",
      "winery_Domaine Barmès-Buecher\n",
      "winery_Domaine D'en Ségur\n",
      "winery_Domaine Ehrhart\n",
      "winery_Domaine Faiveley\n",
      "winery_Domaine Fouassier\n",
      "winery_Domaine Jean Bousquet\n",
      "winery_Domaine Laroche\n",
      "winery_Domaine Marcel Deiss\n",
      "winery_Domaine Rotier\n",
      "winery_Domaine Schoffit\n",
      "winery_Domaine Serene\n",
      "winery_Domaine Vincent Girardin\n",
      "winery_Domaine Zind-Humbrecht\n",
      "winery_Domaine de Chevalier\n",
      "winery_Domaine des Baumard\n",
      "winery_Domaine du Tariquet\n",
      "winery_Domaines Ott\n",
      "winery_Domaines Schlumberger\n",
      "winery_Donnafugata\n",
      "winery_Donum\n",
      "winery_Dopff & Irion\n",
      "winery_Dr. Konstantin Frank\n",
      "winery_Dry Creek Vineyard\n",
      "winery_Duckhorn\n",
      "winery_Dunham\n",
      "winery_Dusted Valley\n",
      "winery_Dutton-Goldfield\n",
      "winery_EOS\n",
      "winery_Easton\n",
      "winery_Eberle\n",
      "winery_Edna Valley Vineyard\n",
      "winery_Efeste\n",
      "winery_Elena Walch\n",
      "winery_Elk Cove\n",
      "winery_Elyse\n",
      "winery_Emilio Moro\n",
      "winery_Emina\n",
      "winery_Epiphany\n",
      "winery_Etude\n",
      "winery_Evening Land\n",
      "winery_Failla\n",
      "winery_Fenestra\n",
      "winery_Ferrari-Carano\n",
      "winery_Fess Parker\n",
      "winery_Fetzer\n",
      "winery_Feudi di San Gregorio\n",
      "winery_Finca Sophenia\n",
      "winery_Firriato\n",
      "winery_Flora Springs\n",
      "winery_Foley\n",
      "winery_Folin Cellars\n",
      "winery_Foppiano\n",
      "winery_Four Vines\n",
      "winery_Fox Run\n",
      "winery_Foxen\n",
      "winery_Francis Ford Coppola\n",
      "winery_Frank Family\n",
      "winery_François Lurton\n",
      "winery_Freemark Abbey\n",
      "winery_Fritz\n",
      "winery_Frog's Leap\n",
      "winery_Gainey\n",
      "winery_Gaja\n",
      "winery_García Figuero\n",
      "winery_Gary Farrell\n",
      "winery_Georges Vigouroux\n",
      "winery_Glenora\n",
      "winery_Goldschmidt\n",
      "winery_González Byass\n",
      "winery_Greenwood Ridge\n",
      "winery_Grgich Hills\n",
      "winery_Gundlach Bundschu\n",
      "winery_Gustave Lorentz\n",
      "winery_Gård\n",
      "winery_Hall\n",
      "winery_Helix by Reininger\n",
      "winery_Henri Bourgeois\n",
      "winery_Henschke\n",
      "winery_Heron Hill\n",
      "winery_Herzog\n",
      "winery_Hess Collection\n",
      "winery_Hirsch\n",
      "winery_Hugel\n",
      "winery_Hunt Cellars\n",
      "winery_I Veroni\n",
      "winery_Ironstone\n",
      "winery_J Vineyards & Winery\n",
      "winery_Jarvis\n",
      "winery_Jean-Baptiste Adam\n",
      "winery_Jean-Luc and Paul Aegerter\n",
      "winery_Jim Barry\n",
      "winery_Joseph Mellot\n",
      "winery_Joseph Swan Vineyards\n",
      "winery_Josmeyer\n",
      "winery_Joullian\n",
      "winery_Justin\n",
      "winery_K Vintners\n",
      "winery_Kaiken\n",
      "winery_Keating\n",
      "winery_Keenan\n",
      "winery_Keller Estate\n",
      "winery_Kellerei Kaltern Caldaro\n",
      "winery_Ken Wright\n",
      "winery_Kendall-Jackson\n",
      "winery_Kenwood\n",
      "winery_Keuka Spring\n",
      "winery_King Estate\n",
      "winery_Kirkland Signature\n",
      "winery_Koehler\n",
      "winery_Korbel\n",
      "winery_Krutz\n",
      "winery_Kuentz-Bas\n",
      "winery_Kuleto Estate\n",
      "winery_Kunde\n",
      "winery_Kynsi\n",
      "winery_L'Ecole No. 41\n",
      "winery_La Fenêtre\n",
      "winery_La Rochelle\n",
      "winery_Labouré-Roi\n",
      "winery_Laetitia\n",
      "winery_Lafond\n",
      "winery_Lakewood\n",
      "winery_Lamoreaux Landing\n",
      "winery_Landmark\n",
      "winery_Lava Cap\n",
      "winery_Le Macchiole\n",
      "winery_Left Coast Cellars\n",
      "winery_Longboard\n",
      "winery_Loring Wine Company\n",
      "winery_Louis Max\n",
      "winery_Lucas & Lewellen\n",
      "winery_Lucien Albrecht\n",
      "winery_Luigi Bosca\n",
      "winery_Luna Beberide\n",
      "winery_Lynmar\n",
      "winery_M. Chapoutier\n",
      "winery_MacPhail\n",
      "winery_Madrigal\n",
      "winery_Mahoney\n",
      "winery_Manzoni\n",
      "winery_Marchesi de' Frescobaldi\n",
      "winery_Marchesi di Barolo\n",
      "winery_Margerum\n",
      "winery_Marimar Estate\n",
      "winery_Markham\n",
      "winery_Marqués de Cáceres\n",
      "winery_Marqués de Gelida\n",
      "winery_Martin Ranch\n",
      "winery_Martin Ray\n",
      "winery_Mastroberardino\n",
      "winery_Matchbook\n",
      "winery_Mazzei\n",
      "winery_Mazzocco\n",
      "winery_McIntyre Vineyards\n",
      "winery_Melrose\n",
      "winery_Mercer\n",
      "winery_Merriam\n",
      "winery_Merry Edwards\n",
      "winery_Merryvale\n",
      "winery_Mezzacorona\n",
      "winery_Michel Torino\n",
      "winery_Michele Satta\n",
      "winery_Midnight\n",
      "winery_Midsummer Cellars\n",
      "winery_Milbrandt\n",
      "winery_Miraflores\n",
      "winery_Montecillo\n",
      "winery_Montevina\n",
      "winery_Monticello Vineyards\n",
      "winery_Morgan\n",
      "winery_Mounts\n",
      "winery_Muga\n",
      "winery_Mumm Napa\n",
      "winery_Murphy-Goode\n",
      "winery_Muscardini\n",
      "winery_Naggiar\n",
      "winery_Navarro\n",
      "winery_Nieto Senetiner\n",
      "winery_Novy\n",
      "winery_OS Winery\n",
      "winery_Oak Grove\n",
      "winery_Ochoa\n",
      "winery_Osborne\n",
      "winery_Oso Libre\n",
      "winery_Other\n",
      "winery_Ott & Murphy\n",
      "winery_Owen Roe\n",
      "winery_Pali\n",
      "winery_Panther Creek\n",
      "winery_Paraiso Vineyards\n",
      "winery_Parducci\n",
      "winery_Pascual Toso\n",
      "winery_Peachy Canyon\n",
      "winery_Pedroncelli\n",
      "winery_Peirano\n",
      "winery_Penfolds\n",
      "winery_Pepper Bridge\n",
      "winery_Perry Creek\n",
      "winery_Peter Lehmann\n",
      "winery_Piattelli\n",
      "winery_Piccini\n",
      "winery_Pietra Santa\n",
      "winery_Pine Ridge\n",
      "winery_Pio Cesare\n",
      "winery_Pizzolato\n",
      "winery_Planeta\n",
      "winery_Plantagenet\n",
      "winery_Poderi Luigi Einaudi\n",
      "winery_Poggio Antico\n",
      "winery_Ponzi\n",
      "winery_Pride Mountain\n",
      "winery_Producteurs Plaimont\n",
      "winery_Provenance Vineyards\n",
      "winery_Quivira\n",
      "winery_Ramón Bilbao\n",
      "winery_Rancho Sisquoc\n",
      "winery_Rancho Zabaco\n",
      "winery_Raptor Ridge\n",
      "winery_Ravenswood\n",
      "winery_Raymond\n",
      "winery_Renieri\n",
      "winery_Renwood\n",
      "winery_René Muré\n",
      "winery_Rex Hill\n",
      "winery_Ridge\n",
      "winery_Roar\n",
      "winery_Robert Hall\n",
      "winery_Rocca delle Macìe\n",
      "winery_Roche de Bellene\n",
      "winery_Rock Wall\n",
      "winery_Rodney Strong\n",
      "winery_Rooster Hill\n",
      "winery_Rusack\n",
      "winery_Rutherford Hill\n",
      "winery_Rutini\n",
      "winery_Saintsbury\n",
      "winery_Salentein\n",
      "winery_San Simeon\n",
      "winery_Sanguis\n",
      "winery_Santa Barbara Winery\n",
      "winery_Santa Julia\n",
      "winery_Saviah\n",
      "winery_Sbragia\n",
      "winery_Schramsberg\n",
      "winery_Schug\n",
      "winery_Septima\n",
      "winery_Sequoia Grove\n",
      "winery_Sextant\n",
      "winery_Shannon Ridge\n",
      "winery_Shaw\n",
      "winery_Sheldrake Point\n",
      "winery_Siduri\n",
      "winery_Sierra Cantabria\n",
      "winery_Silvan Ridge\n",
      "winery_Simi\n",
      "winery_Sineann\n",
      "winery_Six Sigma Ranch\n",
      "winery_Smoking Loon\n",
      "winery_Sobon Estate\n",
      "winery_Sokol Blosser\n",
      "winery_Soléna\n",
      "winery_Spann Vineyards\n",
      "winery_Sparkman\n",
      "winery_Speri\n",
      "winery_Spindrift Cellars\n",
      "winery_St. Supéry\n",
      "winery_Stag's Leap Wine Cellars\n",
      "winery_Standing Stone\n",
      "winery_Steele\n",
      "winery_Stephen Ross\n",
      "winery_Steven Kent\n",
      "winery_Stoller\n",
      "winery_Stolpman\n",
      "winery_Summerland\n",
      "winery_Summers\n",
      "winery_Sur de los Andes\n",
      "winery_Syncline\n",
      "winery_Tablas Creek\n",
      "winery_Tahbilk\n",
      "winery_Taittinger\n",
      "winery_Talbott\n",
      "winery_Talley\n",
      "winery_Tamarack Cellars\n",
      "winery_Tantara\n",
      "winery_Tarara\n",
      "winery_Tenuta Argentiera\n",
      "winery_Tenuta Rapitalà\n",
      "winery_Tenuta Sette Ponti\n",
      "winery_Tenuta Vitanza\n",
      "winery_Tenuta di Trecciano\n",
      "winery_Tenute Cisa Asinari dei Marchesi di Gresy\n",
      "winery_Terrazas de Los Andes\n",
      "winery_Terre del Marchesato\n",
      "winery_Terredora\n",
      "winery_Testarossa\n",
      "winery_The Eyrie Vineyards\n",
      "winery_Thurston Wolfe\n",
      "winery_Tolosa\n",
      "winery_Torbreck\n",
      "winery_Torii Mor\n",
      "winery_Trapiche\n",
      "winery_Trefethen\n",
      "winery_Trinchero\n",
      "winery_Trisaetum\n",
      "winery_Trivento\n",
      "winery_V. Sattui\n",
      "winery_Valentin Bianchi\n",
      "winery_Veramar\n",
      "winery_Vicente Gandia\n",
      "winery_Vietti\n",
      "winery_Villa Matilde\n",
      "winery_Vina Robles\n",
      "winery_Vinum\n",
      "winery_Viña Cobos\n",
      "winery_Viña Mayor\n",
      "winery_Volpaia\n",
      "winery_Von Strasser\n",
      "winery_Wagner\n",
      "winery_Waterbrook\n",
      "winery_Wellington\n",
      "winery_Wente\n",
      "winery_Willamette Valley Vineyards\n",
      "winery_William Church\n",
      "winery_William Hill Estate\n",
      "winery_Williams Selyem\n",
      "winery_Wilson\n",
      "winery_Winderlea\n",
      "winery_Woodward Canyon\n",
      "winery_Wölffer\n",
      "winery_Yalumba\n",
      "winery_Zaca Mesa\n",
      "winery_Zenato\n",
      "winery_Zuccardi\n"
     ]
    }
   ],
   "source": [
    "for col in wine_df:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bddadd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine_df['points']\n",
    "X = wine_df.drop(columns='points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c2a56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e33d9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_test_scaled = X_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bf18f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_scaled[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13bb9095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 18:00:44.499170: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_layers_1 = 750\n",
    "hidden_layers_list = [250]\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_layers_1, input_dim=number_input_features, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "nn.add(tf.keras.layers.Dropout(0.5))\n",
    "for i in hidden_layers_list:\n",
    "    nn.add(tf.keras.layers.Dense(units=i, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "    nn.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='relu'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e4c293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_weights.h5',save_best_only=True,save_weights_only = True,monitor = 'val_mae',verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4ca9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss = 'mae',optimizer ='adam',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c411dfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 750)               608250    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 750)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               187750    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 250)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 796,251\n",
      "Trainable params: 796,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6d4ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_mae',patience = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f30f2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 216.0231 - mae: 65.5047\n",
      "Epoch 1: val_mae improved from inf to 59.29276, saving model to best_weights.h5\n",
      "51/51 [==============================] - 1s 7ms/step - loss: 213.1267 - mae: 64.5792 - val_loss: 136.3293 - val_mae: 59.2928\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 73.7744 - mae: 14.3321\n",
      "Epoch 2: val_mae improved from 59.29276 to 54.74047, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 73.7138 - mae: 14.3497 - val_loss: 103.4168 - val_mae: 54.7405\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 58.6168 - mae: 14.0753\n",
      "Epoch 3: val_mae improved from 54.74047 to 37.90094, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 58.6168 - mae: 14.0753 - val_loss: 79.2267 - val_mae: 37.9009\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 50.5312 - mae: 12.1794\n",
      "Epoch 4: val_mae did not improve from 37.90094\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 50.4772 - mae: 12.1452 - val_loss: 77.6978 - val_mae: 42.1350\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 46.3176 - mae: 12.5931\n",
      "Epoch 5: val_mae did not improve from 37.90094\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 45.6963 - mae: 12.3868 - val_loss: 70.3151 - val_mae: 39.3823\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 41.6343 - mae: 12.3475\n",
      "Epoch 6: val_mae improved from 37.90094 to 20.80261, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 41.6343 - mae: 12.3475 - val_loss: 48.4888 - val_mae: 20.8026\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 38.4133 - mae: 12.0708\n",
      "Epoch 7: val_mae did not improve from 20.80261\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 37.9496 - mae: 11.8797 - val_loss: 49.9883 - val_mae: 25.4459\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 35.1263 - mae: 11.6509\n",
      "Epoch 8: val_mae did not improve from 20.80261\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 35.1287 - mae: 11.6622 - val_loss: 43.1908 - val_mae: 20.9998\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 32.4502 - mae: 11.0519\n",
      "Epoch 9: val_mae did not improve from 20.80261\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 32.4684 - mae: 11.0743 - val_loss: 63.3727 - val_mae: 42.5820\n",
      "Epoch 10/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 31.0183 - mae: 11.0692\n",
      "Epoch 10: val_mae did not improve from 20.80261\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 31.0183 - mae: 11.0692 - val_loss: 44.9986 - val_mae: 26.1669\n",
      "Epoch 11/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 29.1613 - mae: 10.4338\n",
      "Epoch 11: val_mae did not improve from 20.80261\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 29.1613 - mae: 10.4338 - val_loss: 41.0487 - val_mae: 22.6134\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 1\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 37.7702 - mae: 11.5474\n",
      "Epoch 1: val_mae improved from 20.80261 to 19.63776, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 37.7726 - mae: 11.5586 - val_loss: 44.8328 - val_mae: 19.6378\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 35.2943 - mae: 11.4190\n",
      "Epoch 2: val_mae did not improve from 19.63776\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 35.2375 - mae: 11.4018 - val_loss: 42.4285 - val_mae: 20.1665\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 32.8348 - mae: 11.3719\n",
      "Epoch 3: val_mae did not improve from 19.63776\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 32.8469 - mae: 11.3922 - val_loss: 45.3875 - val_mae: 24.9598\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 30.9144 - mae: 11.1825\n",
      "Epoch 4: val_mae did not improve from 19.63776\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 30.9144 - mae: 11.1825 - val_loss: 40.6295 - val_mae: 21.6755\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 29.2565 - mae: 10.9043\n",
      "Epoch 5: val_mae did not improve from 19.63776\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 29.1866 - mae: 10.8453 - val_loss: 43.6359 - val_mae: 25.6022\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 28.0543 - mae: 10.4955\n",
      "Epoch 6: val_mae improved from 19.63776 to 15.50323, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 28.0146 - mae: 10.5044 - val_loss: 32.5158 - val_mae: 15.5032\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 27.3767 - mae: 10.4251\n",
      "Epoch 7: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 27.3748 - mae: 10.4210 - val_loss: 50.6252 - val_mae: 33.4157\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 26.1922 - mae: 9.6246\n",
      "Epoch 8: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 26.1860 - mae: 9.6207 - val_loss: 56.6560 - val_mae: 40.3214\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 26.4537 - mae: 10.1673\n",
      "Epoch 9: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 26.4579 - mae: 10.1695 - val_loss: 48.3802 - val_mae: 31.6267\n",
      "Epoch 10/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 25.7916 - mae: 9.4406\n",
      "Epoch 10: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 25.7945 - mae: 9.4454 - val_loss: 34.4876 - val_mae: 18.4888\n",
      "Epoch 11/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 25.1381 - mae: 9.2142\n",
      "Epoch 11: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 25.0668 - mae: 9.1595 - val_loss: 42.5453 - val_mae: 27.0834\n",
      "Epoch 11: early stopping\n",
      "Random Weights 2\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 24.4939 - mae: 9.1247\n",
      "Epoch 1: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 24.5701 - mae: 9.2063 - val_loss: 38.3128 - val_mae: 22.9140\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 24.6081 - mae: 9.1797\n",
      "Epoch 2: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 24.5939 - mae: 9.1733 - val_loss: 34.5285 - val_mae: 19.4031\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 23.8214 - mae: 8.7977\n",
      "Epoch 3: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 23.8194 - mae: 8.7938 - val_loss: 54.8106 - val_mae: 39.4498\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 23.8090 - mae: 8.7080\n",
      "Epoch 4: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 23.8132 - mae: 8.7114 - val_loss: 43.8417 - val_mae: 28.9083\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 23.3454 - mae: 8.6430\n",
      "Epoch 5: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 23.3200 - mae: 8.6165 - val_loss: 32.4305 - val_mae: 17.7849\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 23.4605 - mae: 8.8570\n",
      "Epoch 6: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 23.4519 - mae: 8.8360 - val_loss: 47.3033 - val_mae: 32.1375\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 22.3555 - mae: 8.0164\n",
      "Epoch 7: val_mae did not improve from 15.50323\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 22.3775 - mae: 8.0454 - val_loss: 31.0413 - val_mae: 16.9998\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 22.4563 - mae: 8.4261\n",
      "Epoch 8: val_mae improved from 15.50323 to 5.67241, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 22.4427 - mae: 8.4132 - val_loss: 19.5146 - val_mae: 5.6724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 21.9303 - mae: 8.2404\n",
      "Epoch 9: val_mae did not improve from 5.67241\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 21.9303 - mae: 8.2404 - val_loss: 56.6783 - val_mae: 43.1660\n",
      "Epoch 10/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 21.1904 - mae: 8.0927\n",
      "Epoch 10: val_mae did not improve from 5.67241\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 21.1654 - mae: 8.0428 - val_loss: 47.4815 - val_mae: 34.1482\n",
      "Epoch 11/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 21.2388 - mae: 8.1472\n",
      "Epoch 11: val_mae did not improve from 5.67241\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 21.3023 - mae: 8.2335 - val_loss: 51.2861 - val_mae: 38.1890\n",
      "Epoch 12/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 20.8064 - mae: 8.1588\n",
      "Epoch 12: val_mae did not improve from 5.67241\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 20.6242 - mae: 8.0116 - val_loss: 37.0264 - val_mae: 24.2150\n",
      "Epoch 13/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 20.7190 - mae: 8.2208\n",
      "Epoch 13: val_mae did not improve from 5.67241\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 20.6331 - mae: 8.1080 - val_loss: 36.4734 - val_mae: 23.8896\n",
      "Epoch 13: early stopping\n",
      "loaded Weights 3\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 21.6403 - mae: 8.2294\n",
      "Epoch 1: val_mae did not improve from 5.67241\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 21.6403 - mae: 8.2294 - val_loss: 23.0376 - val_mae: 10.1021\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 20.6874 - mae: 8.0497\n",
      "Epoch 2: val_mae did not improve from 5.67241\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 20.7027 - mae: 8.0469 - val_loss: 19.4315 - val_mae: 6.8637\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 20.5049 - mae: 8.0473\n",
      "Epoch 3: val_mae did not improve from 5.67241\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 20.5049 - mae: 8.0473 - val_loss: 25.2388 - val_mae: 13.0316\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 20.3462 - mae: 8.4418\n",
      "Epoch 4: val_mae improved from 5.67241 to 4.38351, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 20.2630 - mae: 8.3397 - val_loss: 16.4088 - val_mae: 4.3835\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 19.8462 - mae: 8.1166\n",
      "Epoch 5: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 19.7301 - mae: 8.0166 - val_loss: 23.1462 - val_mae: 11.5147\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 18.7478 - mae: 7.3715\n",
      "Epoch 6: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.7478 - mae: 7.3715 - val_loss: 42.1926 - val_mae: 30.7044\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 19.7466 - mae: 8.2951\n",
      "Epoch 7: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 19.7466 - mae: 8.2951 - val_loss: 27.4879 - val_mae: 16.1988\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 19.0592 - mae: 7.9769\n",
      "Epoch 8: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 19.0154 - mae: 7.8735 - val_loss: 33.9746 - val_mae: 22.6272\n",
      "Epoch 9/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 18.9148 - mae: 7.6738\n",
      "Epoch 9: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.8041 - mae: 7.5689 - val_loss: 25.9996 - val_mae: 14.8483\n",
      "Epoch 9: early stopping\n",
      "Random Weights 4\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 18.3431 - mae: 7.5329\n",
      "Epoch 1: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.3502 - mae: 7.5414 - val_loss: 24.2488 - val_mae: 13.6460\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 17.8264 - mae: 7.2593\n",
      "Epoch 2: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.8422 - mae: 7.2758 - val_loss: 21.4185 - val_mae: 10.9087\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 17.7113 - mae: 7.3568\n",
      "Epoch 3: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.7113 - mae: 7.3568 - val_loss: 26.7558 - val_mae: 16.4408\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 17.4716 - mae: 7.2824\n",
      "Epoch 4: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.4979 - mae: 7.3109 - val_loss: 30.1166 - val_mae: 20.1929\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 16.9091 - mae: 7.3286\n",
      "Epoch 5: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.8898 - mae: 7.3092 - val_loss: 36.5685 - val_mae: 26.9643\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 17.2730 - mae: 7.6232\n",
      "Epoch 6: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.2730 - mae: 7.6232 - val_loss: 26.5199 - val_mae: 16.6512\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 17.0817 - mae: 7.3809\n",
      "Epoch 7: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.9394 - mae: 7.2794 - val_loss: 27.1108 - val_mae: 17.6318\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 5\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 19.3523 - mae: 7.7122\n",
      "Epoch 1: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 19.3404 - mae: 7.7066 - val_loss: 28.1821 - val_mae: 16.7353\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 18.8481 - mae: 7.6484\n",
      "Epoch 2: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.8171 - mae: 7.6177 - val_loss: 17.4975 - val_mae: 6.2571\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 18.8867 - mae: 7.8971\n",
      "Epoch 3: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.8928 - mae: 7.9019 - val_loss: 38.1819 - val_mae: 26.9703\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 18.8953 - mae: 7.8328\n",
      "Epoch 4: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.8818 - mae: 7.8240 - val_loss: 30.2370 - val_mae: 19.1938\n",
      "Epoch 5/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 18.3688 - mae: 7.5389\n",
      "Epoch 5: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.3688 - mae: 7.5389 - val_loss: 33.4556 - val_mae: 22.6054\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 18.1972 - mae: 7.6680\n",
      "Epoch 6: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.2308 - mae: 7.6988 - val_loss: 34.6722 - val_mae: 23.8058\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 18.0602 - mae: 7.6255\n",
      "Epoch 7: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.0485 - mae: 7.6154 - val_loss: 18.0541 - val_mae: 7.8016\n",
      "Epoch 7: early stopping\n",
      "Random Weights 6\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 17.9244 - mae: 7.6995\n",
      "Epoch 1: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.9030 - mae: 7.6816 - val_loss: 33.9262 - val_mae: 23.8761\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 17.5420 - mae: 7.4913\n",
      "Epoch 2: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.5315 - mae: 7.4806 - val_loss: 16.0032 - val_mae: 6.0133\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 17.2357 - mae: 7.4788\n",
      "Epoch 3: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.2508 - mae: 7.4935 - val_loss: 25.6246 - val_mae: 15.8684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 16.6068 - mae: 7.1863\n",
      "Epoch 4: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.6068 - mae: 7.1863 - val_loss: 28.3563 - val_mae: 18.9260\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 17.0551 - mae: 7.5778\n",
      "Epoch 5: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.1595 - mae: 7.6201 - val_loss: 19.8729 - val_mae: 10.2411\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 16.8698 - mae: 7.4341\n",
      "Epoch 6: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.8910 - mae: 7.5005 - val_loss: 17.7176 - val_mae: 8.6573\n",
      "Epoch 7/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 16.8953 - mae: 7.7951\n",
      "Epoch 7: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.8076 - mae: 7.7089 - val_loss: 16.7614 - val_mae: 7.6965\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 7\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 19.7636 - mae: 8.1009\n",
      "Epoch 1: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 19.6125 - mae: 7.9836 - val_loss: 21.1681 - val_mae: 9.6434\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 19.1003 - mae: 7.7822\n",
      "Epoch 2: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 19.0334 - mae: 7.6919 - val_loss: 21.5310 - val_mae: 10.0332\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 19.1270 - mae: 7.8624\n",
      "Epoch 3: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 19.1270 - mae: 7.8624 - val_loss: 16.1891 - val_mae: 5.0710\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 19.3260 - mae: 8.1299\n",
      "Epoch 4: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 19.1474 - mae: 7.9422 - val_loss: 21.6936 - val_mae: 10.3052\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 18.5123 - mae: 7.6668\n",
      "Epoch 5: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.4638 - mae: 7.6336 - val_loss: 30.4377 - val_mae: 19.6052\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 18.2906 - mae: 7.6000\n",
      "Epoch 6: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.3612 - mae: 7.6346 - val_loss: 38.1632 - val_mae: 27.3221\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 18.0271 - mae: 7.5586\n",
      "Epoch 7: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 18.0271 - mae: 7.5586 - val_loss: 30.6159 - val_mae: 20.3796\n",
      "Epoch 8/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 17.5201 - mae: 7.4055\n",
      "Epoch 8: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.5201 - mae: 7.4055 - val_loss: 14.7679 - val_mae: 4.6204\n",
      "Epoch 9/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 17.1026 - mae: 7.0566\n",
      "Epoch 9: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.1026 - mae: 7.0566 - val_loss: 25.7872 - val_mae: 15.8517\n",
      "Epoch 10/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 17.3691 - mae: 7.4850\n",
      "Epoch 10: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 17.3691 - mae: 7.4850 - val_loss: 26.3786 - val_mae: 16.5319\n",
      "Epoch 11/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 17.0404 - mae: 7.5399\n",
      "Epoch 11: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.8573 - mae: 7.3877 - val_loss: 25.9707 - val_mae: 16.7042\n",
      "Epoch 12/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 16.3998 - mae: 7.3259\n",
      "Epoch 12: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.3872 - mae: 7.3139 - val_loss: 26.0756 - val_mae: 16.9664\n",
      "Epoch 13/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 16.5807 - mae: 7.4922\n",
      "Epoch 13: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.5823 - mae: 7.4937 - val_loss: 17.2613 - val_mae: 8.1802\n",
      "Epoch 13: early stopping\n",
      "Random Weights 8\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 16.2004 - mae: 7.1065\n",
      "Epoch 1: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.1935 - mae: 7.0998 - val_loss: 25.1666 - val_mae: 16.1552\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 16.3900 - mae: 7.4380\n",
      "Epoch 2: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.2513 - mae: 7.3395 - val_loss: 21.5034 - val_mae: 12.8743\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 15.7405 - mae: 7.1527\n",
      "Epoch 3: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.7416 - mae: 7.1551 - val_loss: 23.4322 - val_mae: 14.9685\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 16.3489 - mae: 7.8326\n",
      "Epoch 4: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 16.3530 - mae: 7.8400 - val_loss: 16.4376 - val_mae: 7.9638\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 15.5782 - mae: 7.3956\n",
      "Epoch 5: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.5762 - mae: 7.3975 - val_loss: 32.7203 - val_mae: 24.5346\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 15.1759 - mae: 7.1455\n",
      "Epoch 6: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.1531 - mae: 7.1250 - val_loss: 20.3982 - val_mae: 12.5596\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.5424 - mae: 6.8580\n",
      "Epoch 7: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.5623 - mae: 6.8809 - val_loss: 20.1592 - val_mae: 12.4991\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.4992 - mae: 6.9877\n",
      "Epoch 8: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.5333 - mae: 7.0202 - val_loss: 15.6232 - val_mae: 7.9612\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.8998 - mae: 7.3298\n",
      "Epoch 9: val_mae did not improve from 4.38351\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.8975 - mae: 7.3266 - val_loss: 17.4789 - val_mae: 9.8152\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 15.2686 - mae: 7.6853\n",
      "Epoch 10: val_mae improved from 4.38351 to 2.49009, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.3309 - mae: 7.7562 - val_loss: 9.7720 - val_mae: 2.4901\n",
      "Epoch 11/10000\n",
      "47/51 [==========================>...] - ETA: 0s - loss: 14.7274 - mae: 7.4335\n",
      "Epoch 11: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.7093 - mae: 7.4162 - val_loss: 17.4571 - val_mae: 10.1578\n",
      "Epoch 12/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.3967 - mae: 7.2101\n",
      "Epoch 12: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.3898 - mae: 7.2028 - val_loss: 21.6118 - val_mae: 14.3975\n",
      "Epoch 13/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.2867 - mae: 7.2383\n",
      "Epoch 13: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.2560 - mae: 7.2047 - val_loss: 12.0199 - val_mae: 4.8542\n",
      "Epoch 14/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.4865 - mae: 7.4033\n",
      "Epoch 14: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.4607 - mae: 7.3806 - val_loss: 12.3698 - val_mae: 5.4669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.0898 - mae: 7.2532\n",
      "Epoch 15: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.9720 - mae: 7.1523 - val_loss: 13.9063 - val_mae: 7.1021\n",
      "Epoch 15: early stopping\n",
      "loaded Weights 9\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.9381 - mae: 6.8620\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.9381 - mae: 6.8620 - val_loss: 17.1137 - val_mae: 10.0137\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.1886 - mae: 7.0838\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1029 - mae: 6.9862 - val_loss: 25.2690 - val_mae: 18.0658\n",
      "Epoch 3/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 14.2142 - mae: 6.9251\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.2297 - mae: 6.9440 - val_loss: 25.3079 - val_mae: 18.0888\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.3113 - mae: 7.1176\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.4190 - mae: 7.2523 - val_loss: 11.7616 - val_mae: 4.7245\n",
      "Epoch 5/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 14.1343 - mae: 7.2133\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.0229 - mae: 7.1492 - val_loss: 13.3757 - val_mae: 6.7278\n",
      "Epoch 6/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 14.0119 - mae: 7.2708\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.9861 - mae: 7.2658 - val_loss: 18.7409 - val_mae: 12.1406\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.3742 - mae: 6.7324\n",
      "Epoch 7: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.3742 - mae: 6.7324 - val_loss: 15.3893 - val_mae: 8.7288\n",
      "Epoch 8/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.8545 - mae: 7.0969\n",
      "Epoch 8: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.8545 - mae: 7.0969 - val_loss: 15.5873 - val_mae: 8.8805\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.2106 - mae: 6.5905\n",
      "Epoch 9: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.2233 - mae: 6.6040 - val_loss: 20.4607 - val_mae: 14.0297\n",
      "Epoch 9: early stopping\n",
      "Random Weights 10\n",
      "Epoch 1/10000\n",
      "44/51 [========================>.....] - ETA: 0s - loss: 13.6297 - mae: 7.2236\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 13.6361 - mae: 7.2257 - val_loss: 26.5790 - val_mae: 20.0470\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.7377 - mae: 7.3618\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.7104 - mae: 7.3366 - val_loss: 13.2540 - val_mae: 6.9855\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.4507 - mae: 7.0581\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.4507 - mae: 7.0581 - val_loss: 17.0382 - val_mae: 10.6287\n",
      "Epoch 4/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 13.1206 - mae: 6.8468\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.1535 - mae: 6.8837 - val_loss: 11.1373 - val_mae: 4.9325\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.9606 - mae: 6.9735\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.9599 - mae: 6.9748 - val_loss: 13.8456 - val_mae: 8.1554\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 12.8645 - mae: 7.1628\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.8645 - mae: 7.1628 - val_loss: 12.5164 - val_mae: 6.9179\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.4666 - mae: 6.7466\n",
      "Epoch 7: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.4719 - mae: 6.7522 - val_loss: 15.2384 - val_mae: 9.5380\n",
      "Epoch 8/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 12.6682 - mae: 6.9945\n",
      "Epoch 8: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.6682 - mae: 6.9945 - val_loss: 23.8299 - val_mae: 18.1420\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.1695 - mae: 6.5760\n",
      "Epoch 9: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.1669 - mae: 6.5744 - val_loss: 14.5243 - val_mae: 9.1020\n",
      "Epoch 9: early stopping\n",
      "loaded Weights 11\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 14.4204 - mae: 7.0369\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.4204 - mae: 7.0369 - val_loss: 15.7303 - val_mae: 8.1828\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.6225 - mae: 7.0772\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.6441 - mae: 7.1042 - val_loss: 17.9715 - val_mae: 10.6540\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.1177 - mae: 6.9181\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1218 - mae: 6.9216 - val_loss: 19.7009 - val_mae: 12.3763\n",
      "Epoch 4/10000\n",
      "47/51 [==========================>...] - ETA: 0s - loss: 14.6532 - mae: 7.2234\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.6750 - mae: 7.2389 - val_loss: 21.5950 - val_mae: 14.0095\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.2088 - mae: 7.0026\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1824 - mae: 6.9717 - val_loss: 23.7484 - val_mae: 16.3874\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.3959 - mae: 7.1579\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.4138 - mae: 7.1790 - val_loss: 29.3254 - val_mae: 22.1172\n",
      "Epoch 6: early stopping\n",
      "Random Weights 12\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.0149 - mae: 7.0051\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 13.9626 - mae: 6.9495 - val_loss: 14.3225 - val_mae: 7.2397\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.6136 - mae: 6.7857\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.6139 - mae: 6.7859 - val_loss: 27.5039 - val_mae: 20.6513\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.8313 - mae: 6.9834\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.8615 - mae: 7.0209 - val_loss: 11.2701 - val_mae: 4.6916\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.4677 - mae: 6.8340\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.4677 - mae: 6.8340 - val_loss: 22.0065 - val_mae: 15.2657\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.7261 - mae: 7.0677\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.7276 - mae: 7.0727 - val_loss: 15.6775 - val_mae: 9.1932\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.1450 - mae: 6.7366\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.1503 - mae: 6.7359 - val_loss: 12.4042 - val_mae: 5.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.3501 - mae: 6.8173\n",
      "Epoch 7: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.3420 - mae: 6.8099 - val_loss: 13.6961 - val_mae: 7.2421\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 13.4344 - mae: 7.0789\n",
      "Epoch 8: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.4812 - mae: 7.0942 - val_loss: 26.9917 - val_mae: 20.3382\n",
      "Epoch 8: early stopping\n",
      "loaded Weights 13\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.1926 - mae: 6.7900\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.2283 - mae: 6.7530 - val_loss: 28.0497 - val_mae: 20.2617\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.9642 - mae: 7.1032\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.9683 - mae: 7.1023 - val_loss: 16.2882 - val_mae: 8.4456\n",
      "Epoch 3/10000\n",
      "45/51 [=========================>....] - ETA: 0s - loss: 14.7180 - mae: 6.9647\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 14.7516 - mae: 7.0108 - val_loss: 18.1453 - val_mae: 10.3834\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 14.9682 - mae: 7.2816\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.9682 - mae: 7.2816 - val_loss: 27.4521 - val_mae: 19.9406\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.6305 - mae: 7.2261\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.8289 - mae: 7.3541 - val_loss: 16.8562 - val_mae: 9.0953\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.6742 - mae: 7.2403\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.6599 - mae: 7.2263 - val_loss: 16.8017 - val_mae: 9.4018\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.5747 - mae: 7.2773\n",
      "Epoch 7: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.5695 - mae: 7.2717 - val_loss: 28.3566 - val_mae: 20.9537\n",
      "Epoch 7: early stopping\n",
      "Random Weights 14\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.0183 - mae: 6.9312\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.9173 - mae: 6.8947 - val_loss: 15.6037 - val_mae: 8.7534\n",
      "Epoch 2/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 14.0700 - mae: 7.1417\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.0374 - mae: 7.1003 - val_loss: 25.8144 - val_mae: 18.7948\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 13.6977 - mae: 6.7761\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.8900 - mae: 6.9773 - val_loss: 21.6243 - val_mae: 14.5546\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.6954 - mae: 6.9273\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.6916 - mae: 6.9229 - val_loss: 25.0057 - val_mae: 18.2005\n",
      "Epoch 5/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 13.6286 - mae: 7.0272\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.5136 - mae: 6.9316 - val_loss: 28.1719 - val_mae: 21.5364\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.9788 - mae: 7.5877\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.9738 - mae: 7.5815 - val_loss: 25.2733 - val_mae: 18.6392\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 15\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 15.1172 - mae: 7.4513\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.1075 - mae: 7.4412 - val_loss: 11.1276 - val_mae: 3.3805\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 14.8001 - mae: 6.9734\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.8001 - mae: 6.9734 - val_loss: 29.2474 - val_mae: 21.4203\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.7381 - mae: 6.8122\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.8439 - mae: 6.8946 - val_loss: 35.7289 - val_mae: 27.8013\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 14.2899 - mae: 6.7859\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.2899 - mae: 6.7859 - val_loss: 25.7668 - val_mae: 18.2075\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.2863 - mae: 6.9904\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.2917 - mae: 6.9961 - val_loss: 15.1052 - val_mae: 7.8355\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 14.3618 - mae: 7.1413\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.3618 - mae: 7.1413 - val_loss: 16.2572 - val_mae: 9.3712\n",
      "Epoch 6: early stopping\n",
      "Random Weights 16\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.8125 - mae: 6.9614\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 13.7997 - mae: 6.9453 - val_loss: 15.6674 - val_mae: 8.6664\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.2698 - mae: 7.3203\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.2971 - mae: 7.3505 - val_loss: 25.9540 - val_mae: 19.1552\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.5578 - mae: 6.7870\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.5975 - mae: 6.8226 - val_loss: 15.5843 - val_mae: 8.5900\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.6154 - mae: 6.6153\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.6286 - mae: 6.6279 - val_loss: 20.4707 - val_mae: 13.4468\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.0165 - mae: 7.0520\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.0341 - mae: 7.0777 - val_loss: 19.0711 - val_mae: 12.3867\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.8209 - mae: 7.2625\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.8213 - mae: 7.2647 - val_loss: 12.0632 - val_mae: 5.7662\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.2252 - mae: 7.7905\n",
      "Epoch 7: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1862 - mae: 7.7489 - val_loss: 16.5886 - val_mae: 10.0831\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.8767 - mae: 6.6809\n",
      "Epoch 8: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.8767 - mae: 6.6843 - val_loss: 25.5933 - val_mae: 19.4535\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.0318 - mae: 7.0530\n",
      "Epoch 9: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.0447 - mae: 7.0712 - val_loss: 21.6385 - val_mae: 15.7862\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.4917 - mae: 6.7199\n",
      "Epoch 10: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.4906 - mae: 6.7170 - val_loss: 12.6975 - val_mae: 6.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 12.6061 - mae: 6.7780\n",
      "Epoch 11: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.6155 - mae: 6.7878 - val_loss: 14.7741 - val_mae: 9.0311\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 17\n",
      "Epoch 1/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 15.1229 - mae: 7.4964\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.1265 - mae: 7.3963 - val_loss: 20.3207 - val_mae: 12.1830\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 15.0972 - mae: 6.8657\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.1951 - mae: 6.9835 - val_loss: 11.8504 - val_mae: 3.7287\n",
      "Epoch 3/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 15.3310 - mae: 7.1149\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.1535 - mae: 6.9791 - val_loss: 32.9258 - val_mae: 24.8050\n",
      "Epoch 4/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 14.9230 - mae: 7.0670\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.8907 - mae: 7.0766 - val_loss: 17.8151 - val_mae: 10.2607\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.3232 - mae: 6.8697\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.4247 - mae: 6.9294 - val_loss: 18.5329 - val_mae: 10.8800\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.3050 - mae: 6.7923\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.2955 - mae: 6.8055 - val_loss: 20.7708 - val_mae: 13.3635\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 14.1075 - mae: 6.8592\n",
      "Epoch 7: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1075 - mae: 6.8592 - val_loss: 16.5032 - val_mae: 9.1918\n",
      "Epoch 7: early stopping\n",
      "Random Weights 18\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.0002 - mae: 6.7575\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1414 - mae: 6.9232 - val_loss: 19.6136 - val_mae: 12.5337\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.0971 - mae: 7.3211\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1088 - mae: 7.3335 - val_loss: 10.3372 - val_mae: 3.6686\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 13.9706 - mae: 7.3122\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.9354 - mae: 7.2459 - val_loss: 23.4864 - val_mae: 16.6797\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.2634 - mae: 6.6920\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.2693 - mae: 6.6990 - val_loss: 32.8339 - val_mae: 26.2000\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.2666 - mae: 6.7406\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.2538 - mae: 6.7283 - val_loss: 19.4456 - val_mae: 12.9748\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.1034 - mae: 6.7844\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.1034 - mae: 6.7844 - val_loss: 19.0841 - val_mae: 12.8600\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.0183 - mae: 6.6672\n",
      "Epoch 7: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.0272 - mae: 6.6755 - val_loss: 30.9517 - val_mae: 24.4734\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 19\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 15.0573 - mae: 7.2839\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.0817 - mae: 7.3055 - val_loss: 22.5718 - val_mae: 14.3224\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 15.1952 - mae: 7.2253\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.1952 - mae: 7.2253 - val_loss: 11.7429 - val_mae: 3.8184\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 15.3729 - mae: 7.3425\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.5237 - mae: 7.5107 - val_loss: 12.0781 - val_mae: 4.2838\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 14.7090 - mae: 7.0532\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.7090 - mae: 7.0532 - val_loss: 12.0828 - val_mae: 4.4911\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.5651 - mae: 6.9517\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.5231 - mae: 6.9410 - val_loss: 19.1568 - val_mae: 11.7302\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.2202 - mae: 6.7794\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.2403 - mae: 6.7992 - val_loss: 36.2699 - val_mae: 28.7620\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.5216 - mae: 7.1588\n",
      "Epoch 7: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.5423 - mae: 7.1824 - val_loss: 22.3266 - val_mae: 15.0951\n",
      "Epoch 7: early stopping\n",
      "Random Weights 20\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.8156 - mae: 6.6625\n",
      "Epoch 1: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 13.8306 - mae: 6.6796 - val_loss: 16.5005 - val_mae: 9.4314\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.8686 - mae: 6.9857\n",
      "Epoch 2: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.9007 - mae: 7.0167 - val_loss: 9.6877 - val_mae: 2.6854\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.8174 - mae: 6.8570\n",
      "Epoch 3: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.8174 - mae: 6.8570 - val_loss: 18.5512 - val_mae: 11.6844\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.8716 - mae: 7.0437\n",
      "Epoch 4: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.8568 - mae: 7.0293 - val_loss: 16.7653 - val_mae: 9.9978\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.5333 - mae: 6.8469\n",
      "Epoch 5: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.5252 - mae: 6.8448 - val_loss: 12.6576 - val_mae: 6.1278\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.4273 - mae: 6.9373\n",
      "Epoch 6: val_mae did not improve from 2.49009\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.4598 - mae: 6.9635 - val_loss: 28.4733 - val_mae: 21.6980\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.4968 - mae: 6.8569\n",
      "Epoch 7: val_mae improved from 2.49009 to 2.03203, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.5034 - mae: 6.8640 - val_loss: 8.5762 - val_mae: 2.0320\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.4729 - mae: 6.9786\n",
      "Epoch 8: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.4566 - mae: 6.9665 - val_loss: 13.5482 - val_mae: 7.1944\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.3031 - mae: 7.0422\n",
      "Epoch 9: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.2837 - mae: 7.0260 - val_loss: 13.8221 - val_mae: 7.6568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 12.8214 - mae: 6.6822\n",
      "Epoch 10: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.8340 - mae: 6.6908 - val_loss: 19.2526 - val_mae: 13.1748\n",
      "Epoch 11/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 12.6914 - mae: 6.7728\n",
      "Epoch 11: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.6726 - mae: 6.7741 - val_loss: 26.1650 - val_mae: 20.2763\n",
      "Epoch 12/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 12.7535 - mae: 6.8521\n",
      "Epoch 12: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.6837 - mae: 6.7714 - val_loss: 13.4367 - val_mae: 7.4451\n",
      "Epoch 12: early stopping\n",
      "loaded Weights 21\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 13.0588 - mae: 6.6167\n",
      "Epoch 1: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.9995 - mae: 6.5847 - val_loss: 25.6009 - val_mae: 19.2181\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.1322 - mae: 6.7945\n",
      "Epoch 2: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.1322 - mae: 6.7945 - val_loss: 15.5878 - val_mae: 9.1484\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.0017 - mae: 6.7405\n",
      "Epoch 3: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.0017 - mae: 6.7405 - val_loss: 9.4552 - val_mae: 3.0463\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 13.1488 - mae: 6.8905\n",
      "Epoch 4: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.0151 - mae: 6.7983 - val_loss: 10.3855 - val_mae: 4.2847\n",
      "Epoch 5/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.0837 - mae: 7.0139\n",
      "Epoch 5: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.0837 - mae: 7.0139 - val_loss: 15.1933 - val_mae: 9.2193\n",
      "Epoch 6/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 12.2812 - mae: 6.4764\n",
      "Epoch 6: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.2642 - mae: 6.4572 - val_loss: 25.8378 - val_mae: 19.9440\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.2050 - mae: 7.2627\n",
      "Epoch 7: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.2050 - mae: 7.2627 - val_loss: 23.6008 - val_mae: 17.5969\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 12.6053 - mae: 6.7604\n",
      "Epoch 8: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.5315 - mae: 6.6941 - val_loss: 13.8358 - val_mae: 8.1076\n",
      "Epoch 8: early stopping\n",
      "Random Weights 22\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.7529 - mae: 7.0084\n",
      "Epoch 1: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.7567 - mae: 7.0121 - val_loss: 15.1154 - val_mae: 9.3692\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.4131 - mae: 6.8147\n",
      "Epoch 2: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.4012 - mae: 6.8040 - val_loss: 15.6450 - val_mae: 10.1924\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 11.9808 - mae: 6.6047\n",
      "Epoch 3: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.9808 - mae: 6.6047 - val_loss: 21.5644 - val_mae: 16.1919\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 12.2651 - mae: 6.8317\n",
      "Epoch 4: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.1342 - mae: 6.6668 - val_loss: 28.5296 - val_mae: 22.8838\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.0768 - mae: 6.5464\n",
      "Epoch 5: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.0954 - mae: 6.5649 - val_loss: 21.6735 - val_mae: 16.0870\n",
      "Epoch 6/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 12.4587 - mae: 6.9626\n",
      "Epoch 6: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.3588 - mae: 6.8828 - val_loss: 21.1123 - val_mae: 15.7547\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 23\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.3831 - mae: 6.8597\n",
      "Epoch 1: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.3783 - mae: 6.8557 - val_loss: 17.4685 - val_mae: 11.0205\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.4842 - mae: 6.7538\n",
      "Epoch 2: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.4842 - mae: 6.7538 - val_loss: 22.1217 - val_mae: 15.2571\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.7402 - mae: 7.0887\n",
      "Epoch 3: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.7283 - mae: 7.0778 - val_loss: 22.1631 - val_mae: 15.6613\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.7200 - mae: 7.0155\n",
      "Epoch 4: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.7067 - mae: 7.0017 - val_loss: 31.5707 - val_mae: 24.7702\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 13.3638 - mae: 6.7977\n",
      "Epoch 5: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.3616 - mae: 6.7970 - val_loss: 22.8529 - val_mae: 16.2661\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 12.9218 - mae: 6.5479\n",
      "Epoch 6: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.9218 - mae: 6.5479 - val_loss: 12.5263 - val_mae: 6.3320\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.7904 - mae: 6.6019\n",
      "Epoch 7: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.7988 - mae: 6.6141 - val_loss: 10.8919 - val_mae: 4.8605\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.7999 - mae: 6.8927\n",
      "Epoch 8: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.8033 - mae: 6.8952 - val_loss: 16.8612 - val_mae: 10.8486\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.4364 - mae: 6.5866\n",
      "Epoch 9: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.4231 - mae: 6.5750 - val_loss: 12.0189 - val_mae: 6.4207\n",
      "Epoch 10/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 12.3731 - mae: 6.7386\n",
      "Epoch 10: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.2992 - mae: 6.7051 - val_loss: 15.5207 - val_mae: 10.2365\n",
      "Epoch 11/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.0870 - mae: 6.8761\n",
      "Epoch 11: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.1039 - mae: 6.8908 - val_loss: 20.9567 - val_mae: 15.6983\n",
      "Epoch 12/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.9533 - mae: 6.5075\n",
      "Epoch 12: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.9486 - mae: 6.4984 - val_loss: 21.1349 - val_mae: 15.5588\n",
      "Epoch 12: early stopping\n",
      "Random Weights 24\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.2117 - mae: 6.7020\n",
      "Epoch 1: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 12.2250 - mae: 6.7196 - val_loss: 9.5515 - val_mae: 4.1837\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 11.9477 - mae: 6.4968\n",
      "Epoch 2: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.9489 - mae: 6.4976 - val_loss: 18.4916 - val_mae: 12.9830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.1379 - mae: 6.8262\n",
      "Epoch 3: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.1197 - mae: 6.8081 - val_loss: 12.9269 - val_mae: 7.6439\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 12.4265 - mae: 7.0714\n",
      "Epoch 4: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.4893 - mae: 7.1197 - val_loss: 21.6731 - val_mae: 16.2038\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 11.9610 - mae: 6.6912\n",
      "Epoch 5: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.8896 - mae: 6.6996 - val_loss: 7.0445 - val_mae: 2.2282\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 11.3274 - mae: 6.6032\n",
      "Epoch 6: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.3228 - mae: 6.6295 - val_loss: 10.4458 - val_mae: 5.8328\n",
      "Epoch 7/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 11.3406 - mae: 6.7622\n",
      "Epoch 7: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.2641 - mae: 6.7058 - val_loss: 19.1970 - val_mae: 14.7284\n",
      "Epoch 8/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 11.0110 - mae: 6.5993\n",
      "Epoch 8: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.0217 - mae: 6.5801 - val_loss: 12.3295 - val_mae: 7.7911\n",
      "Epoch 9/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 11.2543 - mae: 6.7055\n",
      "Epoch 9: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.1692 - mae: 6.6129 - val_loss: 8.5057 - val_mae: 3.9259\n",
      "Epoch 10/10000\n",
      "38/51 [=====================>........] - ETA: 0s - loss: 11.4171 - mae: 6.7319\n",
      "Epoch 10: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.2705 - mae: 6.5966 - val_loss: 9.0979 - val_mae: 4.5156\n",
      "Epoch 10: early stopping\n",
      "loaded Weights 25\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 13.4390 - mae: 6.7563\n",
      "Epoch 1: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.5013 - mae: 6.7753 - val_loss: 18.8414 - val_mae: 11.8270\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 14.1337 - mae: 6.9538\n",
      "Epoch 2: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1337 - mae: 6.9538 - val_loss: 26.8474 - val_mae: 19.5445\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 14.3384 - mae: 7.0107\n",
      "Epoch 3: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.3410 - mae: 7.0391 - val_loss: 19.6890 - val_mae: 12.5096\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 14.1132 - mae: 6.8080\n",
      "Epoch 4: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1132 - mae: 6.8080 - val_loss: 20.2056 - val_mae: 12.8886\n",
      "Epoch 5/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.7028 - mae: 6.6005\n",
      "Epoch 5: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.7028 - mae: 6.6005 - val_loss: 11.2127 - val_mae: 4.2168\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 13.9239 - mae: 7.0829\n",
      "Epoch 6: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.8775 - mae: 7.0628 - val_loss: 18.9843 - val_mae: 12.2788\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.3488 - mae: 6.6672\n",
      "Epoch 7: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.3437 - mae: 6.6631 - val_loss: 18.7371 - val_mae: 12.2044\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.1310 - mae: 6.7363\n",
      "Epoch 8: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.1271 - mae: 6.7324 - val_loss: 21.8551 - val_mae: 15.4447\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.2037 - mae: 6.7785\n",
      "Epoch 9: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.2094 - mae: 6.7848 - val_loss: 21.5552 - val_mae: 15.2013\n",
      "Epoch 10/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 13.2794 - mae: 7.0354\n",
      "Epoch 10: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.2794 - mae: 7.0354 - val_loss: 19.5892 - val_mae: 13.4575\n",
      "Epoch 10: early stopping\n",
      "Random Weights 26\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.6147 - mae: 6.5831\n",
      "Epoch 1: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.6300 - mae: 6.5970 - val_loss: 27.3778 - val_mae: 21.3079\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.3936 - mae: 6.5578\n",
      "Epoch 2: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.3937 - mae: 6.5622 - val_loss: 25.2300 - val_mae: 19.6050\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 12.3391 - mae: 6.6554\n",
      "Epoch 3: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.3391 - mae: 6.6554 - val_loss: 14.9103 - val_mae: 9.2172\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.7749 - mae: 6.8986\n",
      "Epoch 4: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.7682 - mae: 6.8914 - val_loss: 14.1677 - val_mae: 8.2320\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.5604 - mae: 6.7836\n",
      "Epoch 5: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.5406 - mae: 6.7677 - val_loss: 12.9075 - val_mae: 7.2952\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.6207 - mae: 7.0425\n",
      "Epoch 6: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.5954 - mae: 7.0208 - val_loss: 10.3297 - val_mae: 4.9647\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.9937 - mae: 6.8037\n",
      "Epoch 7: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.0006 - mae: 6.8133 - val_loss: 20.3016 - val_mae: 15.2275\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.5381 - mae: 6.5599\n",
      "Epoch 8: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.5631 - mae: 6.5814 - val_loss: 18.2989 - val_mae: 13.1936\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 11.3634 - mae: 6.4684\n",
      "Epoch 9: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.3642 - mae: 6.4714 - val_loss: 14.7550 - val_mae: 10.1805\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.4730 - mae: 6.8125\n",
      "Epoch 10: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.4509 - mae: 6.7882 - val_loss: 12.7129 - val_mae: 8.0057\n",
      "Epoch 11/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.2609 - mae: 6.6013\n",
      "Epoch 11: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.2669 - mae: 6.6032 - val_loss: 7.0137 - val_mae: 2.1949\n",
      "Epoch 12/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 11.3248 - mae: 6.6484\n",
      "Epoch 12: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.3328 - mae: 6.6584 - val_loss: 15.3298 - val_mae: 10.8841\n",
      "Epoch 13/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.8096 - mae: 6.4786\n",
      "Epoch 13: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.8134 - mae: 6.4834 - val_loss: 9.1284 - val_mae: 4.7904\n",
      "Epoch 14/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - ETA: 0s - loss: 11.3165 - mae: 6.8429\n",
      "Epoch 14: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.3165 - mae: 6.8429 - val_loss: 13.5473 - val_mae: 9.0161\n",
      "Epoch 15/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 11.1666 - mae: 6.8015\n",
      "Epoch 15: val_mae did not improve from 2.03203\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.1042 - mae: 6.7709 - val_loss: 9.8899 - val_mae: 5.6485\n",
      "Epoch 16/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 10.4668 - mae: 6.1682\n",
      "Epoch 16: val_mae improved from 2.03203 to 1.69070, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.5061 - mae: 6.2195 - val_loss: 5.8563 - val_mae: 1.6907\n",
      "Epoch 17/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.3774 - mae: 6.3217\n",
      "Epoch 17: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.3345 - mae: 6.2813 - val_loss: 8.2803 - val_mae: 4.2913\n",
      "Epoch 18/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.3821 - mae: 6.4841\n",
      "Epoch 18: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.4089 - mae: 6.5207 - val_loss: 7.2252 - val_mae: 3.4353\n",
      "Epoch 19/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.4844 - mae: 6.6475\n",
      "Epoch 19: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.4538 - mae: 6.6306 - val_loss: 10.1217 - val_mae: 6.3248\n",
      "Epoch 20/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.7333 - mae: 6.7572\n",
      "Epoch 20: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.6475 - mae: 6.6575 - val_loss: 6.7586 - val_mae: 2.8125\n",
      "Epoch 21/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.4402 - mae: 6.6386\n",
      "Epoch 21: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.4438 - mae: 6.6450 - val_loss: 5.4234 - val_mae: 1.7363\n",
      "Epoch 21: early stopping\n",
      "loaded Weights 27\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.3625 - mae: 6.3146\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.3790 - mae: 6.3354 - val_loss: 5.9684 - val_mae: 2.0508\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 10.7843 - mae: 6.5345\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.7843 - mae: 6.5345 - val_loss: 10.7396 - val_mae: 6.3976\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.5419 - mae: 6.2447\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.6150 - mae: 6.3727 - val_loss: 6.1858 - val_mae: 2.0346\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.4826 - mae: 6.3783\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.4667 - mae: 6.3926 - val_loss: 9.9197 - val_mae: 5.9695\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 10.2109 - mae: 6.2782\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.2069 - mae: 6.2743 - val_loss: 15.8307 - val_mae: 11.9040\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 10.5702 - mae: 6.4887\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.5702 - mae: 6.4887 - val_loss: 21.5555 - val_mae: 17.4745\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.3826 - mae: 6.4488\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.3960 - mae: 6.4660 - val_loss: 13.3834 - val_mae: 9.5599\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.9196 - mae: 6.2845\n",
      "Epoch 8: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9049 - mae: 6.2703 - val_loss: 9.1403 - val_mae: 5.5919\n",
      "Epoch 8: early stopping\n",
      "Random Weights 28\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.1932 - mae: 6.5504\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.2037 - mae: 6.5574 - val_loss: 12.7887 - val_mae: 9.0133\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.9424 - mae: 6.3065 \n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9627 - mae: 6.3298 - val_loss: 8.2144 - val_mae: 4.7007\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.8991 - mae: 6.4588\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.8999 - mae: 6.4607 - val_loss: 6.7254 - val_mae: 3.4361\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.7397 - mae: 6.3831\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7338 - mae: 6.3774 - val_loss: 13.2333 - val_mae: 9.8637\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.8502 - mae: 6.4169\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.8512 - mae: 6.4193 - val_loss: 12.6021 - val_mae: 9.1925\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.8359 - mae: 6.2764\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.8219 - mae: 6.2640 - val_loss: 8.8339 - val_mae: 5.3503\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.9526 - mae: 6.4583 \n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9457 - mae: 6.4513 - val_loss: 9.7074 - val_mae: 6.2135\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6424 - mae: 6.2571\n",
      "Epoch 8: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6478 - mae: 6.2668 - val_loss: 13.3715 - val_mae: 10.1331\n",
      "Epoch 8: early stopping\n",
      "loaded Weights 29\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.8115 - mae: 6.4680\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 10.8553 - mae: 6.5059 - val_loss: 14.4073 - val_mae: 9.8217\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.0559 - mae: 6.4209\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.0389 - mae: 6.4021 - val_loss: 14.8932 - val_mae: 10.1621\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.3340 - mae: 6.4812\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.3438 - mae: 6.4873 - val_loss: 13.8699 - val_mae: 8.8788\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.4202 - mae: 6.4638\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.4118 - mae: 6.4608 - val_loss: 8.9583 - val_mae: 4.1909\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.1195 - mae: 6.4685\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.1234 - mae: 6.4809 - val_loss: 15.7481 - val_mae: 11.3688\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 10.8156 - mae: 6.4868\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.8069 - mae: 6.4784 - val_loss: 12.5679 - val_mae: 8.2815\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.7540 - mae: 6.5200\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.7387 - mae: 6.5036 - val_loss: 9.3494 - val_mae: 5.0984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 10.7623 - mae: 6.6116\n",
      "Epoch 8: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.7519 - mae: 6.6034 - val_loss: 6.7377 - val_mae: 2.8897\n",
      "Epoch 9/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.5409 - mae: 6.5448\n",
      "Epoch 9: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.5091 - mae: 6.5137 - val_loss: 6.9235 - val_mae: 3.0587\n",
      "Epoch 10/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.2932 - mae: 6.5590\n",
      "Epoch 10: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.2106 - mae: 6.5125 - val_loss: 10.0311 - val_mae: 6.4782\n",
      "Epoch 11/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.6753 - mae: 6.1870\n",
      "Epoch 11: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5809 - mae: 6.1030 - val_loss: 11.5342 - val_mae: 8.0957\n",
      "Epoch 12/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 10.0466 - mae: 6.5479\n",
      "Epoch 12: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9649 - mae: 6.4759 - val_loss: 16.0597 - val_mae: 12.5369\n",
      "Epoch 13/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.9691 - mae: 6.3751 \n",
      "Epoch 13: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9712 - mae: 6.3777 - val_loss: 12.9443 - val_mae: 9.3862\n",
      "Epoch 13: early stopping\n",
      "Random Weights 30\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.5142 - mae: 6.8598\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.4381 - mae: 6.7771 - val_loss: 10.8976 - val_mae: 7.2745\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.5400 - mae: 6.1547\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4747 - mae: 6.1470 - val_loss: 7.5886 - val_mae: 4.4707\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.4967 - mae: 6.4546\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4491 - mae: 6.4433 - val_loss: 9.3434 - val_mae: 6.4736\n",
      "Epoch 4/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 9.7184 - mae: 6.7754\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7230 - mae: 6.7353 - val_loss: 9.5739 - val_mae: 6.4632\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.2782 - mae: 6.3405\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2468 - mae: 6.3028 - val_loss: 8.3798 - val_mae: 5.4385\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.1214 - mae: 6.1714\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1278 - mae: 6.1786 - val_loss: 9.8197 - val_mae: 6.9893\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.0948 - mae: 6.3702\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.0965 - mae: 6.3723 - val_loss: 8.4509 - val_mae: 5.7658\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 31\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 11.2525 - mae: 6.5815\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.2576 - mae: 6.5799 - val_loss: 7.5409 - val_mae: 1.9312\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 12.5879 - mae: 6.6891\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.5879 - mae: 6.6891 - val_loss: 7.6724 - val_mae: 1.9264\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 12.4638 - mae: 6.7369\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.4638 - mae: 6.7369 - val_loss: 17.5904 - val_mae: 11.9837\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 12.0900 - mae: 6.7984\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.0900 - mae: 6.7984 - val_loss: 12.5744 - val_mae: 7.4950\n",
      "Epoch 5/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 11.9057 - mae: 6.8615\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.9057 - mae: 6.8615 - val_loss: 17.9590 - val_mae: 13.0471\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.4512 - mae: 6.7997\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.4454 - mae: 6.8040 - val_loss: 7.6015 - val_mae: 3.3329\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.7260 - mae: 6.5705\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.6872 - mae: 6.5351 - val_loss: 11.3465 - val_mae: 7.3175\n",
      "Epoch 7: early stopping\n",
      "Random Weights 32\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.9577 - mae: 6.0783\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9484 - mae: 6.0695 - val_loss: 15.8097 - val_mae: 11.9954\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.3279 - mae: 6.4406\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.3187 - mae: 6.4322 - val_loss: 9.3386 - val_mae: 5.4577\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.3786 - mae: 6.5566\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.3609 - mae: 6.5403 - val_loss: 6.7481 - val_mae: 3.0267\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.8324 - mae: 6.2367\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.8233 - mae: 6.2306 - val_loss: 14.2675 - val_mae: 10.7907\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.7646 - mae: 6.2546\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7745 - mae: 6.2649 - val_loss: 5.7405 - val_mae: 2.2773\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.8634 - mae: 6.4648\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.8653 - mae: 6.4673 - val_loss: 9.3692 - val_mae: 5.9985\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.5555 - mae: 6.3482\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5915 - mae: 6.3905 - val_loss: 9.0139 - val_mae: 6.0097\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.2757 - mae: 6.2069\n",
      "Epoch 8: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2726 - mae: 6.2054 - val_loss: 11.5560 - val_mae: 8.5494\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.4933 - mae: 6.4015\n",
      "Epoch 9: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5022 - mae: 6.4126 - val_loss: 11.0300 - val_mae: 7.9928\n",
      "Epoch 10/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.5239 - mae: 6.5375\n",
      "Epoch 10: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5135 - mae: 6.5276 - val_loss: 8.0008 - val_mae: 5.0693\n",
      "Epoch 10: early stopping\n",
      "loaded Weights 33\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 11.6232 - mae: 6.6080\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 11.6346 - mae: 6.6118 - val_loss: 8.1831 - val_mae: 2.1262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.2069 - mae: 6.7291\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.2181 - mae: 6.7407 - val_loss: 11.7028 - val_mae: 5.3005\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 12.7520 - mae: 6.7737\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.6065 - mae: 6.7083 - val_loss: 11.9096 - val_mae: 6.3161\n",
      "Epoch 4/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 12.1907 - mae: 6.6389\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.1084 - mae: 6.6017 - val_loss: 11.8848 - val_mae: 6.6898\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 11.3300 - mae: 6.3664\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.2503 - mae: 6.3627 - val_loss: 6.6955 - val_mae: 2.1481\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 11.0683 - mae: 6.5952\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.0683 - mae: 6.5952 - val_loss: 7.9366 - val_mae: 3.7171\n",
      "Epoch 6: early stopping\n",
      "Random Weights 34\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 10.8199 - mae: 6.4388\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.8199 - mae: 6.4388 - val_loss: 7.3570 - val_mae: 3.0395\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.9636 - mae: 6.6715\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.8711 - mae: 6.5961 - val_loss: 10.9510 - val_mae: 6.7663\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.2625 - mae: 6.1793\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.2594 - mae: 6.2362 - val_loss: 8.5057 - val_mae: 4.7434\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.1756 - mae: 6.4378\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.2321 - mae: 6.4978 - val_loss: 7.3971 - val_mae: 3.6769\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.2078 - mae: 6.4979\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.1428 - mae: 6.4496 - val_loss: 10.7254 - val_mae: 7.0699\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.2346 - mae: 6.4585\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.2654 - mae: 6.4933 - val_loss: 5.4953 - val_mae: 1.8472\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 10.0122 - mae: 6.4197\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.0122 - mae: 6.4197 - val_loss: 9.7043 - val_mae: 6.1626\n",
      "Epoch 8/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.8667 - mae: 6.3617\n",
      "Epoch 8: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.8667 - mae: 6.3617 - val_loss: 7.9001 - val_mae: 4.4157\n",
      "Epoch 9/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 10.0907 - mae: 6.5356\n",
      "Epoch 9: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.0437 - mae: 6.5330 - val_loss: 9.7730 - val_mae: 6.5273\n",
      "Epoch 10/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.4546 - mae: 6.3936\n",
      "Epoch 10: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4546 - mae: 6.3936 - val_loss: 4.9529 - val_mae: 1.9410\n",
      "Epoch 11/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.8239 - mae: 6.6527\n",
      "Epoch 11: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.8522 - mae: 6.6734 - val_loss: 17.6289 - val_mae: 14.3029\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 35\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 11.6148 - mae: 6.6619\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.9717 - mae: 6.7673 - val_loss: 13.9332 - val_mae: 7.7017\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 13.4657 - mae: 6.7149\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.3953 - mae: 6.5918 - val_loss: 16.6094 - val_mae: 9.7805\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.4005 - mae: 6.4594\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.3958 - mae: 6.4558 - val_loss: 20.1571 - val_mae: 13.3719\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 12.5633 - mae: 6.3799\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.5633 - mae: 6.3799 - val_loss: 15.6599 - val_mae: 9.6902\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 12.5314 - mae: 6.6975\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.5254 - mae: 6.6931 - val_loss: 16.9400 - val_mae: 11.2615\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.1734 - mae: 6.6568\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.1687 - mae: 6.6627 - val_loss: 11.0686 - val_mae: 5.9887\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.3008 - mae: 6.5358\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.2987 - mae: 6.5398 - val_loss: 10.4109 - val_mae: 5.8884\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.9628 - mae: 6.5439\n",
      "Epoch 8: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.9602 - mae: 6.5441 - val_loss: 10.6744 - val_mae: 6.3464\n",
      "Epoch 9/10000\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 10.4495 - mae: 6.4029\n",
      "Epoch 9: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 7ms/step - loss: 10.3658 - mae: 6.3488 - val_loss: 7.3621 - val_mae: 3.5016\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.3162 - mae: 6.4247\n",
      "Epoch 10: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.3408 - mae: 6.4517 - val_loss: 6.7990 - val_mae: 3.0253\n",
      "Epoch 11/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.2043 - mae: 6.4473\n",
      "Epoch 11: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.1731 - mae: 6.4142 - val_loss: 8.2357 - val_mae: 4.3960\n",
      "Epoch 12/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.8764 - mae: 6.2638\n",
      "Epoch 12: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9106 - mae: 6.3027 - val_loss: 11.5767 - val_mae: 8.0937\n",
      "Epoch 13/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 10.3633 - mae: 6.7345\n",
      "Epoch 13: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.3823 - mae: 6.7537 - val_loss: 5.4162 - val_mae: 1.8104\n",
      "Epoch 14/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6918 - mae: 6.2159\n",
      "Epoch 14: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6712 - mae: 6.1991 - val_loss: 6.0336 - val_mae: 2.7032\n",
      "Epoch 15/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6773 - mae: 6.5003\n",
      "Epoch 15: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6834 - mae: 6.5063 - val_loss: 10.6860 - val_mae: 7.4840\n",
      "Epoch 16/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6527 - mae: 6.4996\n",
      "Epoch 16: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6695 - mae: 6.5229 - val_loss: 9.6438 - val_mae: 6.7195\n",
      "Epoch 17/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6746 - mae: 6.6943\n",
      "Epoch 17: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6742 - mae: 6.6935 - val_loss: 5.4553 - val_mae: 2.4152\n",
      "Epoch 18/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.6766 - mae: 6.5444\n",
      "Epoch 18: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6614 - mae: 6.5878 - val_loss: 6.7256 - val_mae: 3.9189\n",
      "Epoch 18: early stopping\n",
      "Random Weights 36\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.0683 - mae: 6.4762\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9647 - mae: 6.4050 - val_loss: 9.4716 - val_mae: 7.0385\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.6323 - mae: 6.2468\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6218 - mae: 6.2371 - val_loss: 7.6014 - val_mae: 5.2788\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.9635 - mae: 6.4506\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8913 - mae: 6.3767 - val_loss: 7.3756 - val_mae: 4.8960\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.7063 - mae: 6.1304\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7063 - mae: 6.1304 - val_loss: 5.8766 - val_mae: 3.3353\n",
      "Epoch 5/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 8.7195 - mae: 6.2438\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6950 - mae: 6.2285 - val_loss: 5.9176 - val_mae: 3.4992\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.5583 - mae: 6.2464\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6975 - mae: 6.4177 - val_loss: 5.0857 - val_mae: 2.9733\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.3751 - mae: 6.1768\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3751 - mae: 6.1768 - val_loss: 4.6773 - val_mae: 2.5126\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.6932 - mae: 6.4745\n",
      "Epoch 8: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6542 - mae: 6.4633 - val_loss: 6.1630 - val_mae: 4.1113\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.4452 - mae: 6.3823\n",
      "Epoch 9: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4525 - mae: 6.3900 - val_loss: 7.5678 - val_mae: 5.5396\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.2322 - mae: 6.2474\n",
      "Epoch 10: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2643 - mae: 6.2794 - val_loss: 4.4499 - val_mae: 2.4619\n",
      "Epoch 11/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.4226 - mae: 6.3575\n",
      "Epoch 11: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4226 - mae: 6.3575 - val_loss: 3.8943 - val_mae: 1.7759\n",
      "Epoch 12/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.3558 - mae: 6.2504\n",
      "Epoch 12: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3558 - mae: 6.2504 - val_loss: 6.2481 - val_mae: 4.1776\n",
      "Epoch 13/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.3556 - mae: 6.2885\n",
      "Epoch 13: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3556 - mae: 6.2885 - val_loss: 6.2493 - val_mae: 4.3581\n",
      "Epoch 14/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.0157 - mae: 6.1958\n",
      "Epoch 14: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0286 - mae: 6.2087 - val_loss: 5.6626 - val_mae: 3.8368\n",
      "Epoch 15/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4083 - mae: 6.3677\n",
      "Epoch 15: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4145 - mae: 6.3700 - val_loss: 7.6519 - val_mae: 5.4683\n",
      "Epoch 16/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.2472 - mae: 6.2676\n",
      "Epoch 16: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2299 - mae: 6.2507 - val_loss: 6.8774 - val_mae: 4.9445\n",
      "Epoch 16: early stopping\n",
      "loaded Weights 37\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.3005 - mae: 6.4986\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.3433 - mae: 6.4822 - val_loss: 15.7310 - val_mae: 7.6914\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 15.5705 - mae: 6.8086\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.5765 - mae: 6.8058 - val_loss: 25.1930 - val_mae: 16.0989\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 15.3124 - mae: 6.4927\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.2967 - mae: 6.4812 - val_loss: 20.2069 - val_mae: 11.5172\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 14.8075 - mae: 6.6528\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.7914 - mae: 6.6533 - val_loss: 24.7331 - val_mae: 17.2084\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.0506 - mae: 6.7740\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.0430 - mae: 6.7679 - val_loss: 16.3500 - val_mae: 9.3267\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 13.1395 - mae: 6.5920\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.1463 - mae: 6.6016 - val_loss: 23.5466 - val_mae: 17.4016\n",
      "Epoch 6: early stopping\n",
      "Random Weights 38\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.4037 - mae: 6.6144\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 12.3979 - mae: 6.6188 - val_loss: 21.8634 - val_mae: 16.4147\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 12.0938 - mae: 6.6306\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.0770 - mae: 6.6199 - val_loss: 23.7990 - val_mae: 18.5627\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 11.5058 - mae: 6.5711\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.5069 - mae: 6.5845 - val_loss: 19.8534 - val_mae: 15.3398\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.7446 - mae: 6.4847\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.7438 - mae: 6.4886 - val_loss: 9.4811 - val_mae: 5.3878\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.6125 - mae: 6.5074\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.5644 - mae: 6.4637 - val_loss: 13.9038 - val_mae: 9.8769\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.2599 - mae: 6.3794\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.2708 - mae: 6.3964 - val_loss: 9.2305 - val_mae: 5.6161\n",
      "Epoch 7/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - ETA: 0s - loss: 9.7871 - mae: 6.2517\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7871 - mae: 6.2517 - val_loss: 9.7853 - val_mae: 6.1924\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.9128 - mae: 6.4805 \n",
      "Epoch 8: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7760 - mae: 6.3944 - val_loss: 9.9977 - val_mae: 6.8492\n",
      "Epoch 9/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.4008 - mae: 6.2806\n",
      "Epoch 9: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4008 - mae: 6.2806 - val_loss: 4.6503 - val_mae: 1.7006\n",
      "Epoch 10/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.2852 - mae: 6.3075\n",
      "Epoch 10: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.3268 - mae: 6.3629 - val_loss: 4.6745 - val_mae: 1.7819\n",
      "Epoch 11/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.2998 - mae: 6.3720\n",
      "Epoch 11: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2923 - mae: 6.3655 - val_loss: 8.9502 - val_mae: 6.1686\n",
      "Epoch 12/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.1019 - mae: 6.3058\n",
      "Epoch 12: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1019 - mae: 6.3058 - val_loss: 8.7339 - val_mae: 6.0231\n",
      "Epoch 13/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.1416 - mae: 6.3765\n",
      "Epoch 13: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1851 - mae: 6.3895 - val_loss: 6.5226 - val_mae: 3.6274\n",
      "Epoch 14/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.3600 - mae: 6.4215\n",
      "Epoch 14: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.3659 - mae: 6.4309 - val_loss: 11.8308 - val_mae: 8.9846\n",
      "Epoch 14: early stopping\n",
      "loaded Weights 39\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 12.0859 - mae: 6.5961\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.0859 - mae: 6.5961 - val_loss: 18.3712 - val_mae: 10.9756\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 15.4606 - mae: 7.3787\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 15.5173 - mae: 7.3705 - val_loss: 14.7713 - val_mae: 6.6111\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 14.1785 - mae: 6.5914\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 14.1664 - mae: 6.5828 - val_loss: 11.3766 - val_mae: 4.2353\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 13.1789 - mae: 6.5558\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 13.2414 - mae: 6.7314 - val_loss: 8.2910 - val_mae: 2.1958\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 12.1934 - mae: 6.4949\n",
      "Epoch 5: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 12.0766 - mae: 6.4523 - val_loss: 7.0921 - val_mae: 1.7856\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 11.4388 - mae: 6.3942\n",
      "Epoch 6: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.4399 - mae: 6.3960 - val_loss: 12.2578 - val_mae: 7.3317\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 11.1934 - mae: 6.4636\n",
      "Epoch 7: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 11.1342 - mae: 6.5092 - val_loss: 9.0836 - val_mae: 4.8680\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.4474 - mae: 6.2727\n",
      "Epoch 8: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.4279 - mae: 6.2573 - val_loss: 9.4918 - val_mae: 5.4440\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.4958 - mae: 6.5222\n",
      "Epoch 9: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.4670 - mae: 6.4948 - val_loss: 10.7133 - val_mae: 6.7657\n",
      "Epoch 10/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 10.2939 - mae: 6.3620\n",
      "Epoch 10: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.2805 - mae: 6.3494 - val_loss: 13.2795 - val_mae: 9.4593\n",
      "Epoch 10: early stopping\n",
      "Random Weights 40\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.1951 - mae: 6.4053\n",
      "Epoch 1: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 10.2078 - mae: 6.4252 - val_loss: 13.1580 - val_mae: 9.6157\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.8092 - mae: 6.2105\n",
      "Epoch 2: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.8565 - mae: 6.2570 - val_loss: 6.1032 - val_mae: 2.5613\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.7781 - mae: 6.2895\n",
      "Epoch 3: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7683 - mae: 6.2839 - val_loss: 6.0372 - val_mae: 2.6531\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.8624 - mae: 6.2692\n",
      "Epoch 4: val_mae did not improve from 1.69070\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9144 - mae: 6.3209 - val_loss: 5.7385 - val_mae: 2.1244\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.4988 - mae: 6.1687\n",
      "Epoch 5: val_mae improved from 1.69070 to 1.68141, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5034 - mae: 6.1793 - val_loss: 4.7727 - val_mae: 1.6814\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.3887 - mae: 6.3760\n",
      "Epoch 6: val_mae did not improve from 1.68141\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.3893 - mae: 6.3797 - val_loss: 6.1033 - val_mae: 3.1972\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.7579 - mae: 6.6380\n",
      "Epoch 7: val_mae did not improve from 1.68141\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7545 - mae: 6.6353 - val_loss: 6.9422 - val_mae: 3.8089\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.2346 - mae: 6.2456\n",
      "Epoch 8: val_mae did not improve from 1.68141\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2031 - mae: 6.2152 - val_loss: 4.7047 - val_mae: 1.7324\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.2008 - mae: 6.3531\n",
      "Epoch 9: val_mae improved from 1.68141 to 1.63979, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1986 - mae: 6.3539 - val_loss: 4.3990 - val_mae: 1.6398\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.7647 - mae: 6.1943\n",
      "Epoch 10: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7740 - mae: 6.2064 - val_loss: 5.0085 - val_mae: 2.5667\n",
      "Epoch 11/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.7410 - mae: 6.2828\n",
      "Epoch 11: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7420 - mae: 6.2833 - val_loss: 6.4294 - val_mae: 3.8829\n",
      "Epoch 12/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.1876 - mae: 6.4483\n",
      "Epoch 12: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2018 - mae: 6.4608 - val_loss: 6.3626 - val_mae: 3.5714\n",
      "Epoch 13/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.8624 - mae: 6.2720\n",
      "Epoch 13: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8503 - mae: 6.2660 - val_loss: 4.6416 - val_mae: 2.2647\n",
      "Epoch 14/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/51 [============================>.] - ETA: 0s - loss: 8.4737 - mae: 6.1038\n",
      "Epoch 14: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5048 - mae: 6.1347 - val_loss: 4.4731 - val_mae: 2.0971\n",
      "Epoch 14: early stopping\n",
      "loaded Weights 41\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.1288 - mae: 6.3059\n",
      "Epoch 1: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.0229 - mae: 6.2352 - val_loss: 4.3753 - val_mae: 1.8068\n",
      "Epoch 2/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 9.1503 - mae: 6.5842\n",
      "Epoch 2: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1327 - mae: 6.5724 - val_loss: 4.5129 - val_mae: 1.9354\n",
      "Epoch 3/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 8.8478 - mae: 6.2150\n",
      "Epoch 3: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8764 - mae: 6.2733 - val_loss: 5.0257 - val_mae: 2.4940\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.9008 - mae: 6.2907\n",
      "Epoch 4: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9008 - mae: 6.2907 - val_loss: 7.9686 - val_mae: 5.4252\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.0982 - mae: 6.5258\n",
      "Epoch 5: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9932 - mae: 6.4602 - val_loss: 5.7465 - val_mae: 3.3625\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.6016 - mae: 6.2291\n",
      "Epoch 6: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6016 - mae: 6.2291 - val_loss: 5.6635 - val_mae: 3.3156\n",
      "Epoch 6: early stopping\n",
      "Random Weights 42\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.5965 - mae: 6.1756\n",
      "Epoch 1: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5965 - mae: 6.1756 - val_loss: 6.3433 - val_mae: 3.9181\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.6613 - mae: 6.3054\n",
      "Epoch 2: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6613 - mae: 6.3054 - val_loss: 7.3252 - val_mae: 5.0838\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.3976 - mae: 6.1744\n",
      "Epoch 3: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3976 - mae: 6.1744 - val_loss: 12.1177 - val_mae: 9.7621\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.6697 - mae: 6.2391\n",
      "Epoch 4: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6240 - mae: 6.2081 - val_loss: 5.9699 - val_mae: 3.7235\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.1045 - mae: 6.0517\n",
      "Epoch 5: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1400 - mae: 6.1020 - val_loss: 11.9413 - val_mae: 9.9723\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.3249 - mae: 6.2753\n",
      "Epoch 6: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3249 - mae: 6.2753 - val_loss: 16.7292 - val_mae: 14.4708\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.3500 - mae: 6.1101\n",
      "Epoch 7: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3339 - mae: 6.1007 - val_loss: 9.0637 - val_mae: 7.0789\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.1248 - mae: 6.1238\n",
      "Epoch 8: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1550 - mae: 6.1543 - val_loss: 10.7789 - val_mae: 8.7673\n",
      "Epoch 9/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.3673 - mae: 6.4184\n",
      "Epoch 9: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3283 - mae: 6.3639 - val_loss: 11.4043 - val_mae: 9.4357\n",
      "Epoch 9: early stopping\n",
      "loaded Weights 43\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.2145 - mae: 6.3235\n",
      "Epoch 1: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2360 - mae: 6.3421 - val_loss: 7.6707 - val_mae: 4.3747\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.5037 - mae: 6.2420\n",
      "Epoch 2: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5225 - mae: 6.2769 - val_loss: 7.0678 - val_mae: 3.8624\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.5467 - mae: 6.2542\n",
      "Epoch 3: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5229 - mae: 6.2614 - val_loss: 7.7584 - val_mae: 4.6366\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.4422 - mae: 6.4151\n",
      "Epoch 4: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4346 - mae: 6.4078 - val_loss: 5.9515 - val_mae: 2.9810\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.3494 - mae: 6.3207\n",
      "Epoch 5: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.3478 - mae: 6.3201 - val_loss: 14.2628 - val_mae: 11.2624\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.4287 - mae: 6.3617\n",
      "Epoch 6: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4420 - mae: 6.3723 - val_loss: 7.3758 - val_mae: 4.2408\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.5262 - mae: 6.4617\n",
      "Epoch 7: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5322 - mae: 6.4726 - val_loss: 9.6312 - val_mae: 6.7562\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.0783 - mae: 6.3884\n",
      "Epoch 8: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.0375 - mae: 6.3522 - val_loss: 5.9275 - val_mae: 3.4407\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.8255 - mae: 6.4109\n",
      "Epoch 9: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8148 - mae: 6.3988 - val_loss: 11.3664 - val_mae: 8.8958\n",
      "Epoch 9: early stopping\n",
      "Random Weights 44\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.8214 - mae: 6.4243\n",
      "Epoch 1: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8214 - mae: 6.4243 - val_loss: 4.1161 - val_mae: 1.8118\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.6665 - mae: 6.4099\n",
      "Epoch 2: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6759 - mae: 6.4213 - val_loss: 10.5773 - val_mae: 8.3537\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.6985 - mae: 6.2400\n",
      "Epoch 3: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6706 - mae: 6.2142 - val_loss: 4.5596 - val_mae: 2.2141\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4148 - mae: 6.2310\n",
      "Epoch 4: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4443 - mae: 6.2636 - val_loss: 7.2135 - val_mae: 5.1163\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4435 - mae: 6.3170\n",
      "Epoch 5: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4861 - mae: 6.3558 - val_loss: 8.7363 - val_mae: 6.4511\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4830 - mae: 6.1960\n",
      "Epoch 6: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4701 - mae: 6.1881 - val_loss: 5.0731 - val_mae: 2.9720\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 45\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - ETA: 0s - loss: 9.5918 - mae: 6.3219\n",
      "Epoch 1: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5918 - mae: 6.3219 - val_loss: 5.5765 - val_mae: 2.0351\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.8049 - mae: 6.3381\n",
      "Epoch 2: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6901 - mae: 6.2508 - val_loss: 6.6757 - val_mae: 3.2401\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.5883 - mae: 6.2861\n",
      "Epoch 3: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6270 - mae: 6.3502 - val_loss: 5.2613 - val_mae: 2.0638\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.7606 - mae: 6.5108\n",
      "Epoch 4: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7310 - mae: 6.4931 - val_loss: 5.8825 - val_mae: 2.7636\n",
      "Epoch 5/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 9.3642 - mae: 6.3049\n",
      "Epoch 5: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2988 - mae: 6.2535 - val_loss: 7.4695 - val_mae: 4.4666\n",
      "Epoch 6/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 9.5742 - mae: 6.4689\n",
      "Epoch 6: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5666 - mae: 6.4736 - val_loss: 4.7673 - val_mae: 1.7362\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.4388 - mae: 6.4913\n",
      "Epoch 7: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2577 - mae: 6.3851 - val_loss: 6.1293 - val_mae: 3.6587\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.0747 - mae: 6.6089\n",
      "Epoch 8: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.0018 - mae: 6.4977 - val_loss: 6.1157 - val_mae: 3.5333\n",
      "Epoch 9/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.0035 - mae: 6.4002\n",
      "Epoch 9: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.0035 - mae: 6.4002 - val_loss: 4.6919 - val_mae: 2.1943\n",
      "Epoch 10/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.5816 - mae: 6.3051\n",
      "Epoch 10: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5930 - mae: 6.3182 - val_loss: 5.4267 - val_mae: 3.3983\n",
      "Epoch 11/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.1094 - mae: 6.1418\n",
      "Epoch 11: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1403 - mae: 6.1957 - val_loss: 3.7992 - val_mae: 1.9847\n",
      "Epoch 11: early stopping\n",
      "Random Weights 46\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.2358 - mae: 6.2970\n",
      "Epoch 1: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2358 - mae: 6.2970 - val_loss: 4.0390 - val_mae: 1.9284\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4237 - mae: 6.3004\n",
      "Epoch 2: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4577 - mae: 6.3384 - val_loss: 3.6835 - val_mae: 1.7095\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.0564 - mae: 6.1726\n",
      "Epoch 3: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0564 - mae: 6.1726 - val_loss: 3.5372 - val_mae: 1.6683\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.0087 - mae: 6.2250\n",
      "Epoch 4: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0240 - mae: 6.2401 - val_loss: 3.5954 - val_mae: 1.8121\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.1658 - mae: 6.4219\n",
      "Epoch 5: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1700 - mae: 6.4273 - val_loss: 3.3425 - val_mae: 1.7698\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8392 - mae: 6.2017\n",
      "Epoch 6: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8346 - mae: 6.1982 - val_loss: 3.6253 - val_mae: 2.0086\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.3521 - mae: 6.3807\n",
      "Epoch 7: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3516 - mae: 6.3785 - val_loss: 3.9747 - val_mae: 1.7847\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.1213 - mae: 6.2786\n",
      "Epoch 8: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1282 - mae: 6.2869 - val_loss: 4.1009 - val_mae: 2.3177\n",
      "Epoch 8: early stopping\n",
      "loaded Weights 47\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6400 - mae: 6.2832\n",
      "Epoch 1: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6491 - mae: 6.2740 - val_loss: 9.1527 - val_mae: 5.0770\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 10.4155 - mae: 6.2305\n",
      "Epoch 2: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.4103 - mae: 6.2238 - val_loss: 13.1693 - val_mae: 8.7804\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.4965 - mae: 6.3360\n",
      "Epoch 3: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.5199 - mae: 6.3638 - val_loss: 9.5791 - val_mae: 5.6554\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 10.1000 - mae: 6.3147\n",
      "Epoch 4: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.1002 - mae: 6.3165 - val_loss: 5.8401 - val_mae: 2.3064\n",
      "Epoch 5/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.7222 - mae: 6.3786\n",
      "Epoch 5: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7222 - mae: 6.3786 - val_loss: 5.7321 - val_mae: 2.6556\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.2636 - mae: 6.3989\n",
      "Epoch 6: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2701 - mae: 6.4064 - val_loss: 7.0132 - val_mae: 4.3004\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.8532 - mae: 6.2319\n",
      "Epoch 7: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8484 - mae: 6.2302 - val_loss: 5.9890 - val_mae: 3.4747\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.6694 - mae: 6.2787\n",
      "Epoch 8: val_mae did not improve from 1.63979\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6769 - mae: 6.2857 - val_loss: 4.9307 - val_mae: 2.5713\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4600 - mae: 6.2142\n",
      "Epoch 9: val_mae improved from 1.63979 to 1.63503, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4667 - mae: 6.2208 - val_loss: 3.9066 - val_mae: 1.6350\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.7199 - mae: 6.3753\n",
      "Epoch 10: val_mae did not improve from 1.63503\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6876 - mae: 6.3467 - val_loss: 5.3855 - val_mae: 3.1501\n",
      "Epoch 11/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.4049 - mae: 6.2209\n",
      "Epoch 11: val_mae did not improve from 1.63503\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4049 - mae: 6.2209 - val_loss: 5.7295 - val_mae: 3.5959\n",
      "Epoch 12/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 8.2381 - mae: 6.1805\n",
      "Epoch 12: val_mae did not improve from 1.63503\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2377 - mae: 6.1843 - val_loss: 3.7799 - val_mae: 1.8682\n",
      "Epoch 13/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 8.1969 - mae: 6.2962\n",
      "Epoch 13: val_mae did not improve from 1.63503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1914 - mae: 6.2929 - val_loss: 3.6925 - val_mae: 1.8154\n",
      "Epoch 14/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.2344 - mae: 6.2904\n",
      "Epoch 14: val_mae improved from 1.63503 to 1.61936, saving model to best_weights.h5\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2344 - mae: 6.2904 - val_loss: 3.6797 - val_mae: 1.6194\n",
      "Epoch 15/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.3801 - mae: 6.2471\n",
      "Epoch 15: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4179 - mae: 6.2951 - val_loss: 3.6483 - val_mae: 1.6362\n",
      "Epoch 16/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.2188 - mae: 6.2745\n",
      "Epoch 16: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1990 - mae: 6.2569 - val_loss: 4.7657 - val_mae: 2.8443\n",
      "Epoch 17/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.2760 - mae: 6.2133\n",
      "Epoch 17: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3461 - mae: 6.2752 - val_loss: 4.1904 - val_mae: 2.0592\n",
      "Epoch 18/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.8916 - mae: 6.3883\n",
      "Epoch 18: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8118 - mae: 6.3372 - val_loss: 4.1775 - val_mae: 1.9386\n",
      "Epoch 19/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.2122 - mae: 6.3677\n",
      "Epoch 19: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1958 - mae: 6.4011 - val_loss: 3.2960 - val_mae: 1.6874\n",
      "Epoch 19: early stopping\n",
      "Random Weights 48\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.9685 - mae: 6.3574\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9572 - mae: 6.3614 - val_loss: 3.2096 - val_mae: 1.7131\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.5348 - mae: 6.0481\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5910 - mae: 6.1315 - val_loss: 3.0425 - val_mae: 1.6691\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.6693 - mae: 6.1489\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7082 - mae: 6.1470 - val_loss: 3.4920 - val_mae: 1.7894\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.7382 - mae: 6.1270\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7174 - mae: 6.1546 - val_loss: 3.1160 - val_mae: 1.7490\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.5570 - mae: 6.0857\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5659 - mae: 6.0947 - val_loss: 3.2087 - val_mae: 1.7875\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.6757 - mae: 6.3113\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6687 - mae: 6.3040 - val_loss: 3.6905 - val_mae: 2.2636\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.7222 - mae: 6.2258\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7344 - mae: 6.2513 - val_loss: 5.0812 - val_mae: 3.6760\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 49\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.2356 - mae: 6.2210\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2304 - mae: 6.2137 - val_loss: 5.0090 - val_mae: 2.7388\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.5621 - mae: 6.1460\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5627 - mae: 6.1477 - val_loss: 8.9082 - val_mae: 6.5866\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.4400 - mae: 6.0173\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4341 - mae: 6.0125 - val_loss: 6.0065 - val_mae: 3.7101\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.2963 - mae: 6.3198\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2963 - mae: 6.3198 - val_loss: 6.4143 - val_mae: 4.5884\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.0198 - mae: 6.1869\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0211 - mae: 6.1867 - val_loss: 4.0767 - val_mae: 2.0488\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.1730 - mae: 6.0624\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1649 - mae: 6.0549 - val_loss: 5.8203 - val_mae: 3.8355\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.1295 - mae: 6.2802\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1229 - mae: 6.2769 - val_loss: 5.9969 - val_mae: 4.2573\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.0106 - mae: 6.2545\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0101 - mae: 6.2547 - val_loss: 5.9763 - val_mae: 4.2996\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.8455 - mae: 6.2315\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8361 - mae: 6.2213 - val_loss: 8.1350 - val_mae: 6.4022\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.0152 - mae: 6.2182\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0406 - mae: 6.2459 - val_loss: 5.7444 - val_mae: 4.0844\n",
      "Epoch 10: early stopping\n",
      "Random Weights 50\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8859 - mae: 6.2631\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8444 - mae: 6.2230 - val_loss: 9.0757 - val_mae: 7.5359\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.9586 - mae: 6.3981\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9524 - mae: 6.3918 - val_loss: 13.9089 - val_mae: 12.3027\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.1822 - mae: 6.2408\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1822 - mae: 6.2408 - val_loss: 10.3907 - val_mae: 8.5351\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.1680 - mae: 6.2657\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1831 - mae: 6.2792 - val_loss: 12.4150 - val_mae: 10.4419\n",
      "Epoch 5/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 8.0426 - mae: 6.1828\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0228 - mae: 6.1749 - val_loss: 6.0224 - val_mae: 4.4214\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8567 - mae: 6.2706\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8266 - mae: 6.2431 - val_loss: 5.9294 - val_mae: 4.5064\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.6135 - mae: 6.1877\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6909 - mae: 6.2544 - val_loss: 11.9196 - val_mae: 10.4504\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.5688 - mae: 6.0960\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5600 - mae: 6.0867 - val_loss: 3.9476 - val_mae: 2.3800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.8217 - mae: 5.9497\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7997 - mae: 5.9279 - val_loss: 14.6555 - val_mae: 12.8237\n",
      "Epoch 10/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.9991 - mae: 6.2899\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0492 - mae: 6.3466 - val_loss: 5.6549 - val_mae: 4.0382\n",
      "Epoch 11/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.7664 - mae: 6.0459\n",
      "Epoch 11: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9316 - mae: 6.2069 - val_loss: 4.6788 - val_mae: 2.9541\n",
      "Epoch 12/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 7.7001 - mae: 5.9807\n",
      "Epoch 12: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6894 - mae: 6.0180 - val_loss: 12.3158 - val_mae: 10.8505\n",
      "Epoch 13/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.7031 - mae: 6.2084\n",
      "Epoch 13: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7031 - mae: 6.2084 - val_loss: 6.2156 - val_mae: 4.6875\n",
      "Epoch 13: early stopping\n",
      "loaded Weights 51\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.6968 - mae: 6.3237\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7190 - mae: 6.2616 - val_loss: 4.4026 - val_mae: 1.6294\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.9412 - mae: 6.2316\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9404 - mae: 6.2324 - val_loss: 4.6293 - val_mae: 2.1453\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.8064 - mae: 6.3388\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7695 - mae: 6.3165 - val_loss: 4.6656 - val_mae: 2.2011\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.8712 - mae: 6.3122\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8705 - mae: 6.3116 - val_loss: 4.7203 - val_mae: 2.2338\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.4849 - mae: 6.1873\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3973 - mae: 6.1313 - val_loss: 7.6821 - val_mae: 5.5922\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.2870 - mae: 6.2048\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3554 - mae: 6.2757 - val_loss: 4.2482 - val_mae: 2.2366\n",
      "Epoch 6: early stopping\n",
      "Random Weights 52\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.3657 - mae: 6.3118\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3657 - mae: 6.3118 - val_loss: 6.0718 - val_mae: 3.9027\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.4304 - mae: 6.2767\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4275 - mae: 6.2741 - val_loss: 6.1907 - val_mae: 4.1330\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.1438 - mae: 6.1043\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0417 - mae: 6.0038 - val_loss: 7.1266 - val_mae: 5.1539\n",
      "Epoch 4/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.1351 - mae: 6.2412\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1084 - mae: 6.2180 - val_loss: 4.5681 - val_mae: 2.7058\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.1466 - mae: 6.2622\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1477 - mae: 6.2644 - val_loss: 4.5539 - val_mae: 2.8052\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.9204 - mae: 6.2603\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9259 - mae: 6.2668 - val_loss: 4.7285 - val_mae: 3.2284\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.7265 - mae: 6.1676\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7276 - mae: 6.1685 - val_loss: 3.3443 - val_mae: 1.7372\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.8699 - mae: 6.2880\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8906 - mae: 6.3079 - val_loss: 3.4315 - val_mae: 1.7618\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.0710 - mae: 6.3307\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0799 - mae: 6.3334 - val_loss: 3.6722 - val_mae: 1.7007\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8772 - mae: 6.0259\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8616 - mae: 6.0158 - val_loss: 3.3636 - val_mae: 1.7503\n",
      "Epoch 11/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7508 - mae: 6.1417\n",
      "Epoch 11: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7723 - mae: 6.1652 - val_loss: 3.3078 - val_mae: 1.7434\n",
      "Epoch 12/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.6935 - mae: 6.2368\n",
      "Epoch 12: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6995 - mae: 6.2452 - val_loss: 3.3816 - val_mae: 2.0160\n",
      "Epoch 13/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7492 - mae: 6.4150\n",
      "Epoch 13: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7410 - mae: 6.4070 - val_loss: 3.5298 - val_mae: 2.1714\n",
      "Epoch 14/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7484 - mae: 6.2454\n",
      "Epoch 14: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7758 - mae: 6.2724 - val_loss: 3.3119 - val_mae: 1.8371\n",
      "Epoch 14: early stopping\n",
      "loaded Weights 53\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.5241 - mae: 6.1714\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.5530 - mae: 6.1937 - val_loss: 4.4052 - val_mae: 1.7727\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6081 - mae: 6.3288\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6137 - mae: 6.3353 - val_loss: 6.3019 - val_mae: 3.0704\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.4474 - mae: 6.2074\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4513 - mae: 6.2247 - val_loss: 4.9425 - val_mae: 2.1630\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.6768 - mae: 6.1577\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6885 - mae: 6.1707 - val_loss: 4.1765 - val_mae: 1.8970\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.3221 - mae: 6.2233\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3204 - mae: 6.2267 - val_loss: 3.6150 - val_mae: 1.6991\n",
      "Epoch 6/10000\n",
      "46/51 [==========================>...] - ETA: 0s - loss: 8.3265 - mae: 6.4283\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3167 - mae: 6.4379 - val_loss: 3.3980 - val_mae: 1.7352\n",
      "Epoch 7/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8540 - mae: 6.0893\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9063 - mae: 6.1380 - val_loss: 5.7939 - val_mae: 3.8869\n",
      "Epoch 8/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.2054 - mae: 6.2846\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2054 - mae: 6.2846 - val_loss: 3.4868 - val_mae: 1.7106\n",
      "Epoch 9/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.9371 - mae: 6.2574\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0482 - mae: 6.3731 - val_loss: 3.6923 - val_mae: 2.0132\n",
      "Epoch 10/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.9280 - mae: 6.3029\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9280 - mae: 6.3029 - val_loss: 3.8412 - val_mae: 2.2909\n",
      "Epoch 10: early stopping\n",
      "Random Weights 54\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.7799 - mae: 6.2424\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7799 - mae: 6.2424 - val_loss: 3.1530 - val_mae: 1.6361\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.8774 - mae: 6.2321\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8774 - mae: 6.2321 - val_loss: 3.5115 - val_mae: 1.9536\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.7845 - mae: 6.2271\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7530 - mae: 6.1997 - val_loss: 7.4017 - val_mae: 5.7947\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7752 - mae: 6.0647\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7570 - mae: 6.0484 - val_loss: 4.6333 - val_mae: 2.9772\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.6449 - mae: 6.0735\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7555 - mae: 6.2040 - val_loss: 5.6087 - val_mae: 4.1550\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.6753 - mae: 6.1537\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6537 - mae: 6.1589 - val_loss: 3.1131 - val_mae: 1.8003\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 55\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.0599 - mae: 6.3699\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.0599 - mae: 6.3699 - val_loss: 4.9125 - val_mae: 1.8326\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.1349 - mae: 5.9966\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2361 - mae: 6.0888 - val_loss: 5.1048 - val_mae: 1.9471\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.6414 - mae: 6.3513\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6427 - mae: 6.3563 - val_loss: 5.5791 - val_mae: 2.8235\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.4669 - mae: 6.0098\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4669 - mae: 6.0098 - val_loss: 4.5894 - val_mae: 2.4809\n",
      "Epoch 5/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.2960 - mae: 6.1706\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2960 - mae: 6.1706 - val_loss: 6.1072 - val_mae: 3.8514\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.2519 - mae: 6.2480\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2560 - mae: 6.2534 - val_loss: 9.1646 - val_mae: 7.3005\n",
      "Epoch 6: early stopping\n",
      "Random Weights 56\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.0138 - mae: 6.1716\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0138 - mae: 6.1716 - val_loss: 3.5363 - val_mae: 1.7122\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.0635 - mae: 6.2737\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0717 - mae: 6.2789 - val_loss: 7.4192 - val_mae: 5.5441\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.9716 - mae: 6.1948\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9652 - mae: 6.1924 - val_loss: 3.7004 - val_mae: 2.0314\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.9663 - mae: 6.1591\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9512 - mae: 6.1452 - val_loss: 6.2897 - val_mae: 4.5327\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8979 - mae: 6.2373\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8811 - mae: 6.2215 - val_loss: 9.2093 - val_mae: 7.5832\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.9853 - mae: 6.3184\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9684 - mae: 6.3016 - val_loss: 3.2357 - val_mae: 1.6248\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.9859 - mae: 6.2943\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9654 - mae: 6.2735 - val_loss: 3.3941 - val_mae: 1.6474\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.1034 - mae: 6.3580\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1016 - mae: 6.3567 - val_loss: 6.6156 - val_mae: 4.9268\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.0203 - mae: 6.3035\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9875 - mae: 6.2714 - val_loss: 7.3969 - val_mae: 5.7330\n",
      "Epoch 10/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.7818 - mae: 6.1984\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7855 - mae: 6.2025 - val_loss: 4.8158 - val_mae: 3.3386\n",
      "Epoch 11/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.9095 - mae: 6.4729\n",
      "Epoch 11: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9414 - mae: 6.5052 - val_loss: 4.6585 - val_mae: 3.1853\n",
      "Epoch 11: early stopping\n",
      "loaded Weights 57\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.6280 - mae: 6.2103\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.6402 - mae: 6.2079 - val_loss: 4.6290 - val_mae: 1.6374\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.5258 - mae: 6.2420\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5155 - mae: 6.2298 - val_loss: 6.4961 - val_mae: 3.1028\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6534 - mae: 6.3478\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6749 - mae: 6.3671 - val_loss: 5.5094 - val_mae: 2.0894\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.3360 - mae: 6.3726\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.3241 - mae: 6.3726 - val_loss: 5.5142 - val_mae: 3.0337\n",
      "Epoch 5/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/51 [===========================>..] - ETA: 0s - loss: 8.7645 - mae: 6.3100\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7712 - mae: 6.3168 - val_loss: 4.7604 - val_mae: 2.2755\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.4902 - mae: 6.1719\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5521 - mae: 6.2450 - val_loss: 4.2120 - val_mae: 2.0258\n",
      "Epoch 6: early stopping\n",
      "Random Weights 58\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.3910 - mae: 6.3405\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3391 - mae: 6.3170 - val_loss: 3.6497 - val_mae: 1.7640\n",
      "Epoch 2/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 8.1399 - mae: 6.3481\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1214 - mae: 6.3348 - val_loss: 3.7973 - val_mae: 2.0924\n",
      "Epoch 3/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 7.9332 - mae: 6.2642\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8990 - mae: 6.2061 - val_loss: 3.6287 - val_mae: 1.7657\n",
      "Epoch 4/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 8.4050 - mae: 6.3573\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3808 - mae: 6.3345 - val_loss: 3.8634 - val_mae: 1.8774\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.0831 - mae: 6.1815\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0638 - mae: 6.1858 - val_loss: 3.4695 - val_mae: 1.6751\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.6947 - mae: 6.0389\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6907 - mae: 6.0355 - val_loss: 4.0265 - val_mae: 2.4580\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.9612 - mae: 6.3196\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8588 - mae: 6.2491 - val_loss: 3.2409 - val_mae: 1.7153\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.7379 - mae: 6.2956\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6619 - mae: 6.2336 - val_loss: 3.3283 - val_mae: 1.9729\n",
      "Epoch 9/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.5961 - mae: 6.0968\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7021 - mae: 6.1733 - val_loss: 3.5153 - val_mae: 1.9014\n",
      "Epoch 10/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.8787 - mae: 6.2652\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8723 - mae: 6.2598 - val_loss: 3.2123 - val_mae: 1.7193\n",
      "Epoch 10: early stopping\n",
      "loaded Weights 59\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.9897 - mae: 6.2602\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1587 - mae: 6.3011 - val_loss: 5.1923 - val_mae: 2.1338\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.9202 - mae: 6.2179\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9310 - mae: 6.2384 - val_loss: 3.9774 - val_mae: 1.6480\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.8052 - mae: 6.3472\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7902 - mae: 6.3307 - val_loss: 4.3699 - val_mae: 1.6758\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.1819 - mae: 6.1795\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1732 - mae: 6.1719 - val_loss: 4.5887 - val_mae: 1.7756\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.0648 - mae: 6.4719\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.0176 - mae: 6.4293 - val_loss: 4.9779 - val_mae: 2.5546\n",
      "Epoch 6/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 8.3176 - mae: 6.1437\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3038 - mae: 6.1348 - val_loss: 4.9162 - val_mae: 2.8769\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4529 - mae: 6.5234\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4369 - mae: 6.5122 - val_loss: 3.4947 - val_mae: 1.7051\n",
      "Epoch 7: early stopping\n",
      "Random Weights 60\n",
      "Epoch 1/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 7.8189 - mae: 6.0183\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 7.8292 - mae: 6.0316 - val_loss: 3.3895 - val_mae: 1.6896\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.9523 - mae: 6.3838\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9583 - mae: 6.3893 - val_loss: 3.4518 - val_mae: 1.8010\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8268 - mae: 6.2932\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7921 - mae: 6.2616 - val_loss: 4.1735 - val_mae: 2.7941\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.5833 - mae: 6.1606\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5735 - mae: 6.1519 - val_loss: 3.1117 - val_mae: 1.7189\n",
      "Epoch 5/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.5537 - mae: 6.0674\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5537 - mae: 6.0674 - val_loss: 3.5289 - val_mae: 1.9738\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7643 - mae: 6.1743\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7813 - mae: 6.1921 - val_loss: 3.2930 - val_mae: 1.7044\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 61\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.8713 - mae: 6.2500\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8804 - mae: 6.2443 - val_loss: 4.8375 - val_mae: 1.6455\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.7754 - mae: 6.3808\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7727 - mae: 6.3745 - val_loss: 6.7920 - val_mae: 3.2579\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.7638 - mae: 6.4102\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7281 - mae: 6.3810 - val_loss: 5.0963 - val_mae: 1.9763\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.2993 - mae: 6.3576\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2914 - mae: 6.3566 - val_loss: 4.3994 - val_mae: 1.7626\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.8029 - mae: 6.3576\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7904 - mae: 6.3492 - val_loss: 4.7419 - val_mae: 2.4279\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.2629 - mae: 6.0666\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2698 - mae: 6.0772 - val_loss: 3.7346 - val_mae: 1.6974\n",
      "Epoch 6: early stopping\n",
      "Random Weights 62\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/51 [============================>.] - ETA: 0s - loss: 8.4118 - mae: 6.4660\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4119 - mae: 6.4666 - val_loss: 3.5609 - val_mae: 1.6924\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.0651 - mae: 6.1332\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0651 - mae: 6.1332 - val_loss: 4.5404 - val_mae: 2.6129\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.0610 - mae: 6.1997\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0586 - mae: 6.2257 - val_loss: 4.4903 - val_mae: 2.7287\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.9565 - mae: 6.2158\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9374 - mae: 6.1981 - val_loss: 3.5005 - val_mae: 1.9704\n",
      "Epoch 5/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.5887 - mae: 6.0835\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5887 - mae: 6.0835 - val_loss: 3.6120 - val_mae: 2.0420\n",
      "Epoch 6/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 8.1557 - mae: 6.5311\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1669 - mae: 6.5422 - val_loss: 3.4994 - val_mae: 1.8714\n",
      "Epoch 6: early stopping\n",
      "loaded Weights 63\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.9989 - mae: 6.4270\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9989 - mae: 6.4270 - val_loss: 4.5189 - val_mae: 1.6770\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.4038 - mae: 6.5140\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4109 - mae: 6.5209 - val_loss: 6.3378 - val_mae: 3.4376\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.9291 - mae: 6.1726\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9099 - mae: 6.2047 - val_loss: 4.1355 - val_mae: 1.6313\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.6369 - mae: 6.1667\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6478 - mae: 6.1777 - val_loss: 4.0416 - val_mae: 1.6230\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.5344 - mae: 6.1591\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5114 - mae: 6.1373 - val_loss: 6.3108 - val_mae: 4.0948\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.2579 - mae: 6.1742\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2579 - mae: 6.1742 - val_loss: 3.8600 - val_mae: 1.8602\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.4279 - mae: 6.2840\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4249 - mae: 6.2823 - val_loss: 6.1553 - val_mae: 4.1961\n",
      "Epoch 8/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.3607 - mae: 6.4040\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3607 - mae: 6.4040 - val_loss: 6.0647 - val_mae: 4.2402\n",
      "Epoch 9/10000\n",
      "38/51 [=====================>........] - ETA: 0s - loss: 7.9379 - mae: 6.1375\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8904 - mae: 6.1012 - val_loss: 3.6531 - val_mae: 1.7854\n",
      "Epoch 9: early stopping\n",
      "Random Weights 64\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.0246 - mae: 6.1986\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0246 - mae: 6.1986 - val_loss: 6.1921 - val_mae: 4.2559\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.9606 - mae: 6.2433\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9606 - mae: 6.2433 - val_loss: 5.8319 - val_mae: 4.2892\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7586 - mae: 6.2210\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7309 - mae: 6.1938 - val_loss: 5.1059 - val_mae: 3.5922\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.6912 - mae: 6.1206\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7026 - mae: 6.1337 - val_loss: 10.0968 - val_mae: 8.5531\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.9341 - mae: 6.3217\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9396 - mae: 6.3269 - val_loss: 7.3100 - val_mae: 5.6841\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7455 - mae: 6.1347\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7443 - mae: 6.1338 - val_loss: 5.4328 - val_mae: 3.8288\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8254 - mae: 6.2175\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8015 - mae: 6.1962 - val_loss: 3.7379 - val_mae: 2.2298\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.5446 - mae: 6.0887\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5463 - mae: 6.0936 - val_loss: 4.4269 - val_mae: 3.0735\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.4876 - mae: 6.1480\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.4952 - mae: 6.1556 - val_loss: 8.0962 - val_mae: 6.7461\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.6106 - mae: 6.2602\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5936 - mae: 6.2429 - val_loss: 5.9639 - val_mae: 4.5740\n",
      "Epoch 11/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.6341 - mae: 6.2468\n",
      "Epoch 11: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6538 - mae: 6.2658 - val_loss: 9.5039 - val_mae: 8.0817\n",
      "Epoch 12/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8148 - mae: 6.3227\n",
      "Epoch 12: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8056 - mae: 6.3131 - val_loss: 9.0256 - val_mae: 7.5266\n",
      "Epoch 12: early stopping\n",
      "loaded Weights 65\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.5577 - mae: 6.0335\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.6043 - mae: 6.0640 - val_loss: 8.0225 - val_mae: 4.9068\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6028 - mae: 6.4299\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5975 - mae: 6.4281 - val_loss: 4.8708 - val_mae: 1.8254\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.6748 - mae: 6.4799\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6688 - mae: 6.4685 - val_loss: 7.2641 - val_mae: 3.8388\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 10.1828 - mae: 6.6287\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.1751 - mae: 6.6186 - val_loss: 6.1155 - val_mae: 2.2782\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.5547 - mae: 6.1974\n",
      "Epoch 5: val_mae did not improve from 1.61936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5664 - mae: 6.2234 - val_loss: 10.5658 - val_mae: 7.7132\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.8030 - mae: 6.2820\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8046 - mae: 6.2933 - val_loss: 3.7870 - val_mae: 1.6511\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.4314 - mae: 6.3874\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2096 - mae: 6.2211 - val_loss: 3.4815 - val_mae: 1.7033\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.0418 - mae: 6.1765\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9600 - mae: 6.0717 - val_loss: 3.6302 - val_mae: 1.6849\n",
      "Epoch 9/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.1920 - mae: 6.2772\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1757 - mae: 6.2739 - val_loss: 3.8854 - val_mae: 1.9913\n",
      "Epoch 10/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.0790 - mae: 6.2074\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0790 - mae: 6.2074 - val_loss: 7.3822 - val_mae: 5.5903\n",
      "Epoch 11/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.1061 - mae: 6.3472\n",
      "Epoch 11: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9470 - mae: 6.2049 - val_loss: 5.2357 - val_mae: 3.5174\n",
      "Epoch 11: early stopping\n",
      "Random Weights 66\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.9387 - mae: 6.2957\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9342 - mae: 6.2912 - val_loss: 5.6807 - val_mae: 4.0424\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.5005 - mae: 5.8855\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.4940 - mae: 5.8801 - val_loss: 3.6324 - val_mae: 2.1623\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.7231 - mae: 6.2366\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8215 - mae: 6.3479 - val_loss: 5.2608 - val_mae: 3.8757\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.5356 - mae: 6.1046\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5430 - mae: 6.1119 - val_loss: 6.3831 - val_mae: 4.9530\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.5285 - mae: 6.0842\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5491 - mae: 6.0823 - val_loss: 3.6589 - val_mae: 2.1599\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.4648 - mae: 6.0713\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.4703 - mae: 6.0775 - val_loss: 5.2796 - val_mae: 3.8734\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.8187 - mae: 6.2650\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7524 - mae: 6.2115 - val_loss: 3.1212 - val_mae: 1.6984\n",
      "Epoch 8/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.4548 - mae: 6.1524\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.4548 - mae: 6.1524 - val_loss: 2.9816 - val_mae: 1.7058\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.4855 - mae: 6.1338\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.4943 - mae: 6.1455 - val_loss: 2.9103 - val_mae: 1.6625\n",
      "Epoch 10/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.6973 - mae: 6.3096\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7033 - mae: 6.2973 - val_loss: 3.0596 - val_mae: 1.6611\n",
      "Epoch 11/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.6738 - mae: 6.3628\n",
      "Epoch 11: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6738 - mae: 6.3628 - val_loss: 4.0877 - val_mae: 2.8327\n",
      "Epoch 12/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.5206 - mae: 6.2662\n",
      "Epoch 12: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5026 - mae: 6.2487 - val_loss: 2.8946 - val_mae: 1.6433\n",
      "Epoch 13/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.3645 - mae: 6.1265\n",
      "Epoch 13: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.4160 - mae: 6.1783 - val_loss: 3.3959 - val_mae: 2.1082\n",
      "Epoch 14/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.6480 - mae: 6.2706\n",
      "Epoch 14: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6136 - mae: 6.1965 - val_loss: 3.2535 - val_mae: 1.6299\n",
      "Epoch 15/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.5678 - mae: 6.0157\n",
      "Epoch 15: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5274 - mae: 5.9771 - val_loss: 4.0205 - val_mae: 2.5545\n",
      "Epoch 16/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.1596 - mae: 6.4713\n",
      "Epoch 16: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1725 - mae: 6.4742 - val_loss: 7.1635 - val_mae: 5.1099\n",
      "Epoch 17/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.2212 - mae: 6.2537\n",
      "Epoch 17: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2501 - mae: 6.2830 - val_loss: 4.2848 - val_mae: 2.3242\n",
      "Epoch 18/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.0270 - mae: 6.1501\n",
      "Epoch 18: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0594 - mae: 6.1900 - val_loss: 3.2718 - val_mae: 1.6535\n",
      "Epoch 19/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.6379 - mae: 6.0890\n",
      "Epoch 19: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6237 - mae: 6.0751 - val_loss: 4.1840 - val_mae: 2.7033\n",
      "Epoch 19: early stopping\n",
      "loaded Weights 67\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.0146 - mae: 6.2666\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 9.0008 - mae: 6.2256 - val_loss: 6.1861 - val_mae: 2.3943\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.4276 - mae: 6.4174\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.4116 - mae: 6.4038 - val_loss: 5.9496 - val_mae: 2.0621\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.6101 - mae: 6.1923\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6106 - mae: 6.1949 - val_loss: 6.3173 - val_mae: 3.2100\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.1567 - mae: 6.2358\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1317 - mae: 6.2185 - val_loss: 5.4158 - val_mae: 2.8126\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.7783 - mae: 6.3136\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8067 - mae: 6.3494 - val_loss: 3.8782 - val_mae: 1.6679\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.2262 - mae: 6.1576\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2598 - mae: 6.1961 - val_loss: 4.6851 - val_mae: 2.7993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.9636 - mae: 6.1277\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0790 - mae: 6.2528 - val_loss: 4.4571 - val_mae: 2.7009\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.0528 - mae: 6.3613\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1286 - mae: 6.4584 - val_loss: 3.8063 - val_mae: 2.2353\n",
      "Epoch 9/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.8102 - mae: 6.2560\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7956 - mae: 6.2354 - val_loss: 4.1052 - val_mae: 2.5212\n",
      "Epoch 10/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.5980 - mae: 6.0769\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6443 - mae: 6.1287 - val_loss: 3.5069 - val_mae: 2.0225\n",
      "Epoch 10: early stopping\n",
      "Random Weights 68\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.7856 - mae: 6.1748\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8124 - mae: 6.2294 - val_loss: 3.5660 - val_mae: 2.1161\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.8926 - mae: 6.3646\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8893 - mae: 6.3618 - val_loss: 3.3069 - val_mae: 1.8435\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.6614 - mae: 6.2423\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6603 - mae: 6.2417 - val_loss: 4.9011 - val_mae: 3.5256\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.8758 - mae: 6.3178\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8868 - mae: 6.3290 - val_loss: 3.4172 - val_mae: 1.8970\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.8957 - mae: 6.4456\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8655 - mae: 6.4034 - val_loss: 3.4661 - val_mae: 2.0065\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.5165 - mae: 6.1204\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5497 - mae: 6.1507 - val_loss: 5.9389 - val_mae: 4.4479\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.8131 - mae: 6.2570\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8131 - mae: 6.2570 - val_loss: 5.4099 - val_mae: 3.8119\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 69\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.2386 - mae: 6.3234\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2323 - mae: 6.3093 - val_loss: 6.3257 - val_mae: 3.1010\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.9590 - mae: 6.4531\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9490 - mae: 6.4406 - val_loss: 6.2901 - val_mae: 2.6367\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.9841 - mae: 6.4763 \n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9716 - mae: 6.4668 - val_loss: 5.0151 - val_mae: 1.9096\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.9403 - mae: 6.1578\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9403 - mae: 6.1578 - val_loss: 5.7689 - val_mae: 3.2320\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.7572 - mae: 6.2628\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7682 - mae: 6.2736 - val_loss: 4.4273 - val_mae: 1.9127\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.7013 - mae: 6.3812\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6788 - mae: 6.3592 - val_loss: 5.5322 - val_mae: 3.2962\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.3480 - mae: 6.2065\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3480 - mae: 6.2065 - val_loss: 3.6195 - val_mae: 1.7022\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.2968 - mae: 6.4053\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3161 - mae: 6.4256 - val_loss: 3.4670 - val_mae: 1.7190\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.9119 - mae: 6.2182\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9185 - mae: 6.2252 - val_loss: 3.3738 - val_mae: 1.7367\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.9446 - mae: 6.2252\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9602 - mae: 6.2363 - val_loss: 3.5019 - val_mae: 1.6479\n",
      "Epoch 11/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.0814 - mae: 6.1720\n",
      "Epoch 11: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0813 - mae: 6.1729 - val_loss: 3.4611 - val_mae: 1.7014\n",
      "Epoch 12/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8736 - mae: 6.2199\n",
      "Epoch 12: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8726 - mae: 6.2154 - val_loss: 3.7334 - val_mae: 1.9734\n",
      "Epoch 13/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.9831 - mae: 6.2563\n",
      "Epoch 13: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9889 - mae: 6.2652 - val_loss: 3.4843 - val_mae: 1.8073\n",
      "Epoch 14/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8355 - mae: 6.1616\n",
      "Epoch 14: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8141 - mae: 6.1402 - val_loss: 3.5032 - val_mae: 1.8475\n",
      "Epoch 15/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8982 - mae: 6.3205\n",
      "Epoch 15: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8873 - mae: 6.3123 - val_loss: 3.3870 - val_mae: 1.9342\n",
      "Epoch 15: early stopping\n",
      "Random Weights 70\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8684 - mae: 6.5030\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8790 - mae: 6.5141 - val_loss: 3.0830 - val_mae: 1.7360\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7764 - mae: 6.2958\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7410 - mae: 6.2601 - val_loss: 3.4774 - val_mae: 1.9612\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.8148 - mae: 6.3923\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8074 - mae: 6.3843 - val_loss: 3.4349 - val_mae: 1.9211\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.7818 - mae: 6.1372\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7703 - mae: 6.1265 - val_loss: 3.3086 - val_mae: 1.7818\n",
      "Epoch 5/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 7.7301 - mae: 6.2374\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7737 - mae: 6.2799 - val_loss: 3.1825 - val_mae: 1.7106\n",
      "Epoch 6/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/51 [============================>.] - ETA: 0s - loss: 7.6630 - mae: 6.1744\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6530 - mae: 6.1631 - val_loss: 3.3854 - val_mae: 1.7389\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.7065 - mae: 6.2282\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7065 - mae: 6.2282 - val_loss: 3.1259 - val_mae: 1.7735\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.7878 - mae: 6.4076\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7106 - mae: 6.2953 - val_loss: 3.7941 - val_mae: 2.2890\n",
      "Epoch 9/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.5399 - mae: 6.1737\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5399 - mae: 6.1737 - val_loss: 2.9091 - val_mae: 1.7176\n",
      "Epoch 10/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.4916 - mae: 6.3055\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.4916 - mae: 6.3055 - val_loss: 2.9370 - val_mae: 1.7582\n",
      "Epoch 10: early stopping\n",
      "loaded Weights 71\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.8470 - mae: 6.0840\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8470 - mae: 6.0840 - val_loss: 6.4824 - val_mae: 3.1649\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.5813 - mae: 6.1693\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5690 - mae: 6.1572 - val_loss: 5.7040 - val_mae: 2.3210\n",
      "Epoch 3/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.7931 - mae: 6.4038\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.7931 - mae: 6.4038 - val_loss: 7.6719 - val_mae: 4.3751\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.1146 - mae: 5.9720\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1146 - mae: 5.9720 - val_loss: 9.0795 - val_mae: 5.9362\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.4413 - mae: 6.5166\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4179 - mae: 6.4950 - val_loss: 4.3244 - val_mae: 1.6977\n",
      "Epoch 6/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.5822 - mae: 6.2255\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5585 - mae: 6.2110 - val_loss: 11.1422 - val_mae: 8.7134\n",
      "Epoch 7/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.6759 - mae: 6.1844\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6205 - mae: 6.1958 - val_loss: 5.3435 - val_mae: 3.2742\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.5129 - mae: 6.2810\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4511 - mae: 6.2346 - val_loss: 6.4404 - val_mae: 4.3093\n",
      "Epoch 9/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.2272 - mae: 6.2696\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2467 - mae: 6.2953 - val_loss: 10.0531 - val_mae: 8.2691\n",
      "Epoch 10/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.9594 - mae: 6.0958\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9594 - mae: 6.0958 - val_loss: 7.1823 - val_mae: 5.3431\n",
      "Epoch 10: early stopping\n",
      "Random Weights 72\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7915 - mae: 6.0118\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 7.7814 - mae: 6.0012 - val_loss: 8.4170 - val_mae: 6.6332\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.9373 - mae: 6.2123\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9363 - mae: 6.2128 - val_loss: 5.5691 - val_mae: 4.0516\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.9419 - mae: 6.4659\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8207 - mae: 6.3438 - val_loss: 9.8909 - val_mae: 8.3396\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.7325 - mae: 6.1339\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7482 - mae: 6.1491 - val_loss: 4.8204 - val_mae: 3.1272\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.2827 - mae: 6.5130\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2770 - mae: 6.5094 - val_loss: 8.9096 - val_mae: 7.2132\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.6971 - mae: 6.0848\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7019 - mae: 6.0906 - val_loss: 4.8581 - val_mae: 3.3938\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.8454 - mae: 6.3267\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8298 - mae: 6.3141 - val_loss: 7.6586 - val_mae: 6.2554\n",
      "Epoch 8/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.6085 - mae: 6.1506\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6042 - mae: 6.1447 - val_loss: 7.6807 - val_mae: 6.1792\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.4177 - mae: 6.0289\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.4132 - mae: 6.0251 - val_loss: 3.1167 - val_mae: 1.8094\n",
      "Epoch 10/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.4264 - mae: 6.1369\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.3793 - mae: 6.0909 - val_loss: 7.2337 - val_mae: 5.9871\n",
      "Epoch 11/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.5547 - mae: 6.1361\n",
      "Epoch 11: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5239 - mae: 6.1051 - val_loss: 9.0394 - val_mae: 7.6026\n",
      "Epoch 12/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.5089 - mae: 6.1145\n",
      "Epoch 12: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5219 - mae: 6.1298 - val_loss: 3.4028 - val_mae: 2.0937\n",
      "Epoch 13/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.5455 - mae: 6.1399\n",
      "Epoch 13: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5184 - mae: 6.1085 - val_loss: 7.7377 - val_mae: 6.1646\n",
      "Epoch 14/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7132 - mae: 6.1241\n",
      "Epoch 14: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7180 - mae: 6.1343 - val_loss: 7.8239 - val_mae: 6.4304\n",
      "Epoch 14: early stopping\n",
      "loaded Weights 73\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.4645 - mae: 6.4913\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 9.4753 - mae: 6.4686 - val_loss: 8.0808 - val_mae: 3.8679\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.9676 - mae: 6.1601 \n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9489 - mae: 6.1500 - val_loss: 8.1911 - val_mae: 4.7141\n",
      "Epoch 3/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 9.2581 - mae: 6.0376\n",
      "Epoch 3: val_mae did not improve from 1.61936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2953 - mae: 6.0921 - val_loss: 4.9029 - val_mae: 2.0303\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.9630 - mae: 6.1965\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9715 - mae: 6.2057 - val_loss: 5.4163 - val_mae: 2.7502\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.8296 - mae: 6.0315\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8467 - mae: 6.0810 - val_loss: 7.4519 - val_mae: 4.8826\n",
      "Epoch 6/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.8477 - mae: 6.5408\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8477 - mae: 6.5408 - val_loss: 4.3443 - val_mae: 2.3180\n",
      "Epoch 7/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.2954 - mae: 6.1704\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2954 - mae: 6.1704 - val_loss: 7.8351 - val_mae: 5.6171\n",
      "Epoch 8/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.5448 - mae: 6.4090\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5191 - mae: 6.4558 - val_loss: 3.4481 - val_mae: 1.7311\n",
      "Epoch 9/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.1873 - mae: 6.4007\n",
      "Epoch 9: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2029 - mae: 6.4158 - val_loss: 6.9422 - val_mae: 5.0842\n",
      "Epoch 10/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.2143 - mae: 6.4105\n",
      "Epoch 10: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2143 - mae: 6.4105 - val_loss: 4.9764 - val_mae: 3.3427\n",
      "Epoch 11/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.6655 - mae: 6.0659\n",
      "Epoch 11: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7683 - mae: 6.1504 - val_loss: 7.3873 - val_mae: 5.6247\n",
      "Epoch 12/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.9135 - mae: 6.2199\n",
      "Epoch 12: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8035 - mae: 6.1537 - val_loss: 3.2455 - val_mae: 1.7863\n",
      "Epoch 13/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.5532 - mae: 6.1460\n",
      "Epoch 13: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6036 - mae: 6.1815 - val_loss: 3.4812 - val_mae: 1.9486\n",
      "Epoch 13: early stopping\n",
      "Random Weights 74\n",
      "Epoch 1/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.6200 - mae: 6.1486\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6200 - mae: 6.1486 - val_loss: 6.9290 - val_mae: 5.2733\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.6958 - mae: 6.1807\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6839 - mae: 6.1699 - val_loss: 3.3602 - val_mae: 1.9810\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.7475 - mae: 6.2907\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7454 - mae: 6.2855 - val_loss: 4.6554 - val_mae: 3.2348\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.8622 - mae: 6.4293\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8555 - mae: 6.4226 - val_loss: 3.3571 - val_mae: 1.9263\n",
      "Epoch 5/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.5905 - mae: 6.1987\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5905 - mae: 6.1987 - val_loss: 3.0865 - val_mae: 1.6860\n",
      "Epoch 6/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.4431 - mae: 6.0505\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.4503 - mae: 6.0585 - val_loss: 4.3980 - val_mae: 3.1167\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.6108 - mae: 6.4006\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.6031 - mae: 6.3932 - val_loss: 5.3056 - val_mae: 4.1489\n",
      "Epoch 8/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 7.5512 - mae: 6.2317\n",
      "Epoch 8: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5351 - mae: 6.2156 - val_loss: 4.0815 - val_mae: 2.7721\n",
      "Epoch 8: early stopping\n",
      "loaded Weights 75\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.9404 - mae: 6.2599\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9653 - mae: 6.2618 - val_loss: 6.0252 - val_mae: 2.4239\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.0229 - mae: 6.2491\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.0319 - mae: 6.2581 - val_loss: 10.6922 - val_mae: 6.9167\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 10.1106 - mae: 6.4134\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 10.1066 - mae: 6.4150 - val_loss: 11.1165 - val_mae: 7.6031\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.4203 - mae: 6.1523\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4203 - mae: 6.1523 - val_loss: 5.3384 - val_mae: 2.3197\n",
      "Epoch 5/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.2935 - mae: 6.3559\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2968 - mae: 6.3608 - val_loss: 5.7342 - val_mae: 3.0220\n",
      "Epoch 6/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.5061 - mae: 6.0680\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5178 - mae: 6.0821 - val_loss: 7.2152 - val_mae: 4.9007\n",
      "Epoch 7/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.5178 - mae: 6.2648\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5243 - mae: 6.2708 - val_loss: 8.3704 - val_mae: 6.0591\n",
      "Epoch 7: early stopping\n",
      "Random Weights 76\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4657 - mae: 6.3228\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.4895 - mae: 6.3466 - val_loss: 5.7822 - val_mae: 3.6305\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4149 - mae: 6.3207\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3874 - mae: 6.2973 - val_loss: 5.1828 - val_mae: 3.2490\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.0773 - mae: 6.2168\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0617 - mae: 6.2010 - val_loss: 6.4440 - val_mae: 4.6291\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.6090 - mae: 5.8982\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.5980 - mae: 5.8916 - val_loss: 5.2177 - val_mae: 3.6683\n",
      "Epoch 5/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.6798 - mae: 6.1973\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7044 - mae: 6.2206 - val_loss: 7.7687 - val_mae: 6.2510\n",
      "Epoch 5: early stopping\n",
      "loaded Weights 77\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.7799 - mae: 6.3258\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.7771 - mae: 6.3191 - val_loss: 4.9265 - val_mae: 1.9519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.4722 - mae: 6.4484\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4722 - mae: 6.4484 - val_loss: 4.6247 - val_mae: 1.6648\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.2096 - mae: 6.2308\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.2083 - mae: 6.3008 - val_loss: 5.9192 - val_mae: 3.3196\n",
      "Epoch 4/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 8.9775 - mae: 6.3061\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9408 - mae: 6.3027 - val_loss: 5.1682 - val_mae: 2.8096\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.5628 - mae: 6.3071\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4922 - mae: 6.2359 - val_loss: 3.9286 - val_mae: 1.7171\n",
      "Epoch 5: early stopping\n",
      "Random Weights 78\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.3228 - mae: 6.3732\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3317 - mae: 6.4251 - val_loss: 4.5133 - val_mae: 2.8204\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.9826 - mae: 6.2076\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0111 - mae: 6.2749 - val_loss: 3.2215 - val_mae: 1.6927\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.8425 - mae: 6.3262\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.8331 - mae: 6.2983 - val_loss: 5.3165 - val_mae: 3.6486\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 7.9008 - mae: 5.9881\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9008 - mae: 5.9881 - val_loss: 3.4145 - val_mae: 1.6677\n",
      "Epoch 5/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 7.8793 - mae: 6.1988\n",
      "Epoch 5: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.9240 - mae: 6.2448 - val_loss: 4.0466 - val_mae: 2.3932\n",
      "Epoch 6/10000\n",
      "42/51 [=======================>......] - ETA: 0s - loss: 7.5895 - mae: 5.9853\n",
      "Epoch 6: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 7.5662 - mae: 5.9741 - val_loss: 3.3794 - val_mae: 1.8940\n",
      "Epoch 7/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 7.7453 - mae: 6.2565\n",
      "Epoch 7: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 7.7383 - mae: 6.2482 - val_loss: 3.9364 - val_mae: 2.4172\n",
      "Epoch 7: early stopping\n",
      "loaded Weights 79\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.4203 - mae: 6.1272\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5801 - mae: 6.1980 - val_loss: 4.5072 - val_mae: 1.7639\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.6072 - mae: 6.4140\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.6072 - mae: 6.4140 - val_loss: 5.3489 - val_mae: 1.6395\n",
      "Epoch 3/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.8638 - mae: 6.3251\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.8681 - mae: 6.3300 - val_loss: 12.0855 - val_mae: 8.5671\n",
      "Epoch 3: early stopping\n",
      "Random Weights 80\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 9.9587 - mae: 6.4015 \n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.9408 - mae: 6.3904 - val_loss: 4.4129 - val_mae: 1.8188\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.4694 - mae: 6.0315\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4694 - mae: 6.0315 - val_loss: 4.8000 - val_mae: 2.4491\n",
      "Epoch 2: early stopping\n",
      "loaded Weights 81\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.9952 - mae: 6.3738\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9930 - mae: 6.3686 - val_loss: 5.0534 - val_mae: 2.0119\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.5317 - mae: 6.3199\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5178 - mae: 6.3125 - val_loss: 4.8100 - val_mae: 1.8998\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.7634 - mae: 6.1418\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7603 - mae: 6.1443 - val_loss: 4.1354 - val_mae: 1.6697\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.5667 - mae: 6.1582\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5909 - mae: 6.1856 - val_loss: 4.2888 - val_mae: 2.0268\n",
      "Epoch 4: early stopping\n",
      "Random Weights 82\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4040 - mae: 6.2094\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.4183 - mae: 6.2269 - val_loss: 4.8387 - val_mae: 2.7177\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.6881 - mae: 6.1628\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6817 - mae: 6.1535 - val_loss: 4.7772 - val_mae: 2.2383\n",
      "Epoch 3/10000\n",
      "45/51 [=========================>....] - ETA: 0s - loss: 8.5227 - mae: 6.3735\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5044 - mae: 6.3804 - val_loss: 3.9254 - val_mae: 2.0233\n",
      "Epoch 4/10000\n",
      "48/51 [===========================>..] - ETA: 0s - loss: 8.1529 - mae: 6.2803\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1647 - mae: 6.2919 - val_loss: 4.6067 - val_mae: 2.6572\n",
      "Epoch 4: early stopping\n",
      "loaded Weights 83\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.7677 - mae: 6.3598\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.7434 - mae: 6.3252 - val_loss: 4.4824 - val_mae: 1.6257\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.4843 - mae: 6.0916\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.4947 - mae: 6.1082 - val_loss: 4.8717 - val_mae: 1.7399\n",
      "Epoch 2: early stopping\n",
      "Random Weights 84\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.2664 - mae: 6.3437\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 9.2811 - mae: 6.3649 - val_loss: 4.3458 - val_mae: 1.6695\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.8713 - mae: 6.3381\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8475 - mae: 6.3196 - val_loss: 4.0529 - val_mae: 1.6973\n",
      "Epoch 2: early stopping\n",
      "loaded Weights 85\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.5392 - mae: 6.3256\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4553 - mae: 6.1919 - val_loss: 4.2795 - val_mae: 1.7514\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.7840 - mae: 6.1770\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7887 - mae: 6.1785 - val_loss: 4.9989 - val_mae: 2.2753\n",
      "Epoch 2: early stopping\n",
      "Random Weights 86\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.9637 - mae: 6.2682\n",
      "Epoch 1: val_mae did not improve from 1.61936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 6ms/step - loss: 8.9496 - mae: 6.2654 - val_loss: 5.3739 - val_mae: 3.0785\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.5201 - mae: 6.3887\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5157 - mae: 6.3856 - val_loss: 3.8375 - val_mae: 1.8922\n",
      "Epoch 3/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.0779 - mae: 6.1227\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.0692 - mae: 6.1226 - val_loss: 3.6413 - val_mae: 1.6403\n",
      "Epoch 4/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.1783 - mae: 6.1326\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1783 - mae: 6.1326 - val_loss: 4.0450 - val_mae: 2.1175\n",
      "Epoch 4: early stopping\n",
      "loaded Weights 87\n",
      "Epoch 1/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 8.5945 - mae: 6.3675\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5089 - mae: 6.2424 - val_loss: 4.3142 - val_mae: 1.8749\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 9.1018 - mae: 6.1960\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.1018 - mae: 6.1960 - val_loss: 5.0849 - val_mae: 1.9836\n",
      "Epoch 2: early stopping\n",
      "Random Weights 88\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.8496 - mae: 6.2610\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7691 - mae: 6.2485 - val_loss: 3.8773 - val_mae: 1.6959\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.2334 - mae: 6.1913\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2446 - mae: 6.2186 - val_loss: 3.7958 - val_mae: 1.8302\n",
      "Epoch 2: early stopping\n",
      "loaded Weights 89\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.7285 - mae: 6.2617\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6702 - mae: 6.1987 - val_loss: 4.5774 - val_mae: 2.1754\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.7457 - mae: 6.2504\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7239 - mae: 6.2595 - val_loss: 6.7121 - val_mae: 4.4402\n",
      "Epoch 2: early stopping\n",
      "Random Weights 90\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.6248 - mae: 6.4622\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6197 - mae: 6.4590 - val_loss: 3.9612 - val_mae: 1.8391\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.4949 - mae: 6.2882\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4991 - mae: 6.2927 - val_loss: 4.1278 - val_mae: 1.9717\n",
      "Epoch 2: early stopping\n",
      "loaded Weights 91\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.7553 - mae: 6.3959\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.7424 - mae: 6.3819 - val_loss: 5.5450 - val_mae: 3.0364\n",
      "Epoch 2/10000\n",
      "51/51 [==============================] - ETA: 0s - loss: 8.8166 - mae: 6.1029\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8166 - mae: 6.1029 - val_loss: 4.3473 - val_mae: 1.7280\n",
      "Epoch 3/10000\n",
      "43/51 [========================>.....] - ETA: 0s - loss: 8.9350 - mae: 6.3117\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.8638 - mae: 6.2450 - val_loss: 4.5985 - val_mae: 1.9401\n",
      "Epoch 3: early stopping\n",
      "Random Weights 92\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.8703 - mae: 6.3200\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.8640 - mae: 6.3166 - val_loss: 3.8391 - val_mae: 1.7112\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.4352 - mae: 6.3671\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4474 - mae: 6.3797 - val_loss: 4.0168 - val_mae: 2.0033\n",
      "Epoch 2: early stopping\n",
      "loaded Weights 93\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.5254 - mae: 6.2380\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.5004 - mae: 6.2119 - val_loss: 4.0319 - val_mae: 1.6775\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.9309 - mae: 6.2725\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.9378 - mae: 6.2817 - val_loss: 4.5729 - val_mae: 1.9654\n",
      "Epoch 2: early stopping\n",
      "Random Weights 94\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.5380 - mae: 6.1458\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.5520 - mae: 6.1688 - val_loss: 3.9226 - val_mae: 1.8413\n",
      "Epoch 2/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.6537 - mae: 6.4104\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6488 - mae: 6.4043 - val_loss: 4.2229 - val_mae: 1.8323\n",
      "Epoch 3/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.6499 - mae: 6.3856\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6926 - mae: 6.4294 - val_loss: 3.9762 - val_mae: 1.6641\n",
      "Epoch 4/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.3835 - mae: 6.2114\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3457 - mae: 6.1811 - val_loss: 3.7535 - val_mae: 1.9108\n",
      "Epoch 4: early stopping\n",
      "loaded Weights 95\n",
      "Epoch 1/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.4801 - mae: 6.3115\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4874 - mae: 6.3171 - val_loss: 4.1873 - val_mae: 1.7679\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 9.1157 - mae: 6.3864\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.0883 - mae: 6.3640 - val_loss: 6.4868 - val_mae: 3.9424\n",
      "Epoch 2: early stopping\n",
      "Random Weights 96\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.6215 - mae: 6.2845\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.6441 - mae: 6.3144 - val_loss: 4.4910 - val_mae: 2.4649\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.1594 - mae: 6.1620\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.1690 - mae: 6.1726 - val_loss: 6.2335 - val_mae: 4.2862\n",
      "Epoch 2: early stopping\n",
      "loaded Weights 97\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.4378 - mae: 6.1143\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.4364 - mae: 6.1103 - val_loss: 4.0795 - val_mae: 1.6296\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.8697 - mae: 6.3331\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8665 - mae: 6.3335 - val_loss: 4.4717 - val_mae: 2.0816\n",
      "Epoch 2: early stopping\n",
      "Random Weights 98\n",
      "Epoch 1/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.7260 - mae: 6.3789\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 6ms/step - loss: 8.7309 - mae: 6.3862 - val_loss: 4.0371 - val_mae: 1.7137\n",
      "Epoch 2/10000\n",
      "49/51 [===========================>..] - ETA: 0s - loss: 8.5649 - mae: 6.2728\n",
      "Epoch 2: val_mae did not improve from 1.61936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 5ms/step - loss: 8.5509 - mae: 6.2619 - val_loss: 3.8574 - val_mae: 1.6714\n",
      "Epoch 3/10000\n",
      "40/51 [======================>.......] - ETA: 0s - loss: 8.4757 - mae: 6.3546\n",
      "Epoch 3: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.3618 - mae: 6.2674 - val_loss: 3.6191 - val_mae: 1.6698\n",
      "Epoch 4/10000\n",
      "50/51 [============================>.] - ETA: 0s - loss: 8.2881 - mae: 6.3832\n",
      "Epoch 4: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.2858 - mae: 6.3805 - val_loss: 4.1267 - val_mae: 2.1720\n",
      "Epoch 4: early stopping\n",
      "loaded Weights 99\n",
      "Epoch 1/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 8.5942 - mae: 6.2355\n",
      "Epoch 1: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 8.8150 - mae: 6.2616 - val_loss: 5.0161 - val_mae: 1.6897\n",
      "Epoch 2/10000\n",
      "39/51 [=====================>........] - ETA: 0s - loss: 9.6582 - mae: 6.4434\n",
      "Epoch 2: val_mae did not improve from 1.61936\n",
      "51/51 [==============================] - 0s 5ms/step - loss: 9.5223 - mae: 6.4118 - val_loss: 4.6699 - val_mae: 2.0022\n",
      "Epoch 2: early stopping\n",
      "Random Weights 100\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(1,101):\n",
    "    if i == 75:\n",
    "        early_stop = EarlyStopping(monitor='val_mae',patience = 3, verbose = 1)\n",
    "    elif i == 80:\n",
    "        early_stop = EarlyStopping(monitor='val_mae',patience = 1, verbose = 1)\n",
    "    nn.fit(X_train_scaled,y_train,epochs=10000,validation_data=(X_test,y_test),callbacks=[checkpoint,early_stop])\n",
    "    if i % 2 != 0:\n",
    "        print(f\"loaded Weights {i}\")\n",
    "        nn.load_weights('best_weights.h5')\n",
    "    else:\n",
    "        print(f\"Random Weights {i}\")\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa80480c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 4.6699 - mae: 2.0022\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = nn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f8643a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212.9652271270752 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = end_time - start_time\n",
    "\n",
    "print(f'{total_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1600e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_input_features = len(X_train_scaled[0])\n",
    "# hidden_layers_1 = 750\n",
    "# hidden_layers_list = [250]\n",
    "\n",
    "# nn_new = tf.keras.models.Sequential()\n",
    "\n",
    "# nn_new.add(tf.keras.layers.Dense(units=hidden_layers_1, input_dim=number_input_features, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "# nn_new.add(tf.keras.layers.Dropout(0.5))\n",
    "# for i in hidden_layers_list:\n",
    "#     nn_new.add(tf.keras.layers.Dense(units=i, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
    "#     nn_new.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# nn_new.add(tf.keras.layers.Dense(units=1, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0646c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79d2b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_new.load_weights('best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79c8beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_new.compile(loss = 'mse',optimizer ='adam',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc5990cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stop = EarlyStopping(monitor='val_mae',patience = 2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8d8a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_new.fit(X_train_scaled,y_train,epochs=10000,validation_data=(X_test,y_test),callbacks=[checkpoint,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9932c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_new.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
